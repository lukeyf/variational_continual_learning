{"cells":[{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.parameter import Parameter\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","\n","\n","class MFVI_Layer(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super(MFVI_Layer, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        \n","        # Mean parameters\n","        self.W_m = nn.Parameter(torch.Tensor(out_features, in_features))\n","        self.b_m = nn.Parameter(torch.Tensor(out_features))\n","\n","        # Log variance parameters\n","        self.W_logv = nn.Parameter(torch.Tensor(out_features, in_features))\n","        self.b_logv = nn.Parameter(torch.Tensor(out_features))\n","\n","        # Prior distributions (initialized to None and will be set in reset_parameters)\n","        self.prior_W_m = None\n","        self.prior_b_m = None\n","        self.prior_W_logv = None\n","        self.prior_b_logv = None\n","\n","        # Initialize parameters\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.W_m.data.normal_(0, 0.1)\n","        self.b_m.data.normal_(0, 0.1)\n","        self.W_logv.data.fill_(-6.0)\n","        self.b_logv.data.fill_(-6.0)\n","\n","        # Initially set priors to match the initial parameters\n","        self.set_priors()\n","\n","    def set_priors(self):\n","        # Update or set the prior distributions to the current parameters\n","        self.prior_W_m = self.W_m.detach().clone()\n","        self.prior_b_m = self.b_m.detach().clone()\n","        self.prior_W_logv = self.W_logv.detach().clone()\n","        self.prior_b_logv = self.b_logv.detach().clone()\n","\n","    def forward(self, x, sample=True):\n","        # Calculate standard deviations from log variances\n","        W_std = torch.exp(0.5 * self.W_logv)\n","        b_std = torch.exp(0.5 * self.b_logv)\n","        \n","        # Calculate the output mean\n","        act_mu = F.linear(x, self.W_m, self.b_m)\n","        \n","        # Calculate the output variance\n","        # The variance of the output is given by the sum of variances of the weighted inputs (assuming independence)\n","        act_var = 1e-16 + F.linear(x.pow(2), W_std.pow(2)) + b_std.pow(2)\n","        act_std = torch.sqrt(act_var)\n","\n","        if self.training or sample:\n","            # If in training mode or sample is True, sample from the posterior\n","            eps = torch.randn_like(act_mu)\n","            return act_mu + act_std * eps\n","        else:\n","            # Otherwise, return the mean of the posterior\n","            return act_mu\n","\n","\n","    def kl_divergence(self,device):\n","        # Calculate the number of parameters for normalization\n","        self.update_prior_device(device)\n","        num_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n","\n","        # Convert log variances to standard deviations\n","        W_std = torch.exp(0.5 * self.W_logv)\n","        b_std = torch.exp(0.5 * self.b_logv)\n","        prior_W_std = torch.exp(0.5 * self.prior_W_logv)\n","        prior_b_std = torch.exp(0.5 * self.prior_b_logv)\n","\n","        # Calculate KL divergence for weights using the standard deviation-based formula\n","        kl_W = 0.5 * (2 * torch.log(prior_W_std / W_std) - 1 + (W_std / prior_W_std).pow(2) + ((self.W_m - self.prior_W_m) / prior_W_std).pow(2)).sum()\n","\n","        # Calculate KL divergence for biases using the standard deviation-based formula\n","        kl_b = 0.5 * (2 * torch.log(prior_b_std / b_std) - 1 + (b_std / prior_b_std).pow(2) + ((self.b_m - self.prior_b_m) / prior_b_std).pow(2)).sum()\n","\n","        # Return the normalized KL divergence\n","        return (kl_W + kl_b) /num_params\n","\n","    def update_prior_device(self, device):\n","        self.prior_W_m = self.prior_W_m.to(device)\n","        self.prior_b_m = self.prior_b_m.to(device)\n","        self.prior_W_logv = self.prior_W_logv.to(device)\n","        self.prior_b_logv = self.prior_b_logv.to(device)\n","\n","\n","\n","class MFVI_NN(nn.Module):\n","    def __init__(self, input_size, hidden_sizes,  output_size, no_train_samples=10, no_pred_samples=100, num_tasks = 1):\n","        super(MFVI_NN, self).__init__()\n","\n","        self.layers = nn.ModuleList()\n","        self.task_specific_layers = nn.ModuleDict()  # Using ModuleDict to hold task-specific layers\n","        self.no_train_samples = no_train_samples\n","        self.no_pred_samples = no_pred_samples\n","\n","        # Define shared layers\n","        sizes = [input_size] + hidden_sizes\n","        for i in range(len(sizes)-1):\n","            self.layers.append(MFVI_Layer(sizes[i], sizes[i+1]))\n","\n","        # Define task-specific output layers\n","        for task_id in range(num_tasks):\n","            self.task_specific_layers[str(task_id)] = MFVI_Layer(sizes[-1], output_size)\n","\n","    def forward(self, x, task_id=0, sample=True):\n","        for layer in self.layers:\n","            x = F.relu(layer(x, sample))\n","\n","        # Select and apply the task-specific output layer\n","        task_layer = self.task_specific_layers[str(task_id)]\n","        x = task_layer(x, sample)\n","        return x\n","\n","    def kl_divergence(self):\n","        kl_div = 0\n","        # Sum KL divergence from shared layers\n","        for layer in self.layers:\n","            kl_div += layer.kl_divergence(next(self.parameters()).device)\n","\n","        # Sum KL divergence from task-specific layers\n","        for task_layer in self.task_specific_layers.values():\n","            kl_div += task_layer.kl_divergence(next(self.parameters()).device)\n","\n","        return kl_div\n","\n","\n","    def update_priors(self):\n","        # Update priors in each shared layer\n","        for layer in self.layers:\n","            layer.set_priors()  # Assuming each MFVI_Layer has a method called set_priors\n","        \n","        for task_layer in self.task_specific_layers.values():\n","            task_layer.set_priors()\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","\n","SEED = 42\n","torch.manual_seed(SEED)  # Set the random seed for PyTorch\n","\n","class MFVI_Layer(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super(MFVI_Layer, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        \n","        # Mean and log variance parameters\n","        self.W_m = nn.Parameter(torch.Tensor(out_features, in_features))\n","        self.b_m = nn.Parameter(torch.Tensor(out_features))\n","        self.W_logv = nn.Parameter(torch.Tensor(out_features, in_features))\n","        self.b_logv = nn.Parameter(torch.Tensor(out_features))\n","\n","        # Prior distributions initialized to None\n","        self.prior_W_m = self.prior_b_m = self.prior_W_logv = self.prior_b_logv = None\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        # Initialize mean parameters to a normal distribution and log variance parameters to a small value\n","        self.W_m.data.normal_(0, 0.1)\n","        self.b_m.data.normal_(0, 0.1)\n","        self.W_logv.data.fill_(-6.0)\n","        self.b_logv.data.fill_(-6.0)\n","        self.set_priors()\n","\n","    def set_priors(self):\n","        # Set priors to the current parameters\n","        self.prior_W_m = self.W_m.detach().clone()\n","        self.prior_b_m = self.b_m.detach().clone()\n","        self.prior_W_logv = self.W_logv.detach().clone()\n","        self.prior_b_logv = self.b_logv.detach().clone()\n","\n","    def forward(self, x, sample=True):\n","        W_std = torch.exp(0.5 * self.W_logv)\n","        b_std = torch.exp(0.5 * self.b_logv)\n","        \n","        act_mu = F.linear(x, self.W_m, self.b_m)\n","        act_var = 1e-16 + F.linear(x.pow(2), W_std.pow(2)) + b_std.pow(2)\n","        act_std = torch.sqrt(act_var)\n","\n","        if self.training or sample:\n","            eps = torch.randn_like(act_mu)\n","            return act_mu + act_std * eps\n","        else:\n","            return act_mu\n","\n","    def kl_divergence(self, device):\n","        self.update_prior_device(device)\n","        num_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n","        # Convert log variance to standard deviation for posterior and prior\n","        W_std_post = torch.exp(0.5 * self.W_logv)\n","        b_std_post = torch.exp(0.5 * self.b_logv)\n","        W_std_prior = torch.exp(0.5 * self.prior_W_logv)\n","        b_std_prior = torch.exp(0.5 * self.prior_b_logv)\n","\n","        # Calculate KL divergence for weights\n","        kl_div_W = torch.log(W_std_prior / W_std_post) + \\\n","                ((W_std_post**2 + (self.W_m - self.prior_W_m)**2) / (2 * W_std_prior**2)) - 0.5\n","        # Sum over all elements\n","        kl_div_W = kl_div_W.sum()\n","\n","        # Calculate KL divergence for biases\n","        kl_div_b = torch.log(b_std_prior / b_std_post) + \\\n","                ((b_std_post**2 + (self.b_m - self.prior_b_m)**2) / (2 * b_std_prior**2)) - 0.5\n","        # Sum over all elements\n","        kl_div_b = kl_div_b.sum()\n","\n","        # Total KL divergence\n","        total_kl = kl_div_W + kl_div_b\n","\n","        return total_kl/num_params\n","\n","    def update_prior_device(self, device):\n","        # Ensure priors are moved to the correct device\n","        self.prior_W_m = self.prior_W_m.to(device)\n","        self.prior_b_m = self.prior_b_m.to(device)\n","        self.prior_W_logv = self.prior_W_logv.to(device)\n","        self.prior_b_logv = self.prior_b_logv.to(device)\n","\n","class MFVI_NN(nn.Module):\n","    def __init__(self, input_size, hidden_sizes, output_size, num_tasks=1, single_head=False):\n","        super(MFVI_NN, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_sizes = hidden_sizes\n","        self.output_size = output_size\n","        self.num_tasks = num_tasks\n","        self.single_head = single_head\n","        self.layers = nn.ModuleList()\n","        self.task_specific_layers = nn.ModuleDict()  # Using ModuleDict for task-specific layers\n","\n","        # Construct shared layers\n","        sizes = [input_size] + hidden_sizes\n","        for i in range(len(sizes) - 1):\n","            self.layers.append(MFVI_Layer(sizes[i], sizes[i + 1]))\n","\n","        # Construct task-specific output layers\n","        if single_head:\n","            self.task_specific_layers[str(0)] = MFVI_Layer(sizes[-1], output_size)\n","        else:\n","            for task_id in range(num_tasks):\n","                self.task_specific_layers[str(task_id)] = MFVI_Layer(sizes[-1], output_size)\n","\n","    def forward(self, x, task_id=0, sample=True):\n","        for layer in self.layers:\n","            x = F.relu(layer(x, sample=sample))\n","        if self.single_head:\n","            x = self.task_specific_layers[\"0\"](x, sample=sample)\n","        else:\n","            x = self.task_specific_layers[str(task_id)](x, sample=sample)\n","        return x\n","\n","    def kl_divergence(self):\n","        kl_div = 0\n","        # Accumulate KL divergence from shared and task-specific layers\n","        for layer in self.layers:\n","            kl_div += layer.kl_divergence(next(self.parameters()).device)\n","        # for task_layer in self.task_specific_layers.values():\n","        #     kl_div += task_layer.kl_divergence(next(self.parameters()).device)\n","        return kl_div\n","\n","    def update_priors(self):\n","        # Update priors in each layer\n","        for layer in self.layers + list(self.task_specific_layers.values()):\n","            layer.set_priors()\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T22:29:34.052062Z","iopub.status.busy":"2024-03-21T22:29:34.051191Z","iopub.status.idle":"2024-03-21T22:29:34.063146Z","shell.execute_reply":"2024-03-21T22:29:34.061986Z","shell.execute_reply.started":"2024-03-21T22:29:34.052035Z"},"id":"su4PfiXIdwAN","trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","\n","def train(model, trainloader, optimizer, epoch, device, kl_weight=1, task_id = 0, binary_label = None):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(trainloader):\n","        data, target = data.to(device), target.to(device)\n","        data = data.view(data.size(0), -1)  # Flatten the images\n","        optimizer.zero_grad()\n","        output = model(data, sample=True, task_id = task_id)\n","        if binary_label != None:\n","            target = (target == binary_label[0]).long()\n","        reconstruction_loss = F.cross_entropy(output, target, reduction='mean')\n","        \n","#         print(kl_divergence,reconstruction_loss)\n","        if task_id == 0:\n","            loss = reconstruction_loss\n","        else:\n","            kl_divergence = model.kl_divergence()\n","            loss = reconstruction_loss + kl_divergence * kl_weight\n","        loss.backward()\n","        optimizer.step()\n","#     print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(trainloader.dataset)} ({100. * batch_idx / len(trainloader):.0f}%)]\\tLoss: {loss.item()}\")\n","\n","def test(model, testloader, device, task_id = 0, binary_label = None):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in testloader:\n","            data, target = data.to(device), target.to(device)\n","            data = data.view(data.size(0), -1)  # Flatten the images\n","            output = model(data, sample=False, task_id = task_id)\n","            if binary_label != None:\n","                target = (target == binary_label[0]).long()\n","\n","            # Use cross_entropy for test loss calculation, sum up batch loss\n","            test_loss += F.cross_entropy(output, target, reduction='mean').item()\n","            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(testloader.dataset)\n","    # print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(testloader.dataset)} ({100. * correct / len(testloader.dataset):.0f}%)\\n')\n","    return test_loss, correct / len(testloader.dataset)\n"]},{"cell_type":"markdown","metadata":{"id":"lCTWinB8DD_M"},"source":["## Permuted MNIST"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T20:26:09.548948Z","iopub.status.busy":"2024-03-21T20:26:09.548620Z","iopub.status.idle":"2024-03-21T20:26:09.626573Z","shell.execute_reply":"2024-03-21T20:26:09.625767Z","shell.execute_reply.started":"2024-03-21T20:26:09.548924Z"},"id":"-iGpZltOvLRw","trusted":true},"outputs":[],"source":["from torchvision import datasets, transforms\n","\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,))])\n","\n","mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/10 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [00:33<00:00,  3.38s/it]\n"]},{"ename":"NameError","evalue":"name 'DataLoader' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     permuted_mnist_train_datasets\u001b[38;5;241m.\u001b[39mappend(permuted_train)\n\u001b[1;32m     25\u001b[0m     permuted_mnist_test_datasets\u001b[38;5;241m.\u001b[39mappend(permuted_test)\n\u001b[0;32m---> 27\u001b[0m permuted_mnist_train_loaders \u001b[38;5;241m=\u001b[39m [DataLoader(m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m permuted_mnist_train_datasets]\n\u001b[1;32m     29\u001b[0m permuted_mnist_test_loaders \u001b[38;5;241m=\u001b[39m [DataLoader(m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m permuted_mnist_test_datasets]\n","Cell \u001b[0;32mIn[7], line 27\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m     permuted_mnist_train_datasets\u001b[38;5;241m.\u001b[39mappend(permuted_train)\n\u001b[1;32m     25\u001b[0m     permuted_mnist_test_datasets\u001b[38;5;241m.\u001b[39mappend(permuted_test)\n\u001b[0;32m---> 27\u001b[0m permuted_mnist_train_loaders \u001b[38;5;241m=\u001b[39m [\u001b[43mDataLoader\u001b[49m(m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m permuted_mnist_train_datasets]\n\u001b[1;32m     29\u001b[0m permuted_mnist_test_loaders \u001b[38;5;241m=\u001b[39m [DataLoader(m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m permuted_mnist_test_datasets]\n","\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"]}],"source":["def permute_mnist(mnist, perm):\n","    \"\"\"Apply a fixed permutation to the pixels of each image in the dataset.\"\"\"\n","    permuted_data = []\n","    for img, target in mnist:\n","        # Flatten the image, apply permutation and reshape back to 1x28x28\n","        img_permuted = img.view(-1)[perm].view(1, 28, 28)\n","        permuted_data.append((img_permuted, target))\n","    return permuted_data\n","\n","# Initialize lists to store the permuted datasets\n","permuted_mnist_train_datasets = []\n","permuted_mnist_test_datasets = []\n","\n","# Generate 10 permuted datasets\n","for _ in tqdm(range(10)):\n","    # Generate a fixed permutation\n","    fixed_permutation = torch.randperm(784)\n","    \n","    # Apply this permutation to the train and test datasets\n","    permuted_train = permute_mnist(mnist_trainset, fixed_permutation)\n","    permuted_test = permute_mnist(mnist_testset, fixed_permutation)\n","    \n","    # Store the permuted datasets\n","    permuted_mnist_train_datasets.append(permuted_train)\n","    permuted_mnist_test_datasets.append(permuted_test)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["\n","from torch.utils.data import DataLoader\n","\n","\n","batch_size = 64\n","permuted_mnist_train_loaders = [DataLoader(m, batch_size=batch_size, shuffle=True) for m in permuted_mnist_train_datasets]\n"," \n","permuted_mnist_test_loaders = [DataLoader(m, batch_size=batch_size, shuffle=False) for m in permuted_mnist_test_datasets]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T20:26:09.706009Z","iopub.status.busy":"2024-03-21T20:26:09.705662Z","iopub.status.idle":"2024-03-21T20:26:09.712251Z","shell.execute_reply":"2024-03-21T20:26:09.711281Z","shell.execute_reply.started":"2024-03-21T20:26:09.705982Z"},"id":"G3VNEXUADM7j","trusted":true},"outputs":[],"source":["import torch\n","torch.manual_seed(SEED)\n","def generate_permutations(task_count, image_size):\n","    permutations = [torch.randperm(image_size) for _ in range(task_count-1)]\n","    return permutations\n","\n","task_count = 10\n","image_size = 28 * 28  # MNIST images are 28x28\n","permutations = generate_permutations(task_count, image_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T20:26:09.874040Z","iopub.status.busy":"2024-03-21T20:26:09.873745Z","iopub.status.idle":"2024-03-21T20:26:09.881105Z","shell.execute_reply":"2024-03-21T20:26:09.880249Z","shell.execute_reply.started":"2024-03-21T20:26:09.874015Z"},"id":"bkE72alHDOKy","trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","class PermutedMNIST(Dataset):\n","    def __init__(self, mnist_dataset, permutation=None):\n","        self.mnist_dataset = mnist_dataset\n","        self.permutation = permutation\n","\n","    def __len__(self):\n","        return len(self.mnist_dataset)\n","\n","    def __getitem__(self, idx):\n","        image, label = self.mnist_dataset[idx]\n","        if self.permutation is not None:\n","            # Apply permutation\n","            image = image.view(-1)[self.permutation].view(1, 28, 28)\n","        return image, label\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:29:05.975601Z","iopub.status.busy":"2024-03-21T21:29:05.974932Z","iopub.status.idle":"2024-03-21T21:29:05.983346Z","shell.execute_reply":"2024-03-21T21:29:05.982351Z","shell.execute_reply.started":"2024-03-21T21:29:05.975572Z"},"id":"1Riy4xPFDRAp","trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","# Create a DataLoader for the original MNIST\n","pmnist_train_loaders = [DataLoader(mnist_trainset, batch_size=batch_size, shuffle=True)]\n","pmnist_test_loaders = [DataLoader(mnist_testset,batch_size=batch_size, shuffle=False)]\n","pmnist_data_loader = [(pmnist_train_loaders[0], pmnist_test_loaders[0])]\n","# Create DataLoaders for permuted tasks\n","for perm in permutations:\n","    permuted_train = PermutedMNIST(mnist_trainset, permutation=perm)\n","    permuted_test = PermutedMNIST(mnist_testset, permutation=perm)\n","\n","    train_loader = DataLoader(permuted_train, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(permuted_test, batch_size=batch_size, shuffle=False)\n","\n","    pmnist_train_loaders.append(train_loader)\n","    pmnist_test_loaders.append(test_loader)\n","    pmnist_data_loader.append((train_loader,test_loader))\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2024-03-21T22:30:10.749119Z","iopub.status.busy":"2024-03-21T22:30:10.748741Z","iopub.status.idle":"2024-03-21T22:30:15.465062Z","shell.execute_reply":"2024-03-21T22:30:15.463857Z","shell.execute_reply.started":"2024-03-21T22:30:10.749089Z"},"id":"fprvcPUPDbhv","outputId":"fb650c07-66b7-43d2-e4e8-37ba765532a2","trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","# Assuming model, optimizer, train_loaders, test_loaders are defined\n","if torch.cuda.is_available():\n","    device = 'cuda'\n","else:\n","    device = 'cpu'"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:21:19.853259Z","iopub.status.busy":"2024-03-21T21:21:19.852461Z","iopub.status.idle":"2024-03-21T21:21:19.859168Z","shell.execute_reply":"2024-03-21T21:21:19.858255Z","shell.execute_reply.started":"2024-03-21T21:21:19.853222Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader, ConcatDataset, Subset\n","def random_coreset(dataset, coreset_size):\n","    \"\"\"\n","    Randomly selects a subset of data points to form a coreset.\n","\n","    Args:\n","    - dataset (torch.utils.data.Dataset): The dataset to sample from.\n","    - coreset_size (int): The number of samples to include in the coreset.\n","\n","    Returns:\n","    - coreset_indices (torch.Tensor): Indices of the selected samples.\n","    \"\"\"\n","    # Ensure coreset size does not exceed dataset size\n","    coreset_size = min(coreset_size, len(dataset))\n","    \n","    # Randomly select indices without replacement\n","    coreset_indices = np.random.choice(len(dataset), size=coreset_size, replace=False)\n","    \n","    # Convert numpy array to torch tensor\n","    coreset_indices = torch.from_numpy(coreset_indices)\n","    \n","    coreset = Subset(dataset, coreset_indices)\n","    return coreset\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":207},"execution":{"iopub.execute_input":"2024-03-21T22:30:21.335314Z","iopub.status.busy":"2024-03-21T22:30:21.334944Z"},"id":"DBD-Tcr1EAn2","outputId":"3116097e-5d13-4583-8b9a-795fc0a6efa2","trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","epoch_per_task = 20\n","\n","def run_vcl(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size=0, beta=1, binary_labels = None):\n","    ave_acc_trend_rc = []\n","    prev_test_loaders= []\n","    coresets = []\n","    if binary_labels is None:\n","        binary_labels = [None] * model.num_tasks\n","    for task_id, (train_loader, test_loader) in enumerate(zip(train_loaders, test_loaders), start=0):\n","        task_accuracies_rc = []\n","        # if coreset_size > 0:\n","        #     for i in (range(len(coresets))):\n","        #         for epoch in (range(1, epoch_per_task + 1)):\n","        #             coreset_loader = DataLoader(coresets[i], batch_size=batch_size, shuffle=True)\n","        #             train(model, coreset_loader, optimizer, epoch, device, beta, task_id=i, binary_label=binary_labels[i])\n","        #         model.update_priors()\n","        for epoch in (range(1, epoch_per_task + 1)):\n","            train(model, train_loader, optimizer, epoch, device, beta, task_id=task_id, binary_label=binary_labels[task_id])\n","        model.update_priors()\n","\n","\n","        # for prediction\n","        prediction_model = type(model)(model.input_size, model.hidden_sizes, model.output_size, model.num_tasks, model.single_head).to(device)\n","        prediction_model.load_state_dict(model.state_dict())\n","        # replay\n","        # if coreset_size > 0:\n","        #     coresets.append(random_coreset(train_loader.dataset, coreset_size))\n","        #     for i in (range(len(coresets))):\n","        #         for epoch in (range(1, epoch_per_task + 1)):\n","        #             coreset_loader = DataLoader(coresets[i], batch_size=batch_size, shuffle=True)\n","        #             train(prediction_model, coreset_loader, optimizer, epoch, device, beta, task_id=i, binary_label=binary_labels[i])\n","        task_num = 0  \n","        prev_test_loaders.append(test_loader)\n","        for ptl in prev_test_loaders: \n","            test_loss, task_accuracy = test(prediction_model, ptl, device,task_id=task_num, binary_label=binary_labels[task_num])\n","            task_accuracies_rc.append(task_accuracy)\n","            task_num += 1\n","        print(task_accuracies_rc)\n","        average_accuracy = sum(task_accuracies_rc) / len(task_accuracies_rc)\n","        ave_acc_trend_rc.append(average_accuracy)\n","        print(f'Average Accuracy across {len(task_accuracies_rc)} tasks: {average_accuracy*100:.2f}%')\n","    return ave_acc_trend_rc\n","\n","def scale_similarity(sim, a, b):\n","    return 1/(1+np.exp(-20*(sim-(a+b)/2)))\n","\n","def run_auto_vcl(model, train_loaders,test_loaders, optimizer, epoch_per_task, coreset_size, \n","                beta_star=1, raw_training_epoch = 5,raw_train_size = 1000, \n","                binary_labels = None, dor = False, return_betas = False):\n","    task_difficulties = []\n","    \n","    ave_acc_trend_rc = []\n","    prev_test_loaders= []\n","    coresets = []\n","    betas = []\n","    if binary_labels is None:\n","        binary_labels = [None] * model.output_size\n","    for task_id, (train_loader, test_loader) in enumerate(zip(train_loaders, test_loaders), start=0):\n","        raw_acc = []\n","        for i in range(10):\n","            raw_model = type(model)(model.input_size, model.hidden_sizes, model.output_size, model.num_tasks, model.single_head).to(device)\n","            ## raw training\n","\n","            raw_trainset = random_coreset(train_loader.dataset, raw_train_size)\n","            raw_train_loader = DataLoader(raw_trainset, batch_size=batch_size, shuffle=True)\n","            raw_optimizer = torch.optim.Adam(raw_model.parameters(), lr=0.001)\n","\n","            for epoch in (range(1, raw_training_epoch + 1)):\n","                train(raw_model, raw_train_loader, raw_optimizer, epoch, device, beta_star, task_id=0, binary_label=binary_labels[task_id])\n","            _, acc_simple_train = test(raw_model, test_loader, device,task_id=0, binary_label=binary_labels[task_id])\n","            raw_acc.append(acc_simple_train)\n","        \n","        acc_simple_train = np.mean(raw_acc)\n","        print(acc_simple_train)\n","\n","        dummy_pred = 1/model.output_size\n","        curr_difficulty = min(max((1-(acc_simple_train - dummy_pred)/(1-dummy_pred)),0),1)\n","        if task_id > 0:\n","            print(task_id-1)\n","            _, raw_pred = test(model, test_loader, device,task_id=task_id-1, binary_label=binary_labels[task_id])\n","            print(raw_pred,'raw_pred')\n","            \n","            # similarity = min(max(np.abs(raw_pred - dummy_pred)/(prev_acc- dummy_pred),0),1)\n","            similarity = scale_similarity(np.abs(raw_pred-dummy_pred), 0, 1-dummy_pred)\n","            prev_difficulty = np.max(task_difficulties)\n","            print(prev_difficulty, curr_difficulty,similarity,'all')\n","            beta = beta_star*10**((prev_difficulty-curr_difficulty)*4+similarity*4)\n","            betas.append(beta)\n","            print(beta,'beta')\n","        else: \n","            beta = beta_star\n","\n","        if coreset_size > 0 and task_id>0:\n","            if (dor):\n","                zipped_and_indices = sorted(enumerate(zip(task_difficulties, coresets)), key=lambda x: x[1][0], reverse=True)\n","\n","                sorted_task_nums = [index for index, _ in zipped_and_indices]\n","                sorted_difficulties = [pair[0] for _, pair in zipped_and_indices]\n","                replay_coresets = [pair[1] for _, pair in zipped_and_indices]\n","                replay_betas = [beta_star*10**(2-d) for d in sorted_difficulties]\n","                print(sorted_difficulties, replay_betas)\n","            else:\n","                replay_coresets = coresets\n","            for i in (range(len(coresets))):\n","                for epoch in (range(1, epoch_per_task + 1)):\n","                    coreset_loader = DataLoader(replay_coresets[i], batch_size=batch_size, shuffle=True)\n","                    if dor:\n","                        sorted_task_num = sorted_task_nums[i]\n","                        train(model, coreset_loader, optimizer, epoch, device, replay_betas[i], task_id=sorted_task_num, binary_label=binary_labels[sorted_task_num])\n","                    else:\n","                        train(model, coreset_loader, optimizer, epoch, device, beta_star, task_id=i, binary_label=binary_labels[i])\n","                model.update_priors()\n","        for epoch in (range(1, epoch_per_task + 1)):\n","            train(model, train_loader, optimizer, epoch, device, beta, task_id=task_id, binary_label=binary_labels[task_id])\n","        model.update_priors()\n","\n","\n","        # for prediction\n","        prediction_model = type(model)(model.input_size, model.hidden_sizes, model.output_size, model.num_tasks, model.single_head).to(device)\n","        prediction_model.load_state_dict(model.state_dict())\n","        # replay\n","\n","        task_difficulties.append(curr_difficulty)\n","        if coreset_size > 0:\n","            \n","            coresets.append(random_coreset(train_loader.dataset, coreset_size))\n","            if (dor):\n","                zipped_and_indices = sorted(enumerate(zip(task_difficulties, coresets)), key=lambda x: x[1][0], reverse=True)\n","\n","                sorted_task_nums = [index for index, _ in zipped_and_indices]\n","                sorted_difficulties = [pair[0] for _, pair in zipped_and_indices]\n","                replay_coresets = [pair[1] for _, pair in zipped_and_indices]\n","                replay_betas = [beta_star*10**(2-d) for d in sorted_difficulties]\n","            else:\n","                replay_coresets = coresets\n","            for i in (range(len(coresets))):\n","                for epoch in (range(1, epoch_per_task + 1)):\n","                    coreset_loader = DataLoader(replay_coresets[i], batch_size=batch_size, shuffle=True)\n","                    if dor:\n","                        sorted_task_num = sorted_task_nums[i]\n","                        train(model, coreset_loader, optimizer, epoch, device, replay_betas[i], task_id=sorted_task_num, binary_label=binary_labels[sorted_task_num])\n","                    else:\n","                        train(model, coreset_loader, optimizer, epoch, device, beta_star, task_id=i, binary_label=binary_labels[i])\n","        task_num = 0  \n","        prev_test_loaders.append(test_loader)\n","\n","        task_accuracies_rc = []\n","        for ptl in prev_test_loaders: \n","            test_loss, task_accuracy = test(prediction_model, ptl, device,task_id=task_num, binary_label=binary_labels[task_num])\n","            task_accuracies_rc.append(task_accuracy)\n","            task_num += 1\n","        \n","        prev_acc = task_accuracy\n","        average_accuracy = sum(task_accuracies_rc) / len(task_accuracies_rc)\n","        ave_acc_trend_rc.append(average_accuracy)\n","        print(f'Average Accuracy across {len(task_accuracies_rc)} tasks: {average_accuracy*100:.2f}%')\n","    if return_betas:\n","        return ave_acc_trend_rc, betas\n","    \n","    return ave_acc_trend_rc"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_split_task(dataset, classes):\n","    \"\"\"\n","    Create a binary classification task from the MNIST dataset.\n","    \n","    Parameters:\n","    - dataset: The original MNIST dataset (training or test).\n","    - classes: A tuple of two integers representing the classes to include in the split.\n","    \n","    Returns:\n","    - A Subset of the original dataset containing only the specified classes.\n","    \"\"\"\n","    # Find indices of classes we're interested in\n","    indices = [i for i, (_, target) in enumerate(dataset) if target in classes]\n","    \n","    # Create a subset of the dataset with only the specified classes\n","    subset = Subset(dataset, indices)\n","    \n","    return subset\n","\n","def create_split_dataloaders(train_dataset, test_dataset, tasks, batch_size=256):\n","    \"\"\"\n","    Create DataLoaders for each binary task in Split MNIST.\n","    \n","    Parameters:\n","    - train_dataset: The MNIST training dataset.\n","    - test_dataset: The MNIST test dataset.\n","    - batch_size: The batch size for the DataLoader.\n","    \n","    Returns:\n","    - A list of tuples containing (train_loader, test_loader) for each binary task.\n","    \"\"\"\n","    train_loaders = []\n","    test_loaders = []\n","    for task in tasks:\n","        # Create training subset and DataLoader\n","        train_subset = create_split_task(train_dataset, task)\n","        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","\n","        # Create test subset and DataLoader\n","        test_subset = create_split_task(test_dataset, task)\n","        test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n","\n","        train_loaders.append(train_loader)\n","        test_loaders.append(test_loader)\n","    \n","    return train_loaders, test_loaders"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","\n","def plot_trends(trends, title = 'Accuracy Trends in the Permuated MNIST Experiment', lower = 0.7):\n","    df = pd.DataFrame({\n","        '# of tasks': range(len(trends[0][0])),\n","        'beta = 0.01': np.mean(trends[0], axis = 0),\n","        'beta = 1': np.mean(trends[1], axis = 0),\n","        'beta = 100': np.mean(trends[2], axis = 0),\n","        'AutoVCL': np.mean(trends[3], axis = 0)\n","    })\n","    # Convert the DataFrame to long format\n","    df_long = df.melt('# of tasks', var_name='Series', value_name='Values')\n","\n","    import altair as alt\n","    legend_order = ['beta = 0.01', 'beta = 1', 'beta = 100', 'AutoVCL']\n","    # Create the plot\n","    chart = alt.Chart(df_long).mark_line(point=True).encode(\n","        \n","        x=alt.X('# of tasks:Q', title='# tasks', axis=alt.Axis(values=list(range(df_long['# of tasks'].max() + 1)))), # Ensure integer ticks),\n","        y=alt.Y('Values:Q', scale=alt.Scale(domain=[lower, 1]), title='Accuracy'),\n","        color=alt.Color('Series:N', sort=legend_order,scale=alt.Scale(scheme='category10'), legend=alt.Legend(title=\"Model\")),\n","        tooltip=['# of tasks', 'Values', 'Series']\n","    ).properties(\n","        width=800,\n","        height=400,\n","        title=title\n","    ).configure_axis(\n","        labelFontSize=15,\n","        titleFontSize=20\n","    ).configure_legend(\n","        labelFontSize=15,\n","        titleFontSize=15\n","    ).configure_title(\n","        fontSize=24\n","    )\n","\n","    chart.display()"]},{"cell_type":"markdown","metadata":{},"source":["## Reproduce"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["10"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["epoch_per_task"]},{"cell_type":"markdown","metadata":{},"source":["## split no core"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["tasks = [(0, 1), (2, 3), (4, 5), (6, 7), (8, 9)]\n","split_train_loaders, split_test_loaders = create_split_dataloaders(mnist_trainset, mnist_testset, tasks, batch_size=256)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.9985815602836879]\n","Average Accuracy across 1 tasks: 99.86%\n","[0.9981087470449173, 0.9931439764936337]\n","Average Accuracy across 2 tasks: 99.56%\n","[0.9749408983451536, 0.9882468168462292, 0.9973319103521878]\n","Average Accuracy across 3 tasks: 98.68%\n","[0.9962174940898345, 0.9059745347698335, 0.923692636072572, 0.9979859013091642]\n","Average Accuracy across 4 tasks: 95.60%\n","[0.9929078014184397, 0.871694417238002, 0.9386339381003201, 0.9859013091641491, 0.9904185577407968]\n","Average Accuracy across 5 tasks: 95.59%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9990543735224586, 0.9951028403525954]\n","Average Accuracy across 2 tasks: 99.71%\n","[0.9111111111111111, 0.9172380019588638, 0.9983991462113126]\n","Average Accuracy across 3 tasks: 94.22%\n","[0.7300236406619386, 0.8770812928501469, 0.7524012806830309, 0.9984894259818731]\n","Average Accuracy across 4 tasks: 83.95%\n","[0.9919621749408983, 0.8751224289911851, 0.8009605122732124, 0.9884189325276939, 0.9924357034795764]\n","Average Accuracy across 5 tasks: 92.98%\n","[0.9981087470449173]\n","Average Accuracy across 1 tasks: 99.81%\n","[0.9990543735224586, 0.9916748285994124]\n","Average Accuracy across 2 tasks: 99.54%\n","[0.9971631205673759, 0.9289911851126347, 0.9989327641408752]\n","Average Accuracy across 3 tasks: 97.50%\n","[0.9815602836879432, 0.8550440744368266, 0.9669156883671292, 0.9984894259818731]\n","Average Accuracy across 4 tasks: 95.05%\n","[0.9839243498817967, 0.8374142997061704, 0.9647812166488794, 0.9521651560926485, 0.9939485627836612]\n","Average Accuracy across 5 tasks: 94.64%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9995271867612293, 0.9960822722820764]\n","Average Accuracy across 2 tasks: 99.78%\n","[0.9976359338061466, 0.9853085210577864, 0.9978655282817502]\n","Average Accuracy across 3 tasks: 99.36%\n","[0.9914893617021276, 0.9696376101860921, 0.9610458911419424, 0.9984894259818731]\n","Average Accuracy across 4 tasks: 98.02%\n","[0.8472813238770686, 0.9157688540646425, 0.9871931696905016, 0.9909365558912386, 0.9949571356530509]\n","Average Accuracy across 5 tasks: 94.72%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9995271867612293, 0.990205680705191]\n","Average Accuracy across 2 tasks: 99.49%\n","[0.9985815602836879, 0.9407443682664055, 0.9973319103521878]\n","Average Accuracy across 3 tasks: 97.89%\n","[0.9806146572104019, 0.8388834476003918, 0.919957310565635, 0.9984894259818731]\n","Average Accuracy across 4 tasks: 93.45%\n","[0.9654846335697399, 0.6669931439764937, 0.9637139807897546, 0.9652567975830816, 0.9934442763489663]\n","Average Accuracy across 5 tasks: 91.10%\n"]}],"source":["\n","coreset_size = 0\n","trends_1 = []\n","for i in range(5):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model,  split_train_loaders,split_test_loaders, optimizer, epoch_per_task, coreset_size, beta=1e-2, binary_labels = tasks)\n","    trends_1.append(trend)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9971631205673759, 0.9960822722820764]\n","Average Accuracy across 2 tasks: 99.66%\n","[0.9985815602836879, 0.9671890303623898, 0.9983991462113126]\n","Average Accuracy across 3 tasks: 98.81%\n","[0.9125295508274232, 0.9353574926542605, 0.9695837780149413, 0.9984894259818731]\n","Average Accuracy across 4 tasks: 95.40%\n","[0.9427895981087471, 0.9201762977473066, 0.9866595517609391, 0.9934541792547835, 0.994452849218356]\n","Average Accuracy across 5 tasks: 96.75%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9995271867612293, 0.9936336924583742]\n","Average Accuracy across 2 tasks: 99.66%\n","[0.9962174940898345, 0.9857982370225269, 0.9994663820704376]\n","Average Accuracy across 3 tasks: 99.38%\n","[0.9981087470449173, 0.9382957884427032, 0.9893276414087513, 0.9984894259818731]\n","Average Accuracy across 4 tasks: 98.11%\n","[0.9947990543735225, 0.8712047012732616, 0.9754535752401281, 0.9929506545820745, 0.9949571356530509]\n","Average Accuracy across 5 tasks: 96.59%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9995271867612293, 0.9916748285994124]\n","Average Accuracy across 2 tasks: 99.56%\n","[0.9971631205673759, 0.9862879529872673, 0.9978655282817502]\n","Average Accuracy across 3 tasks: 99.38%\n","[0.9971631205673759, 0.9740450538687562, 0.9194236926360726, 0.9979859013091642]\n","Average Accuracy across 4 tasks: 97.22%\n","[0.9215130023640662, 0.9515181194906954, 0.9925293489861259, 0.974320241691843, 0.9954614220877458]\n","Average Accuracy across 5 tasks: 96.71%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9995271867612293, 0.9931439764936337]\n","Average Accuracy across 2 tasks: 99.63%\n","[0.9995271867612293, 0.9794319294809011, 1.0]\n","Average Accuracy across 3 tasks: 99.30%\n","[0.9933806146572104, 0.9794319294809011, 0.9871931696905016, 0.9979859013091642]\n","Average Accuracy across 4 tasks: 98.95%\n","[0.9900709219858156, 0.8472086190009794, 0.964247598719317, 0.9884189325276939, 0.9924357034795764]\n","Average Accuracy across 5 tasks: 95.65%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9990543735224586, 0.9926542605288933]\n","Average Accuracy across 2 tasks: 99.59%\n","[0.9962174940898345, 0.9711067580803134, 0.9978655282817502]\n","Average Accuracy across 3 tasks: 98.84%\n","[0.9957446808510638, 0.9427032321253673, 0.9786552828175027, 0.9974823766364552]\n","Average Accuracy across 4 tasks: 97.86%\n","[0.9891252955082742, 0.930460333006856, 0.9695837780149413, 0.9909365558912386, 0.9959657085224407]\n","Average Accuracy across 5 tasks: 97.52%\n"]}],"source":["trends_2 = []\n","for i in range(5):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model,  split_train_loaders,split_test_loaders, optimizer, epoch_per_task, coreset_size, beta=1, binary_labels = tasks)\n","    trends_2.append(trend)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9995271867612293, 0.9715964740450539]\n","Average Accuracy across 2 tasks: 98.56%\n","[0.9990543735224586, 0.9686581782566112, 0.9898612593383138]\n","Average Accuracy across 3 tasks: 98.59%\n","[0.9990543735224586, 0.9637610186092067, 0.9866595517609391, 0.9939577039274925]\n","Average Accuracy across 4 tasks: 98.59%\n","[0.9995271867612293, 0.8839373163565132, 0.9807897545357525, 0.9894259818731118, 0.9788199697428139]\n","Average Accuracy across 5 tasks: 96.65%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9990543735224586, 0.9779627815866797]\n","Average Accuracy across 2 tasks: 98.85%\n","[0.9995271867612293, 0.9760039177277179, 0.9887940234791889]\n","Average Accuracy across 3 tasks: 98.81%\n","[0.9990543735224586, 0.9720861900097943, 0.9818569903948773, 0.9929506545820745]\n","Average Accuracy across 4 tasks: 98.65%\n","[0.9990543735224586, 0.9647404505386875, 0.9781216648879403, 0.9939577039274925, 0.9773071104387292]\n","Average Accuracy across 5 tasks: 98.26%\n","[0.9995271867612293]\n","Average Accuracy across 1 tasks: 99.95%\n","[0.9995271867612293, 0.970617042115573]\n","Average Accuracy across 2 tasks: 98.51%\n","[0.9995271867612293, 0.9662095984329089, 0.9925293489861259]\n","Average Accuracy across 3 tasks: 98.61%\n","[0.9995271867612293, 0.9686581782566112, 0.9935965848452508, 0.9939577039274925]\n","Average Accuracy across 4 tasks: 98.89%\n","[0.9985815602836879, 0.9524975514201763, 0.9909284951974386, 0.9879154078549849, 0.9803328290468987]\n","Average Accuracy across 5 tasks: 98.21%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9990543735224586, 0.9789422135161606]\n","Average Accuracy across 2 tasks: 98.90%\n","[0.9990543735224586, 0.960822722820764, 0.9866595517609391]\n","Average Accuracy across 3 tasks: 98.22%\n","[0.9990543735224586, 0.9725759059745348, 0.9930629669156884, 0.9954682779456193]\n","Average Accuracy across 4 tasks: 99.00%\n","[0.9990543735224586, 0.9333986287952988, 0.9871931696905016, 0.9803625377643505, 0.9762985375693394]\n","Average Accuracy across 5 tasks: 97.53%\n","[0.9985815602836879]\n","Average Accuracy across 1 tasks: 99.86%\n","[0.9995271867612293, 0.9662095984329089]\n","Average Accuracy across 2 tasks: 98.29%\n","[0.9990543735224586, 0.9583741429970617, 0.9957310565635006]\n","Average Accuracy across 3 tasks: 98.44%\n","[0.9990543735224586, 0.970617042115573, 0.9925293489861259, 0.9964753272910373]\n","Average Accuracy across 4 tasks: 98.97%\n","[0.9990543735224586, 0.9637610186092067, 0.9781216648879403, 0.9904330312185297, 0.9475542107917297]\n","Average Accuracy across 5 tasks: 97.58%\n"]}],"source":["\n","trends_3 = []\n","for i in range(5):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, split_train_loaders,split_test_loaders, optimizer, epoch_per_task, coreset_size, beta=1e2, binary_labels = tasks)\n","    trends_3.append(trend)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9849172576832153\n","Average Accuracy across 1 tasks: 99.95%\n","0.790303623898139\n","0\n","0.47355533790401566 raw_pred\n","0.030165484633569495 0.41939275220372196 0.011305380343249198 all\n","0.03078310694200783 beta\n","Average Accuracy across 2 tasks: 99.66%\n","0.7532550693703308\n","1\n","0.7572038420490929 raw_pred\n","0.41939275220372196 0.49348986125933836 0.5359570316743368 all\n","70.3784488137113 beta\n","Average Accuracy across 3 tasks: 99.48%\n","0.9025176233635447\n","2\n","0.3076535750251762 raw_pred\n","0.49348986125933836 0.19496475327291063 0.23992850820810221 all\n","142.49986889497907 beta\n","Average Accuracy across 4 tasks: 99.34%\n","0.7853756933938476\n","3\n","0.6666666666666666 raw_pred\n","0.49348986125933836 0.4292486132123048 0.15886910488091505 all\n","7.806231234471929 beta\n","Average Accuracy across 5 tasks: 97.64%\n","0.9733806146572104\n","Average Accuracy across 1 tasks: 99.95%\n","0.8158178256611166\n","0\n","0.4387855044074437 raw_pred\n","0.05323877068557925 0.3683643486777668 0.022407217512722184 all\n","0.06747246210619345 beta\n","Average Accuracy across 2 tasks: 99.42%\n","0.7606723585912486\n","1\n","0.7822838847385272 raw_pred\n","0.3683643486777668 0.4786552828175028 0.6560357811207798 all\n","152.3980422356817 beta\n","Average Accuracy across 3 tasks: 99.08%\n","0.9217019133937562\n","2\n","0.3756294058408862 raw_pred\n","0.4786552828175028 0.15659617321248764 0.07498040441187932 all\n","38.739860816756945 beta\n","Average Accuracy across 4 tasks: 98.70%\n","0.7073625819465457\n","3\n","0.64851235501765 raw_pred\n","0.4786552828175028 0.5852748361069087 0.11611428000609379 all\n","1.0913873278604704 beta\n","Average Accuracy across 5 tasks: 97.30%\n","0.9746572104018913\n","Average Accuracy across 1 tasks: 99.91%\n","0.8170421155729677\n","0\n","0.4152791380999021 raw_pred\n","0.0506855791962173 0.3659157688540646 0.03538016349768484 all\n","0.07596261299271731 beta\n","Average Accuracy across 2 tasks: 99.71%\n","0.7843116328708645\n","1\n","0.6990394877267876 raw_pred\n","0.3659157688540646 0.43137673425827106 0.26518126368773864 all\n","6.293339968616526 beta\n","Average Accuracy across 3 tasks: 99.54%\n","0.9093655589123868\n","2\n","0.3600201409869084 raw_pred\n","0.43137673425827106 0.1812688821752264 0.09971432160637334 all\n","25.077757285651575 beta\n","Average Accuracy across 4 tasks: 99.50%\n","0.7015128593040847\n","3\n","0.6641452344931922 raw_pred\n","0.43137673425827106 0.5969742813918306 0.15224568450383366 all\n","0.8842855930847834 beta\n","Average Accuracy across 5 tasks: 96.34%\n","0.983451536643026\n","Average Accuracy across 1 tasks: 99.91%\n","0.8092556317335946\n","0\n","0.5646425073457395 raw_pred\n","0.03309692671394804 0.3814887365328108 0.023959250325485303 all\n","0.05038134553538192 beta\n","Average Accuracy across 2 tasks: 99.68%\n","0.822145144076841\n","1\n","0.7572038420490929 raw_pred\n","0.3814887365328108 0.35570971184631794 0.5359570316743368 all\n","176.5811030671684 beta\n","Average Accuracy across 3 tasks: 99.50%\n","0.8689828801611279\n","2\n","0.35850956696878145 raw_pred\n","0.3814887365328108 0.2620342396777442 0.10245943624959257 all\n","7.720683197278597 beta\n","Average Accuracy across 4 tasks: 97.89%\n","0.7337367624810893\n","3\n","0.6374180534543621 raw_pred\n","0.3814887365328108 0.5325264750378214 0.09520818781326915 all\n","0.597973306082757 beta\n","Average Accuracy across 5 tasks: 97.59%\n","0.9565484633569739\n","Average Accuracy across 1 tasks: 99.91%\n","0.7649853085210578\n","0\n","0.5171400587659157 raw_pred\n","0.08690307328605229 0.4700293829578843 0.00940374686994602 all\n","0.03199703591615994 beta\n","Average Accuracy across 2 tasks: 99.73%\n","0.7594450373532552\n","1\n","0.7459978655282817 raw_pred\n","0.4700293829578843 0.4811099252934896 0.4800000045524971 all\n","75.10655616254927 beta\n","Average Accuracy across 3 tasks: 99.50%\n","0.9259818731117827\n","2\n","0.3947633434038268 raw_pred\n","0.4811099252934896 0.1480362537764346 0.05238803525840587 all\n","34.82144803460093 beta\n","Average Accuracy across 4 tasks: 99.18%\n","0.6841149773071104\n","3\n","0.6449823499747857 raw_pred\n","0.4811099252934896 0.6317700453857793 0.10906251614988013 all\n","0.6817255708046698 beta\n","Average Accuracy across 5 tasks: 95.83%\n"]}],"source":["trends_4 = []\n","for i in range(5):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_auto_vcl(model, \n","        split_train_loaders,\n","        split_test_loaders,\n","        optimizer, \n","        epoch_per_task, \n","        coreset_size,\n","        binary_labels = tasks,\n","        dor = True)\n","    trends_4.append(trend)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/html":["\n","<div id=\"altair-viz-0bc06e003d4a4a7e9a3f3027da42a8cc\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-0bc06e003d4a4a7e9a3f3027da42a8cc\") {\n","      outputDiv = document.getElementById(\"altair-viz-0bc06e003d4a4a7e9a3f3027da42a8cc\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 15, \"titleFontSize\": 20}, \"legend\": {\"labelFontSize\": 15, \"titleFontSize\": 15}, \"title\": {\"fontSize\": 24}}, \"data\": {\"name\": \"data-b1e580c65abae6aa1e5c5dfc6b5c2849\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Series\", \"legend\": {\"title\": \"Model\"}, \"scale\": {\"scheme\": \"category10\"}, \"sort\": [\"beta = 0.01\", \"beta = 1\", \"beta = 100\", \"AutoVCL\"], \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"# of tasks\", \"type\": \"quantitative\"}, {\"field\": \"Values\", \"type\": \"quantitative\"}, {\"field\": \"Series\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"values\": [0, 1, 2, 3, 4]}, \"field\": \"# of tasks\", \"title\": \"# tasks\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Values\", \"scale\": {\"domain\": [0.7, 1]}, \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Accuracy Trends in the Permuated MNIST Experiment\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-b1e580c65abae6aa1e5c5dfc6b5c2849\": [{\"# of tasks\": 0, \"Series\": \"beta = 0.01\", \"Values\": 0.9987706855791961}, {\"# of tasks\": 1, \"Series\": \"beta = 0.01\", \"Values\": 0.9961481466045201}, {\"# of tasks\": 2, \"Series\": \"beta = 0.01\", \"Values\": 0.9753215184462471}, {\"# of tasks\": 3, \"Series\": \"beta = 0.01\", \"Values\": 0.9321241404631252}, {\"# of tasks\": 4, \"Series\": \"beta = 0.01\", \"Values\": 0.9380687692972787}, {\"# of tasks\": 0, \"Series\": \"beta = 1\", \"Values\": 0.9990543735224586}, {\"# of tasks\": 1, \"Series\": \"beta = 1\", \"Values\": 0.9961988084735914}, {\"# of tasks\": 2, \"Series\": \"beta = 1\", \"Values\": 0.9914078232380408}, {\"# of tasks\": 3, \"Series\": \"beta = 1\", \"Values\": 0.9750688403153139}, {\"# of tasks\": 4, \"Series\": \"beta = 1\", \"Values\": 0.966427727139591}, {\"# of tasks\": 0, \"Series\": \"beta = 100\", \"Values\": 0.9990543735224586}, {\"# of tasks\": 1, \"Series\": \"beta = 100\", \"Values\": 0.9862018417024982}, {\"# of tasks\": 2, \"Series\": \"beta = 100\", \"Values\": 0.9853240862968645}, {\"# of tasks\": 3, \"Series\": \"beta = 100\", \"Values\": 0.988197906319669}, {\"# of tasks\": 4, \"Series\": \"beta = 100\", \"Values\": 0.9764467561103892}, {\"# of tasks\": 0, \"Series\": \"AutoVCL\", \"Values\": 0.9992434988179669}, {\"# of tasks\": 1, \"Series\": \"AutoVCL\", \"Values\": 0.996414978130651}, {\"# of tasks\": 2, \"Series\": \"AutoVCL\", \"Values\": 0.9942042707056766}, {\"# of tasks\": 3, \"Series\": \"AutoVCL\", \"Values\": 0.9892302822160672}, {\"# of tasks\": 4, \"Series\": \"AutoVCL\", \"Values\": 0.9693894187132981}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.Chart(...)"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","# def plot_trends(trends):\n","#     for t in trends:\n","#         plt.plot(range(len(t[0])),np.mean(t, axis = 0))\n","plot_trends([trends_1,trends_2,trends_3,trends_4,])"]},{"cell_type":"markdown","metadata":{},"source":["## Intentially alike\n"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["tasks = [(0, 1), (2, 3), (4, 5), (6, 7), (8, 9)]\n","split_alike_train_loaders, split_alike_test_loaders = create_split_dataloaders(mnist_trainset, mnist_testset, tasks, batch_size=batch_size)"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9981087470449173, 0.9936336924583742]\n","Average Accuracy across 2 tasks: 99.59%\n","[0.9947990543735225, 0.9809010773751224, 0.9989327641408752]\n","Average Accuracy across 3 tasks: 99.15%\n","[0.47801418439716314, 0.9005876591576886, 0.6947705442902882, 0.9984894259818731]\n","Average Accuracy across 4 tasks: 76.80%\n","[0.968321513002364, 0.7610186092066601, 0.9749199573105657, 0.9783484390735147, 0.9929399899142713]\n","Average Accuracy across 5 tasks: 93.51%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9990543735224586, 0.9946131243878551]\n","Average Accuracy across 2 tasks: 99.68%\n","[0.9976359338061466, 0.8712047012732616, 0.9983991462113126]\n","Average Accuracy across 3 tasks: 95.57%\n","[0.9952718676122931, 0.6214495592556317, 0.7630736392742796, 0.998992950654582]\n","Average Accuracy across 4 tasks: 84.47%\n","[0.9782505910165484, 0.7311459353574926, 0.983991462113127, 0.9838872104733132, 0.9954614220877458]\n","Average Accuracy across 5 tasks: 93.45%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9990543735224586, 0.9965719882468168]\n","Average Accuracy across 2 tasks: 99.78%\n","[0.9877068557919622, 0.9779627815866797, 0.9983991462113126]\n","Average Accuracy across 3 tasks: 98.80%\n","[0.992434988179669, 0.951028403525955, 0.9599786552828175, 0.9984894259818731]\n","Average Accuracy across 4 tasks: 97.55%\n","[0.9891252955082742, 0.9392752203721841, 0.9754535752401281, 0.9813695871097684, 0.9954614220877458]\n","Average Accuracy across 5 tasks: 97.61%\n","[0.9985815602836879]\n","Average Accuracy across 1 tasks: 99.86%\n","[0.9990543735224586, 0.9955925563173359]\n","Average Accuracy across 2 tasks: 99.73%\n","[0.9777777777777777, 0.9853085210577864, 0.9983991462113126]\n","Average Accuracy across 3 tasks: 98.72%\n","[0.9470449172576832, 0.935847208619001, 0.928495197438634, 0.998992950654582]\n","Average Accuracy across 4 tasks: 95.26%\n","[0.8085106382978723, 0.7845249755142018, 0.9754535752401281, 0.973816717019134, 0.9934442763489663]\n","Average Accuracy across 5 tasks: 90.72%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9995271867612293, 0.9941234084231146]\n","Average Accuracy across 2 tasks: 99.68%\n","[0.9962174940898345, 0.9789422135161606, 0.9994663820704376]\n","Average Accuracy across 3 tasks: 99.15%\n","[0.9513002364066194, 0.9603330068560235, 0.9183564567769477, 0.9979859013091642]\n","Average Accuracy across 4 tasks: 95.70%\n","[0.9418439716312057, 0.7664054848188051, 0.8548559231590181, 0.9848942598187311, 0.9939485627836612]\n","Average Accuracy across 5 tasks: 90.84%\n","[0.9985815602836879]\n","Average Accuracy across 1 tasks: 99.86%\n","[0.9995271867612293, 0.9955925563173359]\n","Average Accuracy across 2 tasks: 99.76%\n","[0.9929078014184397, 0.9818805093046034, 0.9994663820704376]\n","Average Accuracy across 3 tasks: 99.14%\n","[0.8321513002364066, 0.9647404505386875, 0.9946638207043756, 0.9969788519637462]\n","Average Accuracy across 4 tasks: 94.71%\n","[0.8302600472813239, 0.9529872673849168, 0.9850586979722519, 0.9763343403826787, 0.9959657085224407]\n","Average Accuracy across 5 tasks: 94.81%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9990543735224586, 0.9951028403525954]\n","Average Accuracy across 2 tasks: 99.71%\n","[0.9976359338061466, 0.9539666993143977, 0.9983991462113126]\n","Average Accuracy across 3 tasks: 98.33%\n","[0.9768321513002364, 0.9167482859941234, 0.9973319103521878, 0.9984894259818731]\n","Average Accuracy across 4 tasks: 97.24%\n","[0.9153664302600473, 0.7693437806072478, 0.9770544290288153, 0.9838872104733132, 0.9929399899142713]\n","Average Accuracy across 5 tasks: 92.77%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9981087470449173, 0.9946131243878551]\n","Average Accuracy across 2 tasks: 99.64%\n","[0.9877068557919622, 0.970617042115573, 0.9989327641408752]\n","Average Accuracy across 3 tasks: 98.58%\n","[0.7243498817966904, 0.9725759059745348, 0.9893276414087513, 0.9984894259818731]\n","Average Accuracy across 4 tasks: 92.12%\n","[0.9725768321513002, 0.9069539666993144, 0.964247598719317, 0.9934541792547835, 0.9924357034795764]\n","Average Accuracy across 5 tasks: 96.59%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9995271867612293, 0.9936336924583742]\n","Average Accuracy across 2 tasks: 99.66%\n","[0.9347517730496454, 0.8721841332027425, 0.9983991462113126]\n","Average Accuracy across 3 tasks: 93.51%\n","[0.9947990543735225, 0.8197845249755142, 0.983991462113127, 0.9984894259818731]\n","Average Accuracy across 4 tasks: 94.93%\n","[0.9479905437352246, 0.9226248775710089, 0.9882604055496265, 0.9889224572004028, 0.994452849218356]\n","Average Accuracy across 5 tasks: 96.85%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9995271867612293, 0.9951028403525954]\n","Average Accuracy across 2 tasks: 99.73%\n","[0.9702127659574468, 0.9319294809010774, 0.9978655282817502]\n","Average Accuracy across 3 tasks: 96.67%\n","[0.9484633569739953, 0.8898139079333987, 0.9663820704375667, 0.9984894259818731]\n","Average Accuracy across 4 tasks: 95.08%\n","[0.9219858156028369, 0.7433888344760039, 0.9711846318036286, 0.9833836858006042, 0.9924357034795764]\n","Average Accuracy across 5 tasks: 92.25%\n"]}],"source":["coreset_size = 0\n","trends_alike_1 = []\n","torch.manual_seed(SEED)\n","for i in range(10):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model,  split_alike_train_loaders,split_alike_test_loaders, optimizer, epoch_per_task, coreset_size, \n","    beta=1e-2, binary_labels = tasks)\n","    trends_alike_1.append(trend)"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9981087470449173, 0.9906953966699314]\n","Average Accuracy across 2 tasks: 99.44%\n","[0.9858156028368794, 0.9823702252693438, 0.9994663820704376]\n","Average Accuracy across 3 tasks: 98.92%\n","[0.9555555555555556, 0.910871694417238, 0.9823906083244397, 0.9979859013091642]\n","Average Accuracy across 4 tasks: 96.17%\n","[0.9801418439716312, 0.8344760039177277, 0.9893276414087513, 0.9813695871097684, 0.9914271306101866]\n","Average Accuracy across 5 tasks: 95.53%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9966903073286052, 0.9916748285994124]\n","Average Accuracy across 2 tasks: 99.42%\n","[0.9981087470449173, 0.9045053868756121, 0.9978655282817502]\n","Average Accuracy across 3 tasks: 96.68%\n","[0.9947990543735225, 0.8604309500489716, 0.9935965848452508, 0.9979859013091642]\n","Average Accuracy across 4 tasks: 96.17%\n","[0.9867612293144208, 0.8192948090107738, 0.987726787620064, 0.9919436052366566, 0.994452849218356]\n","Average Accuracy across 5 tasks: 95.60%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9990543735224586, 0.9970617042115573]\n","Average Accuracy across 2 tasks: 99.81%\n","[0.9981087470449173, 0.9353574926542605, 0.9983991462113126]\n","Average Accuracy across 3 tasks: 97.73%\n","[0.9933806146572104, 0.9280117531831538, 0.9898612593383138, 0.9974823766364552]\n","Average Accuracy across 4 tasks: 97.72%\n","[0.9919621749408983, 0.9427032321253673, 0.9893276414087513, 0.9899295065458208, 0.994452849218356]\n","Average Accuracy across 5 tasks: 98.17%\n","[0.9985815602836879]\n","Average Accuracy across 1 tasks: 99.86%\n","[0.9995271867612293, 0.9946131243878551]\n","Average Accuracy across 2 tasks: 99.71%\n","[0.9971631205673759, 0.9686581782566112, 0.9994663820704376]\n","Average Accuracy across 3 tasks: 98.84%\n","[0.9966903073286052, 0.9392752203721841, 0.9983991462113126, 0.998992950654582]\n","Average Accuracy across 4 tasks: 98.33%\n","[0.9905437352245863, 0.7688540646425074, 0.9850586979722519, 0.9773413897280967, 0.9838628340897629]\n","Average Accuracy across 5 tasks: 94.11%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9995271867612293, 0.9955925563173359]\n","Average Accuracy across 2 tasks: 99.76%\n","[0.9995271867612293, 0.9769833496571988, 0.9983991462113126]\n","Average Accuracy across 3 tasks: 99.16%\n","[0.9985815602836879, 0.9730656219392753, 0.9775880469583778, 0.9979859013091642]\n","Average Accuracy across 4 tasks: 98.68%\n","[0.9919621749408983, 0.807541625857003, 0.9663820704375667, 0.9899295065458208, 0.9939485627836612]\n","Average Accuracy across 5 tasks: 95.00%\n","[0.9985815602836879]\n","Average Accuracy across 1 tasks: 99.86%\n","[0.9995271867612293, 0.9946131243878551]\n","Average Accuracy across 2 tasks: 99.71%\n","[0.9995271867612293, 0.9666993143976493, 0.9978655282817502]\n","Average Accuracy across 3 tasks: 98.80%\n","[0.9711583924349881, 0.9760039177277179, 0.9797225186766275, 0.998992950654582]\n","Average Accuracy across 4 tasks: 98.15%\n","[0.9947990543735225, 0.9490695396669931, 0.9823906083244397, 0.9803625377643505, 0.9964699949571356]\n","Average Accuracy across 5 tasks: 98.06%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9990543735224586, 0.9941234084231146]\n","Average Accuracy across 2 tasks: 99.66%\n","[0.9990543735224586, 0.970617042115573, 0.9989327641408752]\n","Average Accuracy across 3 tasks: 98.95%\n","[0.9858156028368794, 0.9603330068560235, 0.9903948772678762, 0.998992950654582]\n","Average Accuracy across 4 tasks: 98.39%\n","[0.9895981087470449, 0.8428011753183153, 0.9834578441835645, 0.986404833836858, 0.9949571356530509]\n","Average Accuracy across 5 tasks: 95.94%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9990543735224586, 0.9931439764936337]\n","Average Accuracy across 2 tasks: 99.61%\n","[0.9952718676122931, 0.9794319294809011, 0.9994663820704376]\n","Average Accuracy across 3 tasks: 99.14%\n","[0.9602836879432625, 0.9764936336924583, 0.9983991462113126, 0.9974823766364552]\n","Average Accuracy across 4 tasks: 98.32%\n","[0.9966903073286052, 0.9030362389813908, 0.9765208110992529, 0.9843907351460222, 0.9954614220877458]\n","Average Accuracy across 5 tasks: 97.12%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9995271867612293, 0.9931439764936337]\n","Average Accuracy across 2 tasks: 99.63%\n","[0.9872340425531915, 0.8383937316356513, 0.9994663820704376]\n","Average Accuracy across 3 tasks: 94.17%\n","[0.9806146572104019, 0.9236043095004897, 0.9813233724653149, 0.998992950654582]\n","Average Accuracy across 4 tasks: 97.11%\n","[0.9687943262411347, 0.7149853085210578, 0.9829242262540021, 0.9853977844914401, 0.9949571356530509]\n","Average Accuracy across 5 tasks: 92.94%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9995271867612293, 0.9946131243878551]\n","Average Accuracy across 2 tasks: 99.71%\n","[0.9985815602836879, 0.955435847208619, 0.9994663820704376]\n","Average Accuracy across 3 tasks: 98.45%\n","[0.9971631205673759, 0.8506366307541626, 0.987726787620064, 0.9979859013091642]\n","Average Accuracy across 4 tasks: 95.84%\n","[0.9853427895981087, 0.6317335945151812, 0.9797225186766275, 0.9798590130916415, 0.9924357034795764]\n","Average Accuracy across 5 tasks: 91.38%\n"]}],"source":["coreset_size = 0\n","trends_alike_2 = []\n","torch.manual_seed(SEED)\n","for i in range(10):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model,  split_alike_train_loaders,split_alike_test_loaders, optimizer, epoch_per_task, coreset_size, \n","        beta=1, binary_labels = tasks)\n","    trends_alike_2.append(trend)"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9990543735224586, 0.970617042115573]\n","Average Accuracy across 2 tasks: 98.48%\n","[0.9985815602836879, 0.9671890303623898, 0.9919957310565635]\n","Average Accuracy across 3 tasks: 98.59%\n","[0.9990543735224586, 0.965230166503428, 0.987726787620064, 0.9959718026183283]\n","Average Accuracy across 4 tasks: 98.70%\n","[0.9985815602836879, 0.9559255631733594, 0.991462113127001, 0.9904330312185297, 0.967725668179526]\n","Average Accuracy across 5 tasks: 98.08%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9995271867612293, 0.9725759059745348]\n","Average Accuracy across 2 tasks: 98.61%\n","[0.9995271867612293, 0.975024485798237, 0.9930629669156884]\n","Average Accuracy across 3 tasks: 98.92%\n","[0.9995271867612293, 0.9725759059745348, 0.9925293489861259, 0.9929506545820745]\n","Average Accuracy across 4 tasks: 98.94%\n","[0.9990543735224586, 0.9573947110675808, 0.9903948772678762, 0.9788519637462235, 0.9757942511346445]\n","Average Accuracy across 5 tasks: 98.03%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9990543735224586, 0.9745347698334965]\n","Average Accuracy across 2 tasks: 98.68%\n","[0.9990543735224586, 0.9622918707149853, 0.9893276414087513]\n","Average Accuracy across 3 tasks: 98.36%\n","[0.9985815602836879, 0.9711067580803134, 0.9823906083244397, 0.9944612286002014]\n","Average Accuracy across 4 tasks: 98.66%\n","[0.9985815602836879, 0.9431929480901078, 0.9850586979722519, 0.9909365558912386, 0.9697428139183056]\n","Average Accuracy across 5 tasks: 97.75%\n","[0.9985815602836879]\n","Average Accuracy across 1 tasks: 99.86%\n","[0.9995271867612293, 0.980411361410382]\n","Average Accuracy across 2 tasks: 99.00%\n","[1.0, 0.9720861900097943, 0.9946638207043756]\n","Average Accuracy across 3 tasks: 98.89%\n","[0.9990543735224586, 0.9632713026444663, 0.9887940234791889, 0.986404833836858]\n","Average Accuracy across 4 tasks: 98.44%\n","[0.9990543735224586, 0.8868756121449559, 0.991462113127001, 0.9753272910372608, 0.9757942511346445]\n","Average Accuracy across 5 tasks: 96.57%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9990543735224586, 0.980411361410382]\n","Average Accuracy across 2 tasks: 98.97%\n","[0.9990543735224586, 0.9701273261508325, 0.9935965848452508]\n","Average Accuracy across 3 tasks: 98.76%\n","[0.9990543735224586, 0.9666993143976493, 0.9903948772678762, 0.9929506545820745]\n","Average Accuracy across 4 tasks: 98.73%\n","[0.9985815602836879, 0.8251714005876591, 0.9850586979722519, 0.9818731117824774, 0.9712556732223904]\n","Average Accuracy across 5 tasks: 95.24%\n","[0.9985815602836879]\n","Average Accuracy across 1 tasks: 99.86%\n","[0.9995271867612293, 0.9760039177277179]\n","Average Accuracy across 2 tasks: 98.78%\n","[0.9995271867612293, 0.9711067580803134, 0.991462113127001]\n","Average Accuracy across 3 tasks: 98.74%\n","[0.9971631205673759, 0.9559255631733594, 0.9669156883671292, 0.9899295065458208]\n","Average Accuracy across 4 tasks: 97.75%\n","[0.9971631205673759, 0.8648383937316356, 0.9834578441835645, 0.9632426988922457, 0.9737771053958648]\n","Average Accuracy across 5 tasks: 95.65%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9981087470449173, 0.9823702252693438]\n","Average Accuracy across 2 tasks: 99.02%\n","[0.9985815602836879, 0.9647404505386875, 0.9935965848452508]\n","Average Accuracy across 3 tasks: 98.56%\n","[0.9990543735224586, 0.9671890303623898, 0.9919957310565635, 0.9964753272910373]\n","Average Accuracy across 4 tasks: 98.87%\n","[0.9981087470449173, 0.9221351616062684, 0.9845250800426895, 0.9879154078549849, 0.9757942511346445]\n","Average Accuracy across 5 tasks: 97.37%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9990543735224586, 0.9774730656219393]\n","Average Accuracy across 2 tasks: 98.83%\n","[0.9990543735224586, 0.9794319294809011, 0.991462113127001]\n","Average Accuracy across 3 tasks: 99.00%\n","[0.9990543735224586, 0.9681684622918707, 0.9850586979722519, 0.9934541792547835]\n","Average Accuracy across 4 tasks: 98.64%\n","[0.9995271867612293, 0.905484818805093, 0.9866595517609391, 0.9879154078549849, 0.9757942511346445]\n","Average Accuracy across 5 tasks: 97.11%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9995271867612293, 0.9735553379040157]\n","Average Accuracy across 2 tasks: 98.65%\n","[0.9995271867612293, 0.9598432908912831, 0.9909284951974386]\n","Average Accuracy across 3 tasks: 98.34%\n","[0.9990543735224586, 0.9735553379040157, 0.9898612593383138, 0.9944612286002014]\n","Average Accuracy across 4 tasks: 98.92%\n","[0.9990543735224586, 0.951028403525955, 0.9685165421558164, 0.9889224572004028, 0.9697428139183056]\n","Average Accuracy across 5 tasks: 97.55%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9995271867612293, 0.9725759059745348]\n","Average Accuracy across 2 tasks: 98.61%\n","[0.9990543735224586, 0.9715964740450539, 0.9887940234791889]\n","Average Accuracy across 3 tasks: 98.65%\n","[0.9990543735224586, 0.9696376101860921, 0.9866595517609391, 0.9974823766364552]\n","Average Accuracy across 4 tasks: 98.82%\n","[0.9990543735224586, 0.9451518119490695, 0.9770544290288153, 0.9939577039274925, 0.9747856782652546]\n","Average Accuracy across 5 tasks: 97.80%\n"]}],"source":["coreset_size = 0\n","trends_alike_3 = []\n","torch.manual_seed(SEED)\n","for i in range(10):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model,  split_alike_train_loaders,split_alike_test_loaders,\n","     optimizer, epoch_per_task, coreset_size, \n","        beta=1e2, binary_labels = tasks)\n","    trends_alike_3.append(trend)"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.979243498817967\n","Average Accuracy across 1 tasks: 99.91%\n","0.8014201762977473\n","0\n","0.5264446620959843 raw_pred\n","0.041513002364065965 0.3971596474045054 0.011305380343249186 all\n","0.04194062916890819 beta\n","Average Accuracy across 2 tasks: 99.61%\n","0.8017075773745997\n","1\n","0.7038420490928495 raw_pred\n","0.3971596474045054 0.3965848452508005 0.28431466007599576 all\n","13.789796236598516 beta\n","Average Accuracy across 3 tasks: 99.45%\n","0.8942598187311178\n","2\n","0.3504531722054381 raw_pred\n","0.3971596474045054 0.21148036253776437 0.118254598002793 all\n","16.43370669344585 beta\n","Average Accuracy across 4 tasks: 97.45%\n","0.7869894099848713\n","3\n","0.6036308623298033 raw_pred\n","0.3971596474045054 0.42602118003025735 0.050816417179571506 all\n","1.224107441900368 beta\n","Average Accuracy across 5 tasks: 96.22%\n","0.9639243498817966\n","Average Accuracy across 1 tasks: 99.91%\n","0.8270812928501469\n","0\n","0.5186092066601371 raw_pred\n","0.0721513002364067 0.34583741429970627 0.009681441455361192 all\n","0.08789846877597776 beta\n","Average Accuracy across 2 tasks: 99.66%\n","0.8224653148345784\n","1\n","0.7139807897545357 raw_pred\n","0.34583741429970627 0.3550693703308432 0.32730838400317924 all\n","18.719994288068918 beta\n","Average Accuracy across 3 tasks: 98.64%\n","0.9170694864048338\n","2\n","0.3469284994964753 raw_pred\n","0.3550693703308432 0.16586102719033247 0.1258050422166272 all\n","18.199252118853316 beta\n","Average Accuracy across 4 tasks: 98.92%\n","0.7689359556227938\n","3\n","0.6565809379727685 raw_pred\n","0.3550693703308432 0.46212808875441236 0.13372913762305172 all\n","1.2784439044112672 beta\n","Average Accuracy across 5 tasks: 96.50%\n","0.9849172576832151\n","Average Accuracy across 1 tasks: 99.91%\n","0.7770812928501468\n","0\n","0.509794319294809 raw_pred\n","0.030165484633569717 0.44583741429970636 0.00812933485696285 all\n","0.023433093249817304 beta\n","Average Accuracy across 2 tasks: 99.64%\n","0.8010672358591249\n","1\n","0.7556029882604055 raw_pred\n","0.44583741429970636 0.39786552828175026 0.5279856618545608 all\n","201.29370405222926 beta\n","Average Accuracy across 3 tasks: 99.36%\n","0.9308660624370594\n","2\n","0.35297079556898286 raw_pred\n","0.44583741429970636 0.13826787512588123 0.11310440781424105 all\n","48.16103238723149 beta\n","Average Accuracy across 4 tasks: 99.02%\n","0.8270801815431165\n","3\n","0.6520423600605144 raw_pred\n","0.44583741429970636 0.34583963691376707 0.12355876341915184 all\n","7.83837727881816 beta\n","Average Accuracy across 5 tasks: 94.08%\n","0.9692198581560284\n","Average Accuracy across 1 tasks: 99.91%\n","0.7203721841332028\n","0\n","0.5102840352595495 raw_pred\n","0.061560283687943196 0.5592556317335944 0.00820869055473079 all\n","0.011016746849786544 beta\n","Average Accuracy across 2 tasks: 99.68%\n","0.7762540021344717\n","1\n","0.7395944503735326 raw_pred\n","0.5592556317335944 0.4474919957310566 0.44815921976527895 all\n","173.656651700422 beta\n","Average Accuracy across 3 tasks: 99.05%\n","0.9064451158106748\n","2\n","0.46424974823766363 raw_pred\n","0.5592556317335944 0.18710976837865045 0.013586553881826313 all\n","34.90837791447307 beta\n","Average Accuracy across 4 tasks: 98.92%\n","0.7361069087241553\n","3\n","0.7090267271810389 raw_pred\n","0.5592556317335944 0.5277861825516894 0.30587714044569847 all\n","22.355601449462007 beta\n","Average Accuracy across 5 tasks: 97.41%\n","0.9645862884160756\n","Average Accuracy across 1 tasks: 99.91%\n","0.8114593535749265\n","0\n","0.5244857982370226 raw_pred\n","0.07082742316784874 0.377081292850147 0.010875754091169348 all\n","0.06583965365525982 beta\n","Average Accuracy across 2 tasks: 99.63%\n","0.8288153681963715\n","1\n","0.7646744930629669 raw_pred\n","0.377081292850147 0.34236926360725706 0.5728502932686287 all\n","269.308021947599 beta\n","Average Accuracy across 3 tasks: 99.40%\n","0.9363041289023164\n","2\n","0.32628398791540786 raw_pred\n","0.377081292850147 0.1273917421953672 0.17862666828781087 all\n","51.673142716642666 beta\n","Average Accuracy across 4 tasks: 99.14%\n","0.7806354009077154\n","3\n","0.6374180534543621 raw_pred\n","0.377081292850147 0.4387291981845691 0.09520818781326915 all\n","1.362200796594045 beta\n","Average Accuracy across 5 tasks: 96.59%\n","0.9590070921985815\n","Average Accuracy across 1 tasks: 99.91%\n","0.7983349657198825\n","0\n","0.5088148873653281 raw_pred\n","0.08198581560283702 0.403330068560235 0.007972899063972737 all\n","0.055784633535678564 beta\n","Average Accuracy across 2 tasks: 99.80%\n","0.735325506937033\n","1\n","0.7475987193169691 raw_pred\n","0.403330068560235 0.529348986125934 0.48799590374304586 all\n","28.04839046836699 beta\n","Average Accuracy across 3 tasks: 99.52%\n","0.9116817724068479\n","2\n","0.37109768378650554 raw_pred\n","0.529348986125934 0.17663645518630422 0.08151386537959807 all\n","54.56392273556679 beta\n","Average Accuracy across 4 tasks: 99.48%\n","0.7733736762481089\n","3\n","0.6565809379727685 raw_pred\n","0.529348986125934 0.45325264750378214 0.13372913762305172 all\n","6.907197990773529 beta\n","Average Accuracy across 5 tasks: 98.11%\n","0.9807565011820332\n","Average Accuracy across 1 tasks: 99.91%\n","0.7929480901077375\n","0\n","0.4382957884427032 raw_pred\n","0.03848699763593366 0.41410381978452504 0.022622769956161172 all\n","0.038727885999239445 beta\n","Average Accuracy across 2 tasks: 99.59%\n","0.7593383137673426\n","1\n","0.7177161152614728 raw_pred\n","0.41410381978452504 0.48132337246531476 0.3439642188792202 all\n","12.793184546516919 beta\n","Average Accuracy across 3 tasks: 99.37%\n","0.9226082578046325\n","2\n","0.36706948640483383 raw_pred\n","0.48132337246531476 0.15478348439073497 0.08775260044695048 all\n","45.4119294086468 beta\n","Average Accuracy across 4 tasks: 98.77%\n","0.8015128593040848\n","3\n","0.6303580433686334 raw_pred\n","0.48132337246531476 0.39697428139183044 0.08372038084119639 all\n","4.70194871253115 beta\n","Average Accuracy across 5 tasks: 97.21%\n","0.957966903073286\n","Average Accuracy across 1 tasks: 99.95%\n","0.8011753183153771\n","0\n","0.5117531831537708 raw_pred\n","0.08406619385342795 0.3976493633692457 0.008451395963840879 all\n","0.06018287156092516 beta\n","Average Accuracy across 2 tasks: 99.64%\n","0.7438100320170757\n","1\n","0.7870864461045891 raw_pred\n","0.3976493633692457 0.5123799359658485 0.6773738081453834 all\n","178.06269500278069 beta\n","Average Accuracy across 3 tasks: 98.97%\n","0.8749748237663646\n","2\n","0.40584088620342396 raw_pred\n","0.5123799359658485 0.2500503524672708 0.04241884619956286 all\n","16.557460162175275 beta\n","Average Accuracy across 4 tasks: 98.63%\n","0.7156328794755422\n","3\n","0.6722138174483107 raw_pred\n","0.5123799359658485 0.5687342410489156 0.17426113189150272 all\n","2.962288190671072 beta\n","Average Accuracy across 5 tasks: 97.59%\n","0.9591962174940898\n","Average Accuracy across 1 tasks: 99.95%\n","0.8008814887365329\n","0\n","0.4520078354554358 raw_pred\n","0.08160756501182043 0.39823702252693427 0.017290493640564515 all\n","0.06348105628073412 beta\n","Average Accuracy across 2 tasks: 99.66%\n","0.7513340448239061\n","1\n","0.7294557097118464 raw_pred\n","0.39823702252693427 0.4973319103521878 0.39869974057803836 all\n","15.791355514119001 beta\n","Average Accuracy across 3 tasks: 99.36%\n","0.8856998992950654\n","2\n","0.39375629405840884 raw_pred\n","0.4973319103521878 0.22860020140986914 0.05339696668648663 all\n","19.431874749802436 beta\n","Average Accuracy across 4 tasks: 96.47%\n","0.7124054462934947\n","3\n","0.681290973272819 raw_pred\n","0.4973319103521878 0.5751891074130107 0.20194525781898273 all\n","3.1358280678463863 beta\n","Average Accuracy across 5 tasks: 98.61%\n","0.9721513002364066\n","Average Accuracy across 1 tasks: 100.00%\n","0.8056807051909892\n","0\n","0.435847208619001 raw_pred\n","0.055697399527186775 0.38863858961802156 0.023731272930324586 all\n","0.0579642647430365 beta\n","Average Accuracy across 2 tasks: 99.68%\n","0.8159551760939168\n","1\n","0.7732123799359658 raw_pred\n","0.38863858961802156 0.36808964781216647 0.6140213396298738 all\n","345.36722870792204 beta\n","Average Accuracy across 3 tasks: 99.34%\n","0.9011581067472306\n","2\n","0.37915407854984895 raw_pred\n","0.38863858961802156 0.19768378650553875 0.0702352306970874 all\n","11.085623771451136 beta\n","Average Accuracy across 4 tasks: 98.51%\n","0.656732223903177\n","3\n","0.649016641452345 raw_pred\n","0.38863858961802156 0.686535552193646 0.11715341049501429 all\n","0.18924560035997956 beta\n","Average Accuracy across 5 tasks: 97.76%\n"]}],"source":["trends_alike_4 = []\n","alike_betas = []\n","torch.manual_seed(SEED)\n","for i in range(10):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend, alike_beta = run_auto_vcl(model, \n","        split_alike_train_loaders,\n","        split_alike_test_loaders,\n","        optimizer, \n","        epoch_per_task, \n","        coreset_size,\n","        binary_labels = tasks,\n","        return_betas = True)\n","    trends_alike_4.append(trend)\n","    alike_betas.append(alike_beta)"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[],"source":["model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","train(model, split_alike_train_loaders[0], optimizer, 1, device, 1, 0, binary_label=[0,1])"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"data":{"text/plain":["(0.021845142241206154, 0.43927522037218414)"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["test(model, split_alike_test_loaders[1], device,task_id=0, binary_label=[2,1])"]},{"cell_type":"code","execution_count":170,"metadata":{},"outputs":[{"data":{"text/plain":["7"]},"execution_count":170,"metadata":{},"output_type":"execute_result"}],"source":["split_alike_train_loaders[1].dataset[2][1]"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"data":{"text/html":["\n","<div id=\"altair-viz-56423c0d2a704535add2d6bef4115c73\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-56423c0d2a704535add2d6bef4115c73\") {\n","      outputDiv = document.getElementById(\"altair-viz-56423c0d2a704535add2d6bef4115c73\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 15, \"titleFontSize\": 20}, \"legend\": {\"labelFontSize\": 15, \"titleFontSize\": 15}, \"title\": {\"fontSize\": 24}}, \"data\": {\"name\": \"data-11b5466a6117568043ddaafede22c99d\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Series\", \"legend\": {\"title\": \"Model\"}, \"scale\": {\"scheme\": \"category10\"}, \"sort\": [\"beta = 0.01\", \"beta = 1\", \"beta = 100\", \"AutoVCL\"], \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"# of tasks\", \"type\": \"quantitative\"}, {\"field\": \"Values\", \"type\": \"quantitative\"}, {\"field\": \"Series\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"values\": [0, 1, 2, 3, 4]}, \"field\": \"# of tasks\", \"title\": \"# tasks\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Values\", \"scale\": {\"domain\": [0.9, 1]}, \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Accuracy Trends in the Permuated MNIST Experiment\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-11b5466a6117568043ddaafede22c99d\": [{\"# of tasks\": 0, \"Series\": \"beta = 0.01\", \"Values\": 0.9989598108747044}, {\"# of tasks\": 1, \"Series\": \"beta = 0.01\", \"Values\": 0.9969561779463418}, {\"# of tasks\": 2, \"Series\": \"beta = 0.01\", \"Values\": 0.9776302985757075}, {\"# of tasks\": 3, \"Series\": \"beta = 0.01\", \"Values\": 0.9238457364979281}, {\"# of tasks\": 4, \"Series\": \"beta = 0.01\", \"Values\": 0.9394032920214859}, {\"# of tasks\": 0, \"Series\": \"beta = 1\", \"Values\": 0.9989598108747044}, {\"# of tasks\": 1, \"Series\": \"beta = 1\", \"Values\": 0.9964436664559615}, {\"# of tasks\": 2, \"Series\": \"beta = 1\", \"Values\": 0.9808546318672928}, {\"# of tasks\": 3, \"Series\": \"beta = 1\", \"Values\": 0.9748762950182487}, {\"# of tasks\": 4, \"Series\": \"beta = 1\", \"Values\": 0.953865686037396}, {\"# of tasks\": 0, \"Series\": \"beta = 100\", \"Values\": 0.9989598108747044}, {\"# of tasks\": 1, \"Series\": \"beta = 100\", \"Values\": 0.987624553409141}, {\"# of tasks\": 2, \"Series\": \"beta = 100\", \"Values\": 0.9868096685239962}, {\"# of tasks\": 3, \"Series\": \"beta = 100\", \"Values\": 0.9864720075127089}, {\"# of tasks\": 4, \"Series\": \"beta = 100\", \"Values\": 0.9711438477495674}, {\"# of tasks\": 0, \"Series\": \"AutoVCL\", \"Values\": 0.9992434988179669}, {\"# of tasks\": 1, \"Series\": \"AutoVCL\", \"Values\": 0.9965956520631745}, {\"# of tasks\": 2, \"Series\": \"AutoVCL\", \"Values\": 0.9924514340774335}, {\"# of tasks\": 3, \"Series\": \"AutoVCL\", \"Values\": 0.9853155610458131}, {\"# of tasks\": 4, \"Series\": \"AutoVCL\", \"Values\": 0.9700886288510688}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.Chart(...)"]},"metadata":{},"output_type":"display_data"}],"source":["plot_trends([trends_alike_1, trends_alike_2, trends_alike_3, trends_alike_4], lower = 0.9)"]},{"cell_type":"markdown","metadata":{},"source":["## different difficulties"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["transform_cifar = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=1), # Convert image to grayscale\n","    transforms.Resize((28, 28)),\n","    transforms.ToTensor(), \n","    transforms.Normalize((0.5,), (0.5,))])\n","\n","# Load the CIFAR-10 training dataset with the defined transform\n","cifar_train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_cifar)\n","\n","# Load the CIFAR-10 test dataset with the defined transform\n","cifar_test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar)\n"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["tasks = [(0,1),(2,3),(4,5),(6,7),(8,9)]\n","mixed_tasks = [tasks[i//2] for i in range(len(tasks)*2)]"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["torch.manual_seed(SEED)\n","mnist_train_loaders, mnist_test_loaders = \\\n","    create_split_dataloaders(mnist_trainset, mnist_testset, tasks, batch_size=batch_size)\n","cifar_train_loaders, cifar_test_loaders = \\\n","    create_split_dataloaders(cifar_train_dataset, cifar_test_dataset, tasks, batch_size=batch_size)"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["mixed_train_loaders = [mnist_train_loaders, cifar_train_loaders]\n","mixed_test_loaders = [mnist_test_loaders, cifar_test_loaders]\n","\n","mixed_train_loaders = [mixed_train_loaders[i%2][i//2] for i in range(len(mixed_tasks))]\n","mixed_test_loaders = [mixed_test_loaders[i%2][i//2] for i in range(len(mixed_tasks))]"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9981087470449173, 0.867]\n","Average Accuracy across 2 tasks: 93.26%\n","[0.9990543735224586, 0.8065, 0.9946131243878551]\n","Average Accuracy across 3 tasks: 93.34%\n","[0.9030732860520094, 0.763, 0.9760039177277179, 0.712]\n","Average Accuracy across 4 tasks: 83.85%\n","[0.9375886524822695, 0.761, 0.8413320274240941, 0.652, 0.9983991462113126]\n","Average Accuracy across 5 tasks: 83.81%\n","[0.9687943262411347, 0.688, 0.8545543584720862, 0.6565, 0.9946638207043756, 0.764]\n","Average Accuracy across 6 tasks: 82.11%\n","[0.7456264775413711, 0.5765, 0.9030362389813908, 0.6185, 0.884204909284952, 0.7135, 0.9979859013091642]\n","Average Accuracy across 7 tasks: 77.71%\n","[0.8803782505910166, 0.6765, 0.8677766895200784, 0.613, 0.8324439701173959, 0.692, 0.9773413897280967, 0.8595]\n","Average Accuracy across 8 tasks: 79.99%\n","[0.9739952718676123, 0.696, 0.7541625857002938, 0.617, 0.9583778014941302, 0.6445, 0.9521651560926485, 0.7915, 0.9959657085224407]\n","Average Accuracy across 9 tasks: 82.04%\n","[0.9706855791962175, 0.713, 0.8315377081292851, 0.632, 0.871931696905016, 0.6045, 0.877643504531722, 0.7025, 0.9490670700958144, 0.837]\n","Average Accuracy across 10 tasks: 79.90%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9971631205673759, 0.8725]\n","Average Accuracy across 2 tasks: 93.48%\n","[0.9990543735224586, 0.822, 0.9951028403525954]\n","Average Accuracy across 3 tasks: 93.87%\n","[0.9858156028368794, 0.762, 0.9818805093046034, 0.7215]\n","Average Accuracy across 4 tasks: 86.28%\n","[0.9957446808510638, 0.6515, 0.8741429970617042, 0.638, 0.9989327641408752]\n","Average Accuracy across 5 tasks: 83.17%\n","[0.9914893617021276, 0.693, 0.9118511263467189, 0.6205, 0.9855923159018143, 0.7625]\n","Average Accuracy across 6 tasks: 82.75%\n","[0.9801418439716312, 0.6385, 0.7037218413320274, 0.5825, 0.9087513340448239, 0.7365, 0.9984894259818731]\n","Average Accuracy across 7 tasks: 79.27%\n","[0.9560283687943263, 0.665, 0.7335945151811949, 0.565, 0.8943436499466382, 0.675, 0.9924471299093656, 0.8675]\n","Average Accuracy across 8 tasks: 79.36%\n","[0.956501182033097, 0.6835, 0.7056807051909892, 0.5835, 0.9386339381003201, 0.6505, 0.9013091641490433, 0.8055, 0.9959657085224407]\n","Average Accuracy across 9 tasks: 80.23%\n","[0.9092198581560283, 0.6875, 0.6057786483839374, 0.5675, 0.8601921024546425, 0.624, 0.9073514602215509, 0.792, 0.9641956631366616, 0.836]\n","Average Accuracy across 10 tasks: 77.54%\n","[0.9976359338061466]\n","Average Accuracy across 1 tasks: 99.76%\n","[0.9962174940898345, 0.8695]\n","Average Accuracy across 2 tasks: 93.29%\n","[0.9971631205673759, 0.779, 0.9955925563173359]\n","Average Accuracy across 3 tasks: 92.39%\n","[0.9976359338061466, 0.786, 0.9789422135161606, 0.7145]\n","Average Accuracy across 4 tasks: 86.93%\n","[0.9522458628841608, 0.714, 0.954456415279138, 0.6485, 0.9983991462113126]\n","Average Accuracy across 5 tasks: 85.35%\n","[0.8170212765957446, 0.6655, 0.8486777668952008, 0.648, 0.9919957310565635, 0.775]\n","Average Accuracy across 6 tasks: 79.10%\n","[0.4595744680851064, 0.509, 0.8428011753183153, 0.579, 0.5667022411953042, 0.6785, 0.9984894259818731]\n","Average Accuracy across 7 tasks: 66.20%\n","[0.8742316784869977, 0.631, 0.8805093046033301, 0.585, 0.7465314834578441, 0.686, 0.9874118831822759, 0.858]\n","Average Accuracy across 8 tasks: 78.11%\n","[0.3607565011820331, 0.6285, 0.722820763956905, 0.5765, 0.7748132337246532, 0.6265, 0.6742195367573011, 0.813, 0.9924357034795764]\n","Average Accuracy across 9 tasks: 68.55%\n","[0.7862884160756501, 0.6595, 0.5602350636630754, 0.636, 0.6905016008537886, 0.638, 0.8947633434038268, 0.746, 0.8638426626323752, 0.8475]\n","Average Accuracy across 10 tasks: 73.23%\n","[0.9985815602836879]\n","Average Accuracy across 1 tasks: 99.86%\n","[0.9976359338061466, 0.8525]\n","Average Accuracy across 2 tasks: 92.51%\n","[0.9957446808510638, 0.782, 0.9916748285994124]\n","Average Accuracy across 3 tasks: 92.31%\n","[0.9635933806146572, 0.729, 0.984818805093046, 0.709]\n","Average Accuracy across 4 tasks: 84.66%\n","[0.8973995271867612, 0.708, 0.8237022526934378, 0.697, 0.9994663820704376]\n","Average Accuracy across 5 tasks: 82.51%\n","[0.9962174940898345, 0.687, 0.9221351616062684, 0.6625, 0.9706510138740662, 0.779]\n","Average Accuracy across 6 tasks: 83.63%\n","[0.6661938534278959, 0.5855, 0.5675808031341821, 0.658, 0.5197438633938101, 0.7185, 0.9974823766364552]\n","Average Accuracy across 7 tasks: 67.33%\n","[0.9659574468085106, 0.638, 0.7321253672869735, 0.588, 0.7011739594450374, 0.6825, 0.9884189325276939, 0.871]\n","Average Accuracy across 8 tasks: 77.09%\n","[0.75177304964539, 0.594, 0.718413320274241, 0.6225, 0.9455709711846318, 0.608, 0.8962739174219537, 0.8315, 0.9954614220877458]\n","Average Accuracy across 9 tasks: 77.37%\n","[0.7981087470449173, 0.7025, 0.7639569049951028, 0.624, 0.8996798292422625, 0.6005, 0.8705941591137966, 0.7865, 0.989409984871407, 0.8355]\n","Average Accuracy across 10 tasks: 78.71%\n","[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9990543735224586, 0.8695]\n","Average Accuracy across 2 tasks: 93.43%\n","[0.9721040189125295, 0.704, 0.9955925563173359]\n","Average Accuracy across 3 tasks: 89.06%\n","[0.8803782505910166, 0.7655, 0.9853085210577864, 0.7225]\n","Average Accuracy across 4 tasks: 83.84%\n","[0.992434988179669, 0.7085, 0.9647404505386875, 0.666, 0.9994663820704376]\n","Average Accuracy across 5 tasks: 86.62%\n","[0.9943262411347518, 0.651, 0.8971596474045054, 0.6535, 0.9903948772678762, 0.7705]\n","Average Accuracy across 6 tasks: 82.61%\n","[0.9938534278959811, 0.592, 0.8878550440744368, 0.6445, 0.544290288153682, 0.724, 0.998992950654582]\n","Average Accuracy across 7 tasks: 76.94%\n","[0.9773049645390071, 0.6745, 0.9490695396669931, 0.562, 0.8986125933831377, 0.691, 0.9889224572004028, 0.8595]\n","Average Accuracy across 8 tasks: 82.51%\n","[0.9423167848699764, 0.66, 0.8192948090107738, 0.5345, 0.7678762006403416, 0.651, 0.9667673716012085, 0.8195, 0.994452849218356]\n","Average Accuracy across 9 tasks: 79.51%\n","[0.9583924349881797, 0.7365, 0.8594515181194907, 0.641, 0.5971184631803629, 0.681, 0.9788519637462235, 0.7755, 0.9818456883509834, 0.821]\n","Average Accuracy across 10 tasks: 80.31%\n"]}],"source":["coreset_size= 0\n","torch.manual_seed(SEED)\n","mixed_trends_1 = []\n","for i in range(5):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(mixed_tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, mixed_train_loaders,mixed_test_loaders, optimizer, epoch_per_task, coreset_size, beta=1e-2, binary_labels = mixed_tasks)\n","    mixed_trends_1.append(trend)"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.9990543735224586]\n","Average Accuracy across 1 tasks: 99.91%\n","[0.9985815602836879, 0.867]\n","Average Accuracy across 2 tasks: 93.28%\n","[0.9990543735224586, 0.8415, 0.9931439764936337]\n","Average Accuracy across 3 tasks: 94.46%\n","[0.9167848699763593, 0.8105, 0.9760039177277179, 0.6975]\n","Average Accuracy across 4 tasks: 85.02%\n","[0.9787234042553191, 0.7925, 0.9138099902056807, 0.6735, 0.9983991462113126]\n","Average Accuracy across 5 tasks: 87.14%\n","[0.9229314420803783, 0.7225, 0.8594515181194907, 0.6695, 0.996264674493063, 0.7765]\n","Average Accuracy across 6 tasks: 82.45%\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[75], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m MFVI_NN(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, [\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m], \u001b[38;5;241m2\u001b[39m, num_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(mixed_tasks))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m trend \u001b[38;5;241m=\u001b[39m \u001b[43mrun_vcl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmixed_train_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmixed_test_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoreset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmixed_tasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m mixed_trends_2\u001b[38;5;241m.\u001b[39mappend(trend)\n","Cell \u001b[0;32mIn[47], line 23\u001b[0m, in \u001b[0;36mrun_vcl\u001b[0;34m(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta, binary_labels)\u001b[0m\n\u001b[1;32m     21\u001b[0m         model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# for prediction\u001b[39;00m\n","Cell \u001b[0;32mIn[17], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, trainloader, optimizer, epoch, device, kl_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, task_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, binary_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m      6\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the images\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/functional.py:170\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    169\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n\u001b[0;32m--> 170\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_num_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m    172\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["torch.manual_seed(SEED)\n","mixed_trends_2 = []\n","for i in range(5):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(mixed_tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, mixed_train_loaders,mixed_test_loaders, optimizer, epoch_per_task, coreset_size, beta=1, binary_labels = mixed_tasks)\n","    mixed_trends_2.append(trend)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'mixed_tasks' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[41], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m mixed_trends_3 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     model \u001b[38;5;241m=\u001b[39m MFVI_NN(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, [\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m], \u001b[38;5;241m2\u001b[39m, num_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mmixed_tasks\u001b[49m))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m      6\u001b[0m     trend \u001b[38;5;241m=\u001b[39m run_vcl(model, mixed_train_loaders,mixed_test_loaders, optimizer, epoch_per_task, coreset_size, \n\u001b[1;32m      7\u001b[0m         beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, binary_labels \u001b[38;5;241m=\u001b[39m mixed_tasks)\n","\u001b[0;31mNameError\u001b[0m: name 'mixed_tasks' is not defined"]}],"source":["torch.manual_seed(SEED)\n","mixed_trends_3 = []\n","for i in range(5):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(mixed_tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, mixed_train_loaders,mixed_test_loaders, optimizer, epoch_per_task, coreset_size, \n","        beta=1e2, binary_labels = mixed_tasks)\n","    mixed_trends_3.append(trend)"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9734278959810874\n","Average Accuracy across 1 tasks: 99.91%\n","0.7145499999999999\n","0\n","0.5635 raw_pred\n","0.05314420803782527 0.5709000000000002 0.023430667673670316 all\n","0.01053657597065627 beta\n","Average Accuracy across 2 tasks: 93.28%\n","0.7502938295788442\n","1\n","0.4720861900097943 raw_pred\n","0.5709000000000002 0.4994123408423117 0.011638570781885236 all\n","2.1503290384782243 beta\n","Average Accuracy across 3 tasks: 95.12%\n","0.5905000000000001\n","2\n","0.502 raw_pred\n","0.5709000000000002 0.8189999999999997 0.006964089177762089 all\n","0.1085066503231236 beta\n","Average Accuracy across 4 tasks: 83.65%\n","0.7350586979722518\n","3\n","0.4823906083244397 raw_pred\n","0.8189999999999997 0.5298826040554965 0.00949159044096126 all\n","15.647175207027473 beta\n","Average Accuracy across 5 tasks: 87.70%\n","0.6059\n","4\n","0.414 raw_pred\n","0.8189999999999997 0.7882 0.03626371637464836 all\n","1.8546196867506108 beta\n","Average Accuracy across 6 tasks: 83.59%\n","0.9106747230614299\n","5\n","0.4405840886203424 raw_pred\n","0.8189999999999997 0.17865055387714013 0.021632643504852576 all\n","444.55792686667263 beta\n","Average Accuracy across 7 tasks: 86.02%\n","0.66055\n","6\n","0.4575 raw_pred\n","0.8189999999999997 0.6789000000000001 0.015519756578408886 all\n","4.192557487853496 beta\n","Average Accuracy across 8 tasks: 80.37%\n","0.7666666666666666\n","7\n","0.5173978819969742 raw_pred\n","0.8189999999999997 0.4666666666666668 0.0094519026845695 all\n","27.998898364623624 beta\n","Average Accuracy across 9 tasks: 82.82%\n","0.7019\n","8\n","0.5695 raw_pred\n","0.8189999999999997 0.5962000000000001 0.026339319625283387 all\n","9.921041778645769 beta\n","Average Accuracy across 10 tasks: 84.01%\n","0.9866666666666667\n","Average Accuracy across 1 tasks: 99.91%\n","0.7104999999999999\n","0\n","0.579 raw_pred\n","0.026666666666666616 0.5790000000000002 0.03167622837905637 all\n","0.008267450059421769 beta\n","Average Accuracy across 2 tasks: 93.43%\n","0.842458374142997\n","1\n","0.4828599412340842 raw_pred\n","0.5790000000000002 0.3150832517140061 0.009403746869946038 all\n","12.396011789813619 beta\n","Average Accuracy across 3 tasks: 95.02%\n","0.5760000000000001\n","2\n","0.495 raw_pred\n","0.5790000000000002 0.8479999999999999 0.007391541344281971 all\n","0.08985994850420555 beta\n","Average Accuracy across 4 tasks: 85.48%\n","0.7803628601921024\n","3\n","0.4551760939167556 raw_pred\n","0.8479999999999999 0.4392742796157951 0.016246116075497672 all\n","50.10572446277834 beta\n","Average Accuracy across 5 tasks: 87.50%\n","0.6178000000000001\n","4\n","0.417 raw_pred\n","0.8479999999999999 0.7643999999999997 0.03422415769239588 all\n","2.9600335312250077 beta\n","Average Accuracy across 6 tasks: 83.42%\n","0.8961732124874118\n","5\n","0.4511581067472306 raw_pred\n","0.8479999999999999 0.20765357502517645 0.017581638885328682 all\n","428.2646769027691 beta\n","Average Accuracy across 7 tasks: 85.59%\n","0.6613\n","6\n","0.5205 raw_pred\n","0.8479999999999999 0.6774 0.010050813883473748 all\n","5.27962717453358 beta\n","Average Accuracy across 8 tasks: 82.14%\n","0.727634896621281\n","7\n","0.5037821482602118 raw_pred\n","0.8479999999999999 0.544730206757438 0.007214963454548039 all\n","17.45577063664716 beta\n","Average Accuracy across 9 tasks: 83.42%\n","0.6986\n","8\n","0.5355 raw_pred\n","0.8479999999999999 0.6028 0.013519639645969627 all\n","10.836238587849303 beta\n","Average Accuracy across 10 tasks: 85.21%\n","0.9629787234042555\n","Average Accuracy across 1 tasks: 99.91%\n","0.7045999999999999\n","0\n","0.558 raw_pred\n","0.074042553191489 0.5908000000000002 0.0210413470204683 all\n","0.010402449133884075 beta\n","Average Accuracy across 2 tasks: 93.58%\n","0.7632713026444662\n","1\n","0.5205680705190989 raw_pred\n","0.5908000000000002 0.4734573947110676 0.010064368676968296 all\n","3.2331652016174712 beta\n","Average Accuracy across 3 tasks: 88.22%\n","0.57845\n","2\n","0.535 raw_pred\n","0.5908000000000002 0.8431 0.013386917827664793 all\n","0.11075100383499312 beta\n","Average Accuracy across 4 tasks: 79.64%\n","0.8135005336179295\n","3\n","0.46691568836712916 raw_pred\n","0.8431 0.372998932764141 0.012890202282306392 all\n","85.49979591281009 beta\n","Average Accuracy across 5 tasks: 80.95%\n","0.6194\n","4\n","0.462 raw_pred\n","0.8431 0.7612000000000001 0.014202961372691125 all\n","2.423326020015278 beta\n","Average Accuracy across 6 tasks: 79.99%\n","0.9093152064451159\n","5\n","0.5055387713997986 raw_pred\n","0.8431 0.18136958710976825 0.007471020764623208 all\n","475.122650069033 beta\n","Average Accuracy across 7 tasks: 83.35%\n","0.66035\n","6\n","0.5105 raw_pred\n","0.8431 0.6793 0.008243930064601557 all\n","4.877257893309805 beta\n","Average Accuracy across 8 tasks: 80.04%\n","0.7433182047402924\n","7\n","0.5088250126071608 raw_pred\n","0.8431 0.5133635905194152 0.007974500901544418 all\n","22.430742073323746 beta\n","Average Accuracy across 9 tasks: 86.31%\n","0.69975\n","8\n","0.4765 raw_pred\n","0.8431 0.6005 0.01066569269471 all\n","10.305350581240774 beta\n","Average Accuracy across 10 tasks: 85.65%\n","0.9779196217494089\n","Average Accuracy across 1 tasks: 99.91%\n","0.7079500000000001\n","0\n","0.5875 raw_pred\n","0.04416075650118212 0.5840999999999998 0.03732688734412948 all\n","0.009762264614033327 beta\n","Average Accuracy across 2 tasks: 93.43%\n","0.7881978452497551\n","1\n","0.4990205680705191 raw_pred\n","0.5840999999999998 0.4236043095004898 0.006824343742548453 all\n","4.669604910145933 beta\n","Average Accuracy across 3 tasks: 93.76%\n","0.5896999999999999\n","2\n","0.497 raw_pred\n","0.5840999999999998 0.8206000000000002 0.0071037737243887815 all\n","0.12089688049576741 beta\n","Average Accuracy across 4 tasks: 79.47%\n","0.7672892209178228\n","3\n","0.5389541088580576 raw_pred\n","0.8206000000000002 0.4654215581643544 0.014472627098709528 all\n","30.102618572957766 beta\n","Average Accuracy across 5 tasks: 86.61%\n","0.6177999999999999\n","4\n","0.53 raw_pred\n","0.8206000000000002 0.7644000000000002 0.012128434984274248 all\n","1.8763495176709504 beta\n","Average Accuracy across 6 tasks: 83.91%\n","0.906394763343404\n","5\n","0.4566968781470292 raw_pred\n","0.8206000000000002 0.18721047331319207 0.015767092279575727 all\n","395.02672285160367 beta\n","Average Accuracy across 7 tasks: 85.94%\n","0.6496\n","6\n","0.4685 raw_pred\n","0.8206000000000002 0.7008000000000001 0.012493186263129542 all\n","3.381993316837349 beta\n","Average Accuracy across 8 tasks: 80.08%\n","0.6851739788199698\n","7\n","0.5703479576399395 raw_pred\n","0.8206000000000002 0.6296520423600604 0.026777758009972466 all\n","7.428529675226956 beta\n","Average Accuracy across 9 tasks: 84.74%\n","0.6731\n","8\n","0.523 raw_pred\n","0.8206000000000002 0.6537999999999999 0.01056068803662313 all\n","5.1220374811294365 beta\n","Average Accuracy across 10 tasks: 79.81%\n","0.9587234042553192\n","Average Accuracy across 1 tasks: 99.91%\n","0.7157\n","0\n","0.567 raw_pred\n","0.08255319148936158 0.5686 0.025086962153479792 all\n","0.014327176614424935 beta\n","Average Accuracy across 2 tasks: 93.76%\n","0.776983349657199\n","1\n","0.4931439764936337 raw_pred\n","0.5686 0.4460333006856021 0.00766893122194533 all\n","3.318505350072802 beta\n","Average Accuracy across 3 tasks: 95.04%\n","0.5919000000000001\n","2\n","0.4845 raw_pred\n","0.5686 0.8161999999999998 0.009103059208236886 all\n","0.11117630522641903 beta\n","Average Accuracy across 4 tasks: 85.44%\n","0.7661686232657415\n","3\n","0.4829242262540021 raw_pred\n","0.8161999999999998 0.46766275346851693 0.009391777715231146 all\n","27.021913348253367 beta\n","Average Accuracy across 5 tasks: 88.10%\n","0.627\n","4\n","0.427 raw_pred\n","0.8161999999999998 0.746 0.02819528797014257 all\n","2.4750339007600255 beta\n","Average Accuracy across 6 tasks: 80.90%\n","0.939828801611279\n","5\n","0.4204431017119839 raw_pred\n","0.8161999999999998 0.12034239677744196 0.03201964926864353 all\n","815.6597088053937 beta\n","Average Accuracy across 7 tasks: 83.74%\n","0.6616000000000001\n","6\n","0.514 raw_pred\n","0.8161999999999998 0.6767999999999998 0.008836400460607722 all\n","3.9169281200865806 beta\n","Average Accuracy across 8 tasks: 83.05%\n","0.7501260716086737\n","7\n","0.4891578416540595 raw_pred\n","0.8161999999999998 0.49974785678265254 0.008300068271642732 all\n","19.907138865620738 beta\n","Average Accuracy across 9 tasks: 85.48%\n","0.7047\n","8\n","0.5635 raw_pred\n","0.8161999999999998 0.5906 0.023430667673670316 all\n","9.91111854529209 beta\n","Average Accuracy across 10 tasks: 86.55%\n"]}],"source":["mixed_trends_4 = []\n","mixed_betas = []\n","torch.manual_seed(SEED)\n","for i in range(5):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(mixed_tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend, m_beta = run_auto_vcl(model, \n","        mixed_train_loaders,\n","        mixed_test_loaders,\n","        optimizer, \n","        epoch_per_task, \n","        coreset_size,\n","        binary_labels = mixed_tasks,\n","        return_betas = True)\n","    mixed_trends_4.append(trend)\n","    mixed_betas.append(m_beta)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# mixed_trends_5 = []\n","# for i in range(5):\n","#     model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(mixed_tasks)).to(device)\n","#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","#     trend = run_auto_vcl(model, \n","#         mixed_train_loaders,\n","#         mixed_test_loaders,\n","#         optimizer, \n","#         epoch_per_task, \n","#         coreset_size,\n","#         binary_labels = mixed_tasks,\n","#         dor = True)\n","#     mixed_trends_5.append(trend)"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"data":{"text/html":["\n","<div id=\"altair-viz-cf2cf6db44004ab7a232bc953accb479\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-cf2cf6db44004ab7a232bc953accb479\") {\n","      outputDiv = document.getElementById(\"altair-viz-cf2cf6db44004ab7a232bc953accb479\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 15, \"titleFontSize\": 20}, \"legend\": {\"labelFontSize\": 15, \"titleFontSize\": 15}, \"title\": {\"fontSize\": 24}}, \"data\": {\"name\": \"data-0995d372d61c2822dcbd9ccab4ba948b\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Series\", \"legend\": {\"title\": \"Model\"}, \"scale\": {\"scheme\": \"category10\"}, \"sort\": [\"beta = 0.01\", \"beta = 1\", \"beta = 100\", \"AutoVCL\"], \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"# of tasks\", \"type\": \"quantitative\"}, {\"field\": \"Values\", \"type\": \"quantitative\"}, {\"field\": \"Series\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"values\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}, \"field\": \"# of tasks\", \"title\": \"# tasks\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Values\", \"scale\": {\"domain\": [0.7, 1]}, \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Accuracy Trends in the Permuated MNIST Experiment\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-0995d372d61c2822dcbd9ccab4ba948b\": [{\"# of tasks\": 0, \"Series\": \"beta = 0.01\", \"Values\": 0.9986761229314421}, {\"# of tasks\": 1, \"Series\": \"beta = 0.01\", \"Values\": 0.9319179669030733}, {\"# of tasks\": 2, \"Series\": \"beta = 0.01\", \"Values\": 0.9219464315566949}, {\"# of tasks\": 3, \"Series\": \"beta = 0.01\", \"Values\": 0.8511225210300012}, {\"# of tasks\": 4, \"Series\": \"beta = 0.01\", \"Values\": 0.8429180670114145}, {\"# of tasks\": 5, \"Series\": \"beta = 0.01\", \"Values\": 0.8204008173097689}, {\"# of tasks\": 6, \"Series\": \"beta = 0.01\", \"Values\": 0.7348719397256817}, {\"# of tasks\": 7, \"Series\": \"beta = 0.01\", \"Values\": 0.7941155893594078}, {\"# of tasks\": 8, \"Series\": \"beta = 0.01\", \"Values\": 0.7754111923717356}, {\"# of tasks\": 9, \"Series\": \"beta = 0.01\", \"Values\": 0.7793528814298464}, {\"# of tasks\": 0, \"Series\": \"beta = 1\", \"Values\": 0.9986761229314421}, {\"# of tasks\": 1, \"Series\": \"beta = 1\", \"Values\": 0.931090780141844}, {\"# of tasks\": 2, \"Series\": \"beta = 1\", \"Values\": 0.9285954551734305}, {\"# of tasks\": 3, \"Series\": \"beta = 1\", \"Values\": 0.8522970140061081}, {\"# of tasks\": 4, \"Series\": \"beta = 1\", \"Values\": 0.8662689407366002}, {\"# of tasks\": 5, \"Series\": \"beta = 1\", \"Values\": 0.8309205398116666}, {\"# of tasks\": 6, \"Series\": \"beta = 1\", \"Values\": 0.8241463752835175}, {\"# of tasks\": 7, \"Series\": \"beta = 1\", \"Values\": 0.8222078244957451}, {\"# of tasks\": 8, \"Series\": \"beta = 1\", \"Values\": 0.826404486023425}, {\"# of tasks\": 9, \"Series\": \"beta = 1\", \"Values\": 0.8183212374289976}, {\"# of tasks\": 0, \"Series\": \"beta = 100\", \"Values\": 0.9986761229314421}, {\"# of tasks\": 1, \"Series\": \"beta = 100\", \"Values\": 0.892835342789598}, {\"# of tasks\": 2, \"Series\": \"beta = 100\", \"Values\": 0.9177893450309458}, {\"# of tasks\": 3, \"Series\": \"beta = 100\", \"Values\": 0.8523094916331507}, {\"# of tasks\": 4, \"Series\": \"beta = 100\", \"Values\": 0.8788792721972006}, {\"# of tasks\": 5, \"Series\": \"beta = 100\", \"Values\": 0.8473913378981525}, {\"# of tasks\": 6, \"Series\": \"beta = 100\", \"Values\": 0.8661871112672337}, {\"# of tasks\": 7, \"Series\": \"beta = 100\", \"Values\": 0.8479065491663119}, {\"# of tasks\": 8, \"Series\": \"beta = 100\", \"Values\": 0.8564882538126204}, {\"# of tasks\": 9, \"Series\": \"beta = 100\", \"Values\": 0.8499741815164803}, {\"# of tasks\": 0, \"Series\": \"AutoVCL\", \"Values\": 0.9990543735224586}, {\"# of tasks\": 1, \"Series\": \"AutoVCL\", \"Values\": 0.9349543735224586}, {\"# of tasks\": 2, \"Series\": \"AutoVCL\", \"Values\": 0.9343282214550392}, {\"# of tasks\": 3, \"Series\": \"AutoVCL\", \"Values\": 0.8273525080287948}, {\"# of tasks\": 4, \"Series\": \"AutoVCL\", \"Values\": 0.8617249768838461}, {\"# of tasks\": 5, \"Series\": \"AutoVCL\", \"Values\": 0.8236326397068356}, {\"# of tasks\": 6, \"Series\": \"AutoVCL\", \"Values\": 0.8492932263137194}, {\"# of tasks\": 7, \"Series\": \"AutoVCL\", \"Values\": 0.8113676794617428}, {\"# of tasks\": 8, \"Series\": \"AutoVCL\", \"Values\": 0.8455578452052052}, {\"# of tasks\": 9, \"Series\": \"AutoVCL\", \"Values\": 0.8424412490104766}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.Chart(...)"]},"metadata":{},"output_type":"display_data"}],"source":["plot_trends([mixed_trends_1, mixed_trends_2, mixed_trends_3, mixed_trends_4])"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["P-MNIST"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 97.18%\n","Average Accuracy across 2 tasks: 86.45%\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[30], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m MFVI_NN(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m], \u001b[38;5;241m10\u001b[39m, num_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, single_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m trend \u001b[38;5;241m=\u001b[39m \u001b[43mrun_vcl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmnist_train_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpmnist_test_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoreset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m p_trends_1\u001b[38;5;241m.\u001b[39mappend(trend)\n","Cell \u001b[0;32mIn[20], line 23\u001b[0m, in \u001b[0;36mrun_vcl\u001b[0;34m(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta, binary_labels)\u001b[0m\n\u001b[1;32m     21\u001b[0m         model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# for prediction\u001b[39;00m\n","Cell \u001b[0;32mIn[17], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, trainloader, optimizer, epoch, device, kl_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, task_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, binary_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m      6\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the images\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[4], line 12\u001b[0m, in \u001b[0;36mPermutedMNIST.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 12\u001b[0m     image, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmnist_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermutation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# Apply permutation\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermutation]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/transforms.py:93\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     90\u001b[0m         _log_api_usage_once(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m transforms\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m     95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["p_trends_1 = []\n","torch.manual_seed(SEED)\n","coreset_size = 0\n","for i in range(5):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10, single_head=True).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, pmnist_train_loaders,pmnist_test_loaders, optimizer, epoch_per_task, coreset_size, beta=1e-2)\n","    p_trends_1.append(trend)"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"data":{"text/plain":["MFVI_NN(\n","  (layers): ModuleList(\n","    (0-1): 2 x MFVI_Layer()\n","  )\n","  (task_specific_layers): ModuleDict(\n","    (0): MFVI_Layer()\n","  )\n",")"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"MFVI_NN.__init__() got an unexpected keyword argument 'single_head'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(SEED)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mMFVI_NN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_tasks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_head\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m      7\u001b[0m     trend \u001b[38;5;241m=\u001b[39m run_vcl(model, permuted_mnist_train_loaders,permuted_mnist_test_loaders, \n\u001b[1;32m      8\u001b[0m         optimizer,\u001b[38;5;241m10\u001b[39m, coreset_size, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: MFVI_NN.__init__() got an unexpected keyword argument 'single_head'"]}],"source":["p_trends_2 = []\n","coreset_size = 0\n","torch.manual_seed(SEED)\n","for i in range(5):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10, single_head=True).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, permuted_mnist_train_loaders,permuted_mnist_test_loaders, \n","        optimizer,10, coreset_size, beta=100)\n","    p_trends_2.append(trend)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.9721]\n","Average Accuracy across 1 tasks: 97.21%\n","[0.9254, 0.9682]\n","Average Accuracy across 2 tasks: 94.68%\n","[0.8229, 0.8182, 0.9667]\n","Average Accuracy across 3 tasks: 86.93%\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[46], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m MFVI_NN(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m], \u001b[38;5;241m10\u001b[39m, num_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, single_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m trend \u001b[38;5;241m=\u001b[39m \u001b[43mrun_vcl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmnist_train_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpmnist_test_loaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoreset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m p_trends_3\u001b[38;5;241m.\u001b[39mappend(trend)\n","Cell \u001b[0;32mIn[37], line 23\u001b[0m, in \u001b[0;36mrun_vcl\u001b[0;34m(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta, binary_labels)\u001b[0m\n\u001b[1;32m     21\u001b[0m         model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# for prediction\u001b[39;00m\n","Cell \u001b[0;32mIn[40], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label)\u001b[0m\n\u001b[1;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the images\u001b[39;00m\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 9\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m binary_label \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     target \u001b[38;5;241m=\u001b[39m (target \u001b[38;5;241m==\u001b[39m binary_label[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mlong()\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[45], line 100\u001b[0m, in \u001b[0;36mMFVI_NN.forward\u001b[0;34m(self, x, task_id, sample)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, task_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 100\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingle_head:\n\u001b[1;32m    102\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_specific_layers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m](x, sample\u001b[38;5;241m=\u001b[39msample)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[45], line 42\u001b[0m, in \u001b[0;36mMFVI_Layer.forward\u001b[0;34m(self, x, sample)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 42\u001b[0m     W_std \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_logv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     b_std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_logv)\n\u001b[1;32m     45\u001b[0m     act_mu \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["p_trends_3 = []\n","torch.manual_seed(SEED)\n","for i in range(5):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10, single_head=True).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, pmnist_train_loaders,pmnist_test_loaders,\n","     optimizer, epoch_per_task, coreset_size, beta=100)\n","    p_trends_3.append(trend)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6274200000000001\n","Average Accuracy across 1 tasks: 97.39%\n","0.59131\n","0\n","0.1433 raw_pred\n","0.41397777777777767 0.45409999999999995 0.0002933062276259872 all\n","0.692921977329255 beta\n","Average Accuracy across 2 tasks: 95.61%\n","0.62581\n","1\n","0.0637 raw_pred\n","0.45409999999999995 0.41576666666666673 0.00025499795550306954 all\n","1.4267678845975205 beta\n","Average Accuracy across 3 tasks: 91.74%\n","0.61495\n","2\n","0.1025 raw_pred\n","0.45409999999999995 0.4278333333333333 0.00012972033049847497 all\n","1.2752212702334638 beta\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[50], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m MFVI_NN(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m], \u001b[38;5;241m10\u001b[39m, num_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, single_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m trend, p_beta\u001b[38;5;241m=\u001b[39m \u001b[43mrun_auto_vcl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmnist_train_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpmnist_test_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoreset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_betas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m p_trends_4\u001b[38;5;241m.\u001b[39mappend(trend)\n\u001b[1;32m     10\u001b[0m p_betas\u001b[38;5;241m.\u001b[39mappend(p_beta)\n","Cell \u001b[0;32mIn[49], line 115\u001b[0m, in \u001b[0;36mrun_auto_vcl\u001b[0;34m(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta_star, raw_training_epoch, raw_train_size, binary_labels, dor, return_betas)\u001b[0m\n\u001b[1;32m    113\u001b[0m         model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m--> 115\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# for prediction\u001b[39;00m\n","Cell \u001b[0;32mIn[40], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label)\u001b[0m\n\u001b[1;32m     18\u001b[0m     kl_divergence \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mkl_divergence()\n\u001b[1;32m     19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m reconstruction_loss \u001b[38;5;241m+\u001b[39m kl_divergence \u001b[38;5;241m*\u001b[39m kl_weight\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["p_trends_4 = []\n","p_betas = []\n","torch.manual_seed(SEED)\n","for i in range(5):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10, single_head=True).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend, p_beta= run_auto_vcl(model, pmnist_train_loaders,pmnist_test_loaders, optimizer, \n","        epoch_per_task, coreset_size, return_betas=True)\n","    p_trends_4.append(trend)\n","    p_betas.append(p_beta)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["\n","<div id=\"altair-viz-29193f0ae8734336bd48febeeeabdc28\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-29193f0ae8734336bd48febeeeabdc28\") {\n","      outputDiv = document.getElementById(\"altair-viz-29193f0ae8734336bd48febeeeabdc28\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 15, \"titleFontSize\": 20}, \"legend\": {\"labelFontSize\": 15, \"titleFontSize\": 15}, \"title\": {\"fontSize\": 24}}, \"data\": {\"name\": \"data-a687ae4d97cee9f20172d3187863d4cd\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Series\", \"legend\": {\"title\": \"Model\"}, \"scale\": {\"scheme\": \"category10\"}, \"sort\": [\"beta = 0.01\", \"beta = 1\", \"beta = 100\", \"AutoVCL\"], \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"# of tasks\", \"type\": \"quantitative\"}, {\"field\": \"Values\", \"type\": \"quantitative\"}, {\"field\": \"Series\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"values\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}, \"field\": \"# of tasks\", \"title\": \"# tasks\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Values\", \"scale\": {\"domain\": [0.7, 1]}, \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Accuracy Trends in the Permuated MNIST Experiment\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-a687ae4d97cee9f20172d3187863d4cd\": [{\"# of tasks\": 0, \"Series\": \"beta = 0.01\", \"Values\": 0.97744}, {\"# of tasks\": 1, \"Series\": \"beta = 0.01\", \"Values\": 0.96143}, {\"# of tasks\": 2, \"Series\": \"beta = 0.01\", \"Values\": 0.9407466666666668}, {\"# of tasks\": 3, \"Series\": \"beta = 0.01\", \"Values\": 0.9128900000000002}, {\"# of tasks\": 4, \"Series\": \"beta = 0.01\", \"Values\": 0.88806}, {\"# of tasks\": 5, \"Series\": \"beta = 0.01\", \"Values\": 0.8564733333333333}, {\"# of tasks\": 6, \"Series\": \"beta = 0.01\", \"Values\": 0.8341799999999999}, {\"# of tasks\": 7, \"Series\": \"beta = 0.01\", \"Values\": 0.7968824999999999}, {\"# of tasks\": 8, \"Series\": \"beta = 0.01\", \"Values\": 0.7716711111111111}, {\"# of tasks\": 9, \"Series\": \"beta = 0.01\", \"Values\": 0.747904}, {\"# of tasks\": 0, \"Series\": \"beta = 1\", \"Values\": 0.97728}, {\"# of tasks\": 1, \"Series\": \"beta = 1\", \"Values\": 0.96854}, {\"# of tasks\": 2, \"Series\": \"beta = 1\", \"Values\": 0.9638933333333334}, {\"# of tasks\": 3, \"Series\": \"beta = 1\", \"Values\": 0.9590250000000001}, {\"# of tasks\": 4, \"Series\": \"beta = 1\", \"Values\": 0.955376}, {\"# of tasks\": 5, \"Series\": \"beta = 1\", \"Values\": 0.9522633333333335}, {\"# of tasks\": 6, \"Series\": \"beta = 1\", \"Values\": 0.9486828571428572}, {\"# of tasks\": 7, \"Series\": \"beta = 1\", \"Values\": 0.9459199999999999}, {\"# of tasks\": 8, \"Series\": \"beta = 1\", \"Values\": 0.9431555555555555}, {\"# of tasks\": 9, \"Series\": \"beta = 1\", \"Values\": 0.94054}, {\"# of tasks\": 0, \"Series\": \"beta = 100\", \"Values\": 0.97768}, {\"# of tasks\": 1, \"Series\": \"beta = 100\", \"Values\": 0.9062899999999999}, {\"# of tasks\": 2, \"Series\": \"beta = 100\", \"Values\": 0.8830333333333333}, {\"# of tasks\": 3, \"Series\": \"beta = 100\", \"Values\": 0.8722049999999999}, {\"# of tasks\": 4, \"Series\": \"beta = 100\", \"Values\": 0.8659840000000001}, {\"# of tasks\": 5, \"Series\": \"beta = 100\", \"Values\": 0.8620166666666667}, {\"# of tasks\": 6, \"Series\": \"beta = 100\", \"Values\": 0.8599257142857143}, {\"# of tasks\": 7, \"Series\": \"beta = 100\", \"Values\": 0.8576475}, {\"# of tasks\": 8, \"Series\": \"beta = 100\", \"Values\": 0.8549911111111111}, {\"# of tasks\": 9, \"Series\": \"beta = 100\", \"Values\": 0.8537279999999999}, {\"# of tasks\": 0, \"Series\": \"AutoVCL\", \"Values\": 0.97714}, {\"# of tasks\": 1, \"Series\": \"AutoVCL\", \"Values\": 0.97051}, {\"# of tasks\": 2, \"Series\": \"AutoVCL\", \"Values\": 0.9648933333333332}, {\"# of tasks\": 3, \"Series\": \"AutoVCL\", \"Values\": 0.959845}, {\"# of tasks\": 4, \"Series\": \"AutoVCL\", \"Values\": 0.9560000000000001}, {\"# of tasks\": 5, \"Series\": \"AutoVCL\", \"Values\": 0.9525366666666667}, {\"# of tasks\": 6, \"Series\": \"AutoVCL\", \"Values\": 0.9482857142857144}, {\"# of tasks\": 7, \"Series\": \"AutoVCL\", \"Values\": 0.9451075000000001}, {\"# of tasks\": 8, \"Series\": \"AutoVCL\", \"Values\": 0.9417088888888889}, {\"# of tasks\": 9, \"Series\": \"AutoVCL\", \"Values\": 0.939086}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.Chart(...)"]},"metadata":{},"output_type":"display_data"}],"source":["plot_trends([p_trends_1, p_trends_2,p_trends_3, p_trends_4])"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 99.91%\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[53], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m MFVI_NN(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m], \u001b[38;5;241m10\u001b[39m, num_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     trend \u001b[38;5;241m=\u001b[39m \u001b[43mrun_vcl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoreset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     pc_trends_1\u001b[38;5;241m.\u001b[39mappend(trend)\n\u001b[1;32m      8\u001b[0m pc_trends_2 \u001b[38;5;241m=\u001b[39m []\n","Cell \u001b[0;32mIn[51], line 23\u001b[0m, in \u001b[0;36mrun_vcl\u001b[0;34m(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta, binary_labels)\u001b[0m\n\u001b[1;32m     21\u001b[0m         model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# for prediction\u001b[39;00m\n","Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, trainloader, optimizer, epoch, device, kl_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, task_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, binary_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m      6\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the images\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/datasets/mnist.py:142\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    138\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/PIL/Image.py:3103\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3101\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mtostring()\n\u001b[0;32m-> 3103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/PIL/Image.py:3019\u001b[0m, in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m _MAPMODES:\n\u001b[1;32m   3018\u001b[0m     im \u001b[38;5;241m=\u001b[39m new(mode, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m-> 3019\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3020\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3021\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImagePalette\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/PIL/Image.py:544\u001b[0m, in \u001b[0;36mImage._new\u001b[0;34m(self, im)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_new\u001b[39m(\u001b[38;5;28mself\u001b[39m, im):\n\u001b[0;32m--> 544\u001b[0m     new \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m     new\u001b[38;5;241m.\u001b[39mim \u001b[38;5;241m=\u001b[39m im\n\u001b[1;32m    546\u001b[0m     new\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mmode\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["pc_trends_1 = []\n","coreset_size = 1000\n","for i in range(1):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, train_loaders,test_loaders, optimizer, epoch_per_task, coreset_size, beta=1e-2)\n","    pc_trends_1.append(trend)\n","pc_trends_2 = []\n","for i in range(1):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, train_loaders,test_loaders, optimizer, epoch_per_task, coreset_size, beta=1)\n","    pc_trends_2.append(trend)\n","pc_trends_3 = []\n","for i in range(1):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, train_loaders,test_loaders, optimizer, epoch_per_task, coreset_size, beta=1e2)\n","    pc_trends_3.append(trend)\n","pc_trends_4 = []\n","for i in range(1):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend  = run_auto_vcl(model, train_loaders,test_loaders, optimizer, epoch_per_task, coreset_size, \n","            raw_training_epoch = raw_training_epoch,\n","            raw_train_size= raw_train_size)\n","    pc_trends_4.append(trend)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["\n","<div id=\"altair-viz-c73b0b2d3c2d4680ad59e695bc6e946b\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-c73b0b2d3c2d4680ad59e695bc6e946b\") {\n","      outputDiv = document.getElementById(\"altair-viz-c73b0b2d3c2d4680ad59e695bc6e946b\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 15, \"titleFontSize\": 20}, \"legend\": {\"labelFontSize\": 15, \"titleFontSize\": 15}, \"title\": {\"fontSize\": 24}}, \"data\": {\"name\": \"data-1a08c5aab4d92bc279dd866125d5b863\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Series\", \"legend\": {\"title\": \"Model\"}, \"scale\": {\"scheme\": \"category10\"}, \"sort\": [\"beta = 0.01\", \"beta = 1\", \"beta = 100\", \"AutoVCL\"], \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"# of tasks\", \"type\": \"quantitative\"}, {\"field\": \"Values\", \"type\": \"quantitative\"}, {\"field\": \"Series\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"values\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}, \"field\": \"# of tasks\", \"title\": \"# tasks\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Values\", \"scale\": {\"domain\": [0.7, 1]}, \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Accuracy Trends in the Permuated MNIST Experiment\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-1a08c5aab4d92bc279dd866125d5b863\": [{\"# of tasks\": 0, \"Series\": \"beta = 0.01\", \"Values\": 0.9775}, {\"# of tasks\": 1, \"Series\": \"beta = 0.01\", \"Values\": 0.96975}, {\"# of tasks\": 2, \"Series\": \"beta = 0.01\", \"Values\": 0.9576333333333333}, {\"# of tasks\": 3, \"Series\": \"beta = 0.01\", \"Values\": 0.9513750000000001}, {\"# of tasks\": 4, \"Series\": \"beta = 0.01\", \"Values\": 0.94978}, {\"# of tasks\": 5, \"Series\": \"beta = 0.01\", \"Values\": 0.9429666666666666}, {\"# of tasks\": 6, \"Series\": \"beta = 0.01\", \"Values\": 0.9362285714285715}, {\"# of tasks\": 7, \"Series\": \"beta = 0.01\", \"Values\": 0.928275}, {\"# of tasks\": 8, \"Series\": \"beta = 0.01\", \"Values\": 0.9333555555555555}, {\"# of tasks\": 9, \"Series\": \"beta = 0.01\", \"Values\": 0.92408}, {\"# of tasks\": 0, \"Series\": \"beta = 1\", \"Values\": 0.9793}, {\"# of tasks\": 1, \"Series\": \"beta = 1\", \"Values\": 0.9674499999999999}, {\"# of tasks\": 2, \"Series\": \"beta = 1\", \"Values\": 0.9642}, {\"# of tasks\": 3, \"Series\": \"beta = 1\", \"Values\": 0.9582999999999999}, {\"# of tasks\": 4, \"Series\": \"beta = 1\", \"Values\": 0.9564999999999999}, {\"# of tasks\": 5, \"Series\": \"beta = 1\", \"Values\": 0.95355}, {\"# of tasks\": 6, \"Series\": \"beta = 1\", \"Values\": 0.9523714285714285}, {\"# of tasks\": 7, \"Series\": \"beta = 1\", \"Values\": 0.9499875000000001}, {\"# of tasks\": 8, \"Series\": \"beta = 1\", \"Values\": 0.9471555555555555}, {\"# of tasks\": 9, \"Series\": \"beta = 1\", \"Values\": 0.9460200000000001}, {\"# of tasks\": 0, \"Series\": \"beta = 100\", \"Values\": 0.9781}, {\"# of tasks\": 1, \"Series\": \"beta = 100\", \"Values\": 0.9076}, {\"# of tasks\": 2, \"Series\": \"beta = 100\", \"Values\": 0.8961666666666667}, {\"# of tasks\": 3, \"Series\": \"beta = 100\", \"Values\": 0.8945000000000001}, {\"# of tasks\": 4, \"Series\": \"beta = 100\", \"Values\": 0.89268}, {\"# of tasks\": 5, \"Series\": \"beta = 100\", \"Values\": 0.8887}, {\"# of tasks\": 6, \"Series\": \"beta = 100\", \"Values\": 0.8901428571428571}, {\"# of tasks\": 7, \"Series\": \"beta = 100\", \"Values\": 0.8902374999999999}, {\"# of tasks\": 8, \"Series\": \"beta = 100\", \"Values\": 0.887688888888889}, {\"# of tasks\": 9, \"Series\": \"beta = 100\", \"Values\": 0.8904}, {\"# of tasks\": 0, \"Series\": \"AutoVCL\", \"Values\": 0.9785}, {\"# of tasks\": 1, \"Series\": \"AutoVCL\", \"Values\": 0.96895}, {\"# of tasks\": 2, \"Series\": \"AutoVCL\", \"Values\": 0.9633333333333333}, {\"# of tasks\": 3, \"Series\": \"AutoVCL\", \"Values\": 0.9565250000000001}, {\"# of tasks\": 4, \"Series\": \"AutoVCL\", \"Values\": 0.9528800000000001}, {\"# of tasks\": 5, \"Series\": \"AutoVCL\", \"Values\": 0.9487166666666665}, {\"# of tasks\": 6, \"Series\": \"AutoVCL\", \"Values\": 0.9437571428571427}, {\"# of tasks\": 7, \"Series\": \"AutoVCL\", \"Values\": 0.9435250000000001}, {\"# of tasks\": 8, \"Series\": \"AutoVCL\", \"Values\": 0.9409777777777778}, {\"# of tasks\": 9, \"Series\": \"AutoVCL\", \"Values\": 0.9401200000000001}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.Chart(...)"]},"metadata":{},"output_type":"display_data"}],"source":["plot_trends([pc_trends_1, pc_trends_2, pc_trends_3, pc_trends_4])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}

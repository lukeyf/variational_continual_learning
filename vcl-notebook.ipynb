{"cells":[{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T19:55:42.498812Z","iopub.status.busy":"2024-03-21T19:55:42.498474Z","iopub.status.idle":"2024-03-21T19:55:46.218148Z","shell.execute_reply":"2024-03-21T19:55:46.217361Z","shell.execute_reply.started":"2024-03-21T19:55:42.498783Z"},"id":"SPZBRp-PUgWP","trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.parameter import Parameter\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","SEED = 42\n","\n","# Set the random seed for PyTorch\n","torch.manual_seed(SEED)\n","\n","# Additionally, if using NumPy operations in your data processing, set its seed\n","np.random.seed(SEED)\n","\n","class MFVI_Layer(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super(MFVI_Layer, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        \n","        # Mean parameters\n","        self.W_m = nn.Parameter(torch.Tensor(out_features, in_features))\n","        self.b_m = nn.Parameter(torch.Tensor(out_features))\n","\n","        # Log variance parameters\n","        self.W_logv = nn.Parameter(torch.Tensor(out_features, in_features))\n","        self.b_logv = nn.Parameter(torch.Tensor(out_features))\n","\n","        # Prior distributions (initialized to None and will be set in reset_parameters)\n","        self.prior_W_m = None\n","        self.prior_b_m = None\n","        self.prior_W_logv = None\n","        self.prior_b_logv = None\n","\n","        # Initialize parameters\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        self.W_m.data.normal_(0, 0.1)\n","        self.b_m.data.normal_(0, 0.1)\n","        self.W_logv.data.fill_(-6.0)\n","        self.b_logv.data.fill_(-6.0)\n","\n","        # Initially set priors to match the initial parameters\n","        self.set_priors()\n","\n","    def set_priors(self):\n","        # Update or set the prior distributions to the current parameters\n","        self.prior_W_m = self.W_m.detach().clone()\n","        self.prior_b_m = self.b_m.detach().clone()\n","        self.prior_W_logv = self.W_logv.detach().clone()\n","        self.prior_b_logv = self.b_logv.detach().clone()\n","\n","    def forward(self, x, sample=True):\n","        # Calculate standard deviations from log variances\n","        W_std = torch.exp(0.5 * self.W_logv)\n","        b_std = torch.exp(0.5 * self.b_logv)\n","        \n","        # Calculate the output mean\n","        act_mu = F.linear(x, self.W_m, self.b_m)\n","        \n","        # Calculate the output variance\n","        # The variance of the output is given by the sum of variances of the weighted inputs (assuming independence)\n","        act_var = 1e-16 + F.linear(x.pow(2), W_std.pow(2)) + b_std.pow(2)\n","        act_std = torch.sqrt(act_var)\n","\n","        if self.training or sample:\n","            # If in training mode or sample is True, sample from the posterior\n","            eps = torch.randn_like(act_mu)\n","            return act_mu + act_std * eps\n","        else:\n","            # Otherwise, return the mean of the posterior\n","            return act_mu\n","\n","\n","    def kl_divergence(self,device):\n","        # Calculate the number of parameters for normalization\n","        self.update_prior_device(device)\n","        num_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n","\n","        # Convert log variances to standard deviations\n","        W_std = torch.exp(0.5 * self.W_logv)\n","        b_std = torch.exp(0.5 * self.b_logv)\n","        prior_W_std = torch.exp(0.5 * self.prior_W_logv)\n","        prior_b_std = torch.exp(0.5 * self.prior_b_logv)\n","\n","        # Calculate KL divergence for weights using the standard deviation-based formula\n","        kl_W = 0.5 * (2 * torch.log(prior_W_std / W_std) - 1 + (W_std / prior_W_std).pow(2) + ((self.W_m - self.prior_W_m) / prior_W_std).pow(2)).sum()\n","\n","        # Calculate KL divergence for biases using the standard deviation-based formula\n","        kl_b = 0.5 * (2 * torch.log(prior_b_std / b_std) - 1 + (b_std / prior_b_std).pow(2) + ((self.b_m - self.prior_b_m) / prior_b_std).pow(2)).sum()\n","\n","        # Return the normalized KL divergence\n","        return (kl_W + kl_b) /num_params\n","\n","    def update_prior_device(self, device):\n","        self.prior_W_m = self.prior_W_m.to(device)\n","        self.prior_b_m = self.prior_b_m.to(device)\n","        self.prior_W_logv = self.prior_W_logv.to(device)\n","        self.prior_b_logv = self.prior_b_logv.to(device)\n","\n","\n","\n","class MFVI_NN(nn.Module):\n","    def __init__(self, input_size, hidden_sizes,  output_size, num_tasks = 1, single_head =False):\n","        super(MFVI_NN, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_sizes = hidden_sizes\n","        self.output_size = output_size\n","        self.num_tasks = num_tasks\n","        self.single_head = single_head\n","\n","        self.layers = nn.ModuleList()\n","        self.task_specific_layers = nn.ModuleDict()  # Using ModuleDict to hold task-specific layers\n","\n","        # Define shared layers\n","        sizes = [input_size] + hidden_sizes\n","        for i in range(len(sizes)-1):\n","            self.layers.append(MFVI_Layer(sizes[i], sizes[i+1]))\n","\n","        # Define task-specific output layers\n","        if single_head:\n","            self.task_specific_layers[str(0)] = MFVI_Layer(sizes[-1], output_size)\n","        else:\n","            for task_id in range(num_tasks):\n","                self.task_specific_layers[str(task_id)] = MFVI_Layer(sizes[-1], output_size)\n","\n","    def forward(self, x, task_id=0, sample=True):\n","        for layer in self.layers:\n","            x = F.relu(layer(x, sample))\n","        if self.single_head:\n","            task_layer = self.task_specific_layers[\"0\"]\n","            x = task_layer(x, sample)\n","        else:\n","            # Select and apply the task-specific output layer\n","            task_layer = self.task_specific_layers[str(task_id)]\n","            x = task_layer(x, sample)\n","        return x\n","\n","    def kl_divergence(self):\n","        kl_div = 0\n","        # Sum KL divergence from shared layers\n","        for layer in self.layers:\n","            kl_div += layer.kl_divergence(next(self.parameters()).device)\n","        if self.single_head:\n","            layer = self.task_specific_layers[\"0\"]\n","            kl_div += layer.kl_divergence(next(self.parameters()).device)\n","        # Sum KL divergence from task-specific layers\n","        # for task_layer in self.task_specific_layers.values():\n","        #     kl_div += task_layer.kl_divergence(next(self.parameters()).device)\n","\n","        return kl_div\n","\n","\n","    def update_priors(self):\n","        # Update priors in each shared layer\n","        for layer in self.layers:\n","            layer.set_priors()  # Assuming each MFVI_Layer has a method called set_priors\n","        \n","        for task_layer in self.task_specific_layers.values():\n","            task_layer.set_priors()\n","\n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T22:29:34.052062Z","iopub.status.busy":"2024-03-21T22:29:34.051191Z","iopub.status.idle":"2024-03-21T22:29:34.063146Z","shell.execute_reply":"2024-03-21T22:29:34.061986Z","shell.execute_reply.started":"2024-03-21T22:29:34.052035Z"},"id":"su4PfiXIdwAN","trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","\n","def train(model, trainloader, optimizer, epoch, device, kl_weight=1, task_id = 0, binary_label = None):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(trainloader):\n","        data, target = data.to(device), target.to(device)\n","        data = data.view(data.size(0), -1)  # Flatten the images\n","        optimizer.zero_grad()\n","        output = model(data, sample=True, task_id = task_id)\n","        if binary_label != None:\n","            target = (target == binary_label[0]).long()\n","        reconstruction_loss = F.cross_entropy(output, target, reduction='mean')\n","        \n","#         print(kl_divergence,reconstruction_loss)\n","        if task_id == 0:\n","            loss = reconstruction_loss\n","        else:\n","            kl_divergence = model.kl_divergence()\n","            loss = reconstruction_loss + kl_divergence * kl_weight\n","        loss.backward()\n","        optimizer.step()\n","#     print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(trainloader.dataset)} ({100. * batch_idx / len(trainloader):.0f}%)]\\tLoss: {loss.item()}\")\n","\n","def test(model, testloader, device, task_id = 0, binary_label = None):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in testloader:\n","            data, target = data.to(device), target.to(device)\n","            data = data.view(data.size(0), -1)  # Flatten the images\n","            output = model(data, sample=False, task_id = task_id)\n","            if binary_label != None:\n","                target = (target == binary_label[0]).long()\n","\n","            # Use cross_entropy for test loss calculation, sum up batch loss\n","            test_loss += F.cross_entropy(output, target, reduction='mean').item()\n","            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(testloader.dataset)\n","    # print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(testloader.dataset)} ({100. * correct / len(testloader.dataset):.0f}%)\\n')\n","    return test_loss, correct / len(testloader.dataset)\n"]},{"cell_type":"markdown","metadata":{"id":"lCTWinB8DD_M"},"source":["## Permuted MNIST"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T20:26:09.548948Z","iopub.status.busy":"2024-03-21T20:26:09.548620Z","iopub.status.idle":"2024-03-21T20:26:09.626573Z","shell.execute_reply":"2024-03-21T20:26:09.625767Z","shell.execute_reply.started":"2024-03-21T20:26:09.548924Z"},"id":"-iGpZltOvLRw","trusted":true},"outputs":[],"source":["from torchvision import datasets, transforms\n","\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5,), (0.5,))])\n","\n","mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T20:26:09.706009Z","iopub.status.busy":"2024-03-21T20:26:09.705662Z","iopub.status.idle":"2024-03-21T20:26:09.712251Z","shell.execute_reply":"2024-03-21T20:26:09.711281Z","shell.execute_reply.started":"2024-03-21T20:26:09.705982Z"},"id":"G3VNEXUADM7j","trusted":true},"outputs":[],"source":["import torch\n","\n","def generate_permutations(task_count, image_size):\n","    permutations = [torch.randperm(image_size) for _ in range(task_count)]\n","    return permutations\n","\n","task_count = 10\n","image_size = 28 * 28  # MNIST images are 28x28\n","permutations = generate_permutations(task_count, image_size)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T20:26:09.874040Z","iopub.status.busy":"2024-03-21T20:26:09.873745Z","iopub.status.idle":"2024-03-21T20:26:09.881105Z","shell.execute_reply":"2024-03-21T20:26:09.880249Z","shell.execute_reply.started":"2024-03-21T20:26:09.874015Z"},"id":"bkE72alHDOKy","trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","class PermutedMNIST(Dataset):\n","    def __init__(self, mnist_dataset, permutation=None):\n","        self.mnist_dataset = mnist_dataset\n","        self.permutation = permutation\n","\n","    def __len__(self):\n","        return len(self.mnist_dataset)\n","\n","    def __getitem__(self, idx):\n","        image, label = self.mnist_dataset[idx]\n","        if self.permutation is not None:\n","            # Apply permutation\n","            image = image.view(-1)[self.permutation].view(1, 28, 28)\n","        return image, label\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:29:05.975601Z","iopub.status.busy":"2024-03-21T21:29:05.974932Z","iopub.status.idle":"2024-03-21T21:29:05.983346Z","shell.execute_reply":"2024-03-21T21:29:05.982351Z","shell.execute_reply.started":"2024-03-21T21:29:05.975572Z"},"id":"1Riy4xPFDRAp","trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","batch_size = 256\n","\n","# Create a DataLoader for the original MNIST\n","pmnist_train_loaders = []\n","pmnist_test_loaders = []\n","\n","# Create DataLoaders for permuted tasks\n","for perm in permutations:\n","    permuted_train = PermutedMNIST(mnist_trainset, permutation=perm)\n","    permuted_test = PermutedMNIST(mnist_testset, permutation=perm)\n","\n","    train_loader = DataLoader(permuted_train, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(permuted_test, batch_size=batch_size, shuffle=False)\n","\n","    pmnist_train_loaders.append(train_loader)\n","    pmnist_test_loaders.append(test_loader)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2024-03-21T22:30:10.749119Z","iopub.status.busy":"2024-03-21T22:30:10.748741Z","iopub.status.idle":"2024-03-21T22:30:15.465062Z","shell.execute_reply":"2024-03-21T22:30:15.463857Z","shell.execute_reply.started":"2024-03-21T22:30:10.749089Z"},"id":"fprvcPUPDbhv","outputId":"fb650c07-66b7-43d2-e4e8-37ba765532a2","trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","# Assuming model, optimizer, train_loaders, test_loaders are defined\n","if torch.cuda.is_available():\n","    device = 'cuda'\n","else:\n","    device = 'cpu'"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:21:19.853259Z","iopub.status.busy":"2024-03-21T21:21:19.852461Z","iopub.status.idle":"2024-03-21T21:21:19.859168Z","shell.execute_reply":"2024-03-21T21:21:19.858255Z","shell.execute_reply.started":"2024-03-21T21:21:19.853222Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader, ConcatDataset, Subset\n","def random_coreset(dataset, coreset_size):\n","    \"\"\"\n","    Randomly selects a subset of data points to form a coreset.\n","\n","    Args:\n","    - dataset (torch.utils.data.Dataset): The dataset to sample from.\n","    - coreset_size (int): The number of samples to include in the coreset.\n","\n","    Returns:\n","    - coreset_indices (torch.Tensor): Indices of the selected samples.\n","    \"\"\"\n","    # Ensure coreset size does not exceed dataset size\n","    coreset_size = min(coreset_size, len(dataset))\n","    \n","    # Randomly select indices without replacement\n","    coreset_indices = np.random.choice(len(dataset), size=coreset_size, replace=False)\n","    \n","    # Convert numpy array to torch tensor\n","    coreset_indices = torch.from_numpy(coreset_indices)\n","    \n","    coreset = Subset(dataset, coreset_indices)\n","    return coreset\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":207},"execution":{"iopub.execute_input":"2024-03-21T22:30:21.335314Z","iopub.status.busy":"2024-03-21T22:30:21.334944Z"},"id":"DBD-Tcr1EAn2","outputId":"3116097e-5d13-4583-8b9a-795fc0a6efa2","trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","epoch_per_task = 10\n","model = MFVI_NN(28*28, [100, 100], 2, num_tasks = 10).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","coreset_size = 200\n","beta = 1\n","\n","def run_vcl(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size=0, beta=1, binary_labels = None):\n","    ave_acc_trend_rc = []\n","    prev_test_loaders= []\n","    coresets = []\n","    if binary_labels is None:\n","        binary_labels = [None] * model.output_size\n","    for task_id, (train_loader, test_loader) in enumerate(zip(train_loaders, test_loaders), start=0):\n","        task_accuracies_rc = []\n","        if coreset_size > 0:\n","            for i in (range(len(coresets))):\n","                for epoch in (range(1, epoch_per_task + 1)):\n","                    coreset_loader = DataLoader(coresets[i], batch_size=batch_size, shuffle=True)\n","                    train(model, coreset_loader, optimizer, epoch, device, beta, task_id=i, binary_label=binary_labels[i])\n","                model.update_priors()\n","        for epoch in (range(1, epoch_per_task + 1)):\n","            train(model, train_loader, optimizer, epoch, device, beta, task_id=task_id, binary_label=binary_labels[task_id])\n","        model.update_priors()\n","\n","\n","        # for prediction\n","        prediction_model = type(model)(model.input_size, model.hidden_sizes, model.output_size, model.num_tasks, model.single_head).to(device)\n","        prediction_model.load_state_dict(model.state_dict())\n","        # replay\n","        if coreset_size > 0:\n","            coresets.append(random_coreset(train_loader.dataset, coreset_size))\n","            for i in (range(len(coresets))):\n","                for epoch in (range(1, epoch_per_task + 1)):\n","                    coreset_loader = DataLoader(coresets[i], batch_size=batch_size, shuffle=True)\n","                    train(prediction_model, coreset_loader, optimizer, epoch, device, beta, task_id=i, binary_label=binary_labels[i])\n","        task_num = 0  \n","        prev_test_loaders.append(test_loader)\n","        for ptl in prev_test_loaders: \n","            test_loss, task_accuracy = test(prediction_model, ptl, device,task_id=task_num, binary_label=binary_labels[task_num])\n","            task_accuracies_rc.append(task_accuracy)\n","            task_num += 1\n","        average_accuracy = sum(task_accuracies_rc) / len(task_accuracies_rc)\n","        ave_acc_trend_rc.append(average_accuracy)\n","        print(f'Average Accuracy across {len(task_accuracies_rc)} tasks: {average_accuracy*100:.2f}%')\n","    return ave_acc_trend_rc\n","\n","def scale_similarity(sim, a, b):\n","    return 1/(1+np.exp(-20*(sim-(a+b)/2)))\n","\n","def run_auto_vcl(model, train_loaders,test_loaders, optimizer, epoch_per_task, coreset_size, \n","                beta_star=1, raw_training_epoch = 1,raw_train_size = 1000, \n","                binary_labels = None, dor = False, return_betas = False):\n","    task_difficulties = []\n","    \n","    ave_acc_trend_rc = []\n","    prev_test_loaders= []\n","    coresets = []\n","    betas = []\n","    if binary_labels is None:\n","        binary_labels = [None] * model.output_size\n","    for task_id, (train_loader, test_loader) in enumerate(zip(train_loaders, test_loaders), start=0):\n","        raw_acc = []\n","        for i in range(10):\n","            raw_model = type(model)(model.input_size, model.hidden_sizes, model.output_size, model.num_tasks, model.single_head).to(device)\n","            ## raw training\n","\n","            raw_trainset = random_coreset(train_loader.dataset, raw_train_size)\n","            raw_train_loader = DataLoader(raw_trainset, batch_size=batch_size, shuffle=True)\n","            raw_optimizer = torch.optim.Adam(raw_model.parameters(), lr=0.001)\n","\n","            for epoch in (range(1, raw_training_epoch + 1)):\n","                train(raw_model, raw_train_loader, raw_optimizer, epoch, device, beta_star, task_id=0, binary_label=binary_labels[task_id])\n","            _, acc_simple_train = test(raw_model, test_loader, device,task_id=0, binary_label=binary_labels[task_id])\n","            raw_acc.append(acc_simple_train)\n","        \n","        acc_simple_train = np.mean(raw_acc)\n","        print(acc_simple_train)\n","\n","        dummy_pred = 1/model.output_size\n","        curr_difficulty = min(max((1-(acc_simple_train - dummy_pred)/(1-dummy_pred)),0),1)\n","        if task_id > 0:\n","            print(task_id-1)\n","            _, raw_pred = test(model, test_loader, device,task_id=task_id-1, binary_label=binary_labels[task_id])\n","            print(raw_pred,'raw_pred')\n","            \n","            # similarity = min(max(np.abs(raw_pred - dummy_pred)/(prev_acc- dummy_pred),0),1)\n","            similarity = scale_similarity(np.abs(raw_pred-dummy_pred), 0, 1-dummy_pred)\n","            prev_difficulty = np.max(task_difficulties)\n","            print(prev_difficulty, curr_difficulty,similarity,'all')\n","            beta = beta_star*10**((prev_difficulty-curr_difficulty)*4+similarity*4)\n","            betas.append(beta)\n","            print(beta,'beta')\n","        else: \n","            beta = beta_star\n","\n","        if coreset_size > 0 and task_id>0:\n","            if (dor):\n","                zipped_and_indices = sorted(enumerate(zip(task_difficulties, coresets)), key=lambda x: x[1][0], reverse=True)\n","\n","                sorted_task_nums = [index for index, _ in zipped_and_indices]\n","                sorted_difficulties = [pair[0] for _, pair in zipped_and_indices]\n","                replay_coresets = [pair[1] for _, pair in zipped_and_indices]\n","                replay_betas = [beta_star*10**(2-d) for d in sorted_difficulties]\n","                print(sorted_difficulties, replay_betas)\n","            else:\n","                replay_coresets = coresets\n","            for i in (range(len(coresets))):\n","                for epoch in (range(1, epoch_per_task + 1)):\n","                    coreset_loader = DataLoader(replay_coresets[i], batch_size=batch_size, shuffle=True)\n","                    if dor:\n","                        sorted_task_num = sorted_task_nums[i]\n","                        train(model, coreset_loader, optimizer, epoch, device, replay_betas[i], task_id=sorted_task_num, binary_label=binary_labels[sorted_task_num])\n","                    else:\n","                        train(model, coreset_loader, optimizer, epoch, device, beta_star, task_id=i, binary_label=binary_labels[i])\n","                model.update_priors()\n","        for epoch in (range(1, epoch_per_task + 1)):\n","            train(model, train_loader, optimizer, epoch, device, beta, task_id=task_id, binary_label=binary_labels[task_id])\n","        model.update_priors()\n","\n","\n","        # for prediction\n","        prediction_model = type(model)(model.input_size, model.hidden_sizes, model.output_size, model.num_tasks, model.single_head).to(device)\n","        prediction_model.load_state_dict(model.state_dict())\n","        # replay\n","\n","        task_difficulties.append(curr_difficulty)\n","        if coreset_size > 0:\n","            \n","            coresets.append(random_coreset(train_loader.dataset, coreset_size))\n","            if (dor):\n","                zipped_and_indices = sorted(enumerate(zip(task_difficulties, coresets)), key=lambda x: x[1][0], reverse=True)\n","\n","                sorted_task_nums = [index for index, _ in zipped_and_indices]\n","                sorted_difficulties = [pair[0] for _, pair in zipped_and_indices]\n","                replay_coresets = [pair[1] for _, pair in zipped_and_indices]\n","                replay_betas = [beta_star*10**(2-d) for d in sorted_difficulties]\n","            else:\n","                replay_coresets = coresets\n","            for i in (range(len(coresets))):\n","                for epoch in (range(1, epoch_per_task + 1)):\n","                    coreset_loader = DataLoader(replay_coresets[i], batch_size=batch_size, shuffle=True)\n","                    if dor:\n","                        sorted_task_num = sorted_task_nums[i]\n","                        train(model, coreset_loader, optimizer, epoch, device, replay_betas[i], task_id=sorted_task_num, binary_label=binary_labels[sorted_task_num])\n","                    else:\n","                        train(model, coreset_loader, optimizer, epoch, device, beta_star, task_id=i, binary_label=binary_labels[i])\n","        task_num = 0  \n","        prev_test_loaders.append(test_loader)\n","\n","        task_accuracies_rc = []\n","        for ptl in prev_test_loaders: \n","            test_loss, task_accuracy = test(prediction_model, ptl, device,task_id=task_num, binary_label=binary_labels[task_num])\n","            task_accuracies_rc.append(task_accuracy)\n","            task_num += 1\n","        \n","        prev_acc = task_accuracy\n","        average_accuracy = sum(task_accuracies_rc) / len(task_accuracies_rc)\n","        ave_acc_trend_rc.append(average_accuracy)\n","        print(f'Average Accuracy across {len(task_accuracies_rc)} tasks: {average_accuracy*100:.2f}%')\n","    if return_betas:\n","        return ave_acc_trend_rc, betas\n","    \n","    return ave_acc_trend_rc"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def create_split_task(dataset, classes):\n","    \"\"\"\n","    Create a binary classification task from the MNIST dataset.\n","    \n","    Parameters:\n","    - dataset: The original MNIST dataset (training or test).\n","    - classes: A tuple of two integers representing the classes to include in the split.\n","    \n","    Returns:\n","    - A Subset of the original dataset containing only the specified classes.\n","    \"\"\"\n","    # Find indices of classes we're interested in\n","    indices = [i for i, (_, target) in enumerate(dataset) if target in classes]\n","    \n","    # Create a subset of the dataset with only the specified classes\n","    subset = Subset(dataset, indices)\n","    \n","    return subset\n","\n","def create_split_dataloaders(train_dataset, test_dataset, tasks, batch_size=256):\n","    \"\"\"\n","    Create DataLoaders for each binary task in Split MNIST.\n","    \n","    Parameters:\n","    - train_dataset: The MNIST training dataset.\n","    - test_dataset: The MNIST test dataset.\n","    - batch_size: The batch size for the DataLoader.\n","    \n","    Returns:\n","    - A list of tuples containing (train_loader, test_loader) for each binary task.\n","    \"\"\"\n","    train_loaders = []\n","    test_loaders = []\n","    for task in tasks:\n","        # Create training subset and DataLoader\n","        train_subset = create_split_task(train_dataset, task)\n","        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","\n","        # Create test subset and DataLoader\n","        test_subset = create_split_task(test_dataset, task)\n","        test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n","\n","        train_loaders.append(train_loader)\n","        test_loaders.append(test_loader)\n","    \n","    return train_loaders, test_loaders"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","\n","def plot_trends(trends, title = 'Accuracy Trends in the Permuated MNIST Experiment', lower = 0.7):\n","    df = pd.DataFrame({\n","        '# of tasks': range(len(trends[0][0])),\n","        'beta = 0.01': np.mean(trends[0], axis = 0),\n","        'beta = 1': np.mean(trends[1], axis = 0),\n","        'beta = 100': np.mean(trends[2], axis = 0),\n","        'AutoVCL': np.mean(trends[3], axis = 0)\n","    })\n","    # Convert the DataFrame to long format\n","    df_long = df.melt('# of tasks', var_name='Series', value_name='Values')\n","\n","    import altair as alt\n","    legend_order = ['beta = 0.01', 'beta = 1', 'beta = 100', 'AutoVCL']\n","    # Create the plot\n","    chart = alt.Chart(df_long).mark_line(point=True).encode(\n","        \n","        x=alt.X('# of tasks:Q', title='# tasks', axis=alt.Axis(values=list(range(df_long['# of tasks'].max() + 1)))), # Ensure integer ticks),\n","        y=alt.Y('Values:Q', scale=alt.Scale(domain=[lower, 1]), title='Accuracy'),\n","        color=alt.Color('Series:N', sort=legend_order,scale=alt.Scale(scheme='category10'), legend=alt.Legend(title=\"Model\")),\n","        tooltip=['# of tasks', 'Values', 'Series']\n","    ).properties(\n","        width=800,\n","        height=400,\n","        title=title\n","    ).configure_axis(\n","        labelFontSize=15,\n","        titleFontSize=20\n","    ).configure_legend(\n","        labelFontSize=15,\n","        titleFontSize=15\n","    ).configure_title(\n","        fontSize=24\n","    )\n","\n","    chart.display()"]},{"cell_type":"markdown","metadata":{},"source":["## Reproduce"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["10"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["epoch_per_task"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 97.05%\n","Average Accuracy across 2 tasks: 94.08%\n","Average Accuracy across 3 tasks: 92.56%\n"]},{"name":"stderr","output_type":"stream","text":["[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n","[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n","[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n","[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[54], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m MFVI_NN(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m], \u001b[38;5;241m10\u001b[39m, num_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, single_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m vcl_trend, coreset_trend \u001b[38;5;241m=\u001b[39m \u001b[43mrun_vcl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mpmnist_train_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpmnist_test_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoreset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_coreset_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m vcl_results[coreset_size] \u001b[38;5;241m=\u001b[39m vcl_trend\n\u001b[1;32m      9\u001b[0m coreset_results[coreset_size] \u001b[38;5;241m=\u001b[39m coreset_trend\n","Cell \u001b[0;32mIn[53], line 24\u001b[0m, in \u001b[0;36mrun_vcl\u001b[0;34m(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta, binary_labels, return_coreset_score)\u001b[0m\n\u001b[1;32m     22\u001b[0m         model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# for prediction\u001b[39;00m\n","Cell \u001b[0;32mIn[40], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label, use_kl)\u001b[0m\n\u001b[1;32m     16\u001b[0m     loss \u001b[38;5;241m=\u001b[39m reconstruction_loss\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     kl_divergence \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkl_divergence\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m reconstruction_loss \u001b[38;5;241m+\u001b[39m kl_divergence \u001b[38;5;241m*\u001b[39m kl_weight\n\u001b[1;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","Cell \u001b[0;32mIn[48], line 147\u001b[0m, in \u001b[0;36mMFVI_NN.kl_divergence\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Sum KL divergence from shared layers\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 147\u001b[0m     kl_div \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkl_divergence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingle_head:\n\u001b[1;32m    149\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_specific_layers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","Cell \u001b[0;32mIn[48], line 87\u001b[0m, in \u001b[0;36mMFVI_Layer.kl_divergence\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m     85\u001b[0m W_std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_logv)\n\u001b[1;32m     86\u001b[0m b_std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_logv)\n\u001b[0;32m---> 87\u001b[0m prior_W_std \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior_W_logv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m prior_b_std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior_b_logv)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Calculate KL divergence for weights using the standard deviation-based formula\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["vcl_results = {}\n","coreset_results = {}\n","for coreset_size in [200, 400, 1000, 2500, 5000]:\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10, single_head=True).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    vcl_trend, coreset_trend = run_vcl(model,  pmnist_train_loaders,pmnist_test_loaders, optimizer, epoch_per_task, coreset_size, \n","        beta=1, return_coreset_score=False)\n","    vcl_results[coreset_size] = vcl_trend\n","    coreset_results[coreset_size] = coreset_trend\n","vcl_trend =  run_vcl(model,  pmnist_train_loaders,pmnist_test_loaders, optimizer, epoch_per_task, coreset_size=0, beta=1)\n","vcl_results[0] = vcl_trend"]},{"cell_type":"markdown","metadata":{},"source":["## split no core"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["tasks = [(0, 1), (2, 3), (4, 5), (6, 7), (8, 9)]\n","split_train_loaders, split_test_loaders = create_split_dataloaders(mnist_trainset, mnist_testset, tasks, batch_size=256)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.73%\n","Average Accuracy across 3 tasks: 97.64%\n","Average Accuracy across 4 tasks: 97.37%\n","Average Accuracy across 5 tasks: 97.08%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.76%\n","Average Accuracy across 3 tasks: 98.83%\n","Average Accuracy across 4 tasks: 98.68%\n","Average Accuracy across 5 tasks: 96.74%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.46%\n","Average Accuracy across 3 tasks: 99.13%\n","Average Accuracy across 4 tasks: 96.26%\n","Average Accuracy across 5 tasks: 95.84%\n","Average Accuracy across 1 tasks: 99.95%\n","Average Accuracy across 2 tasks: 99.66%\n","Average Accuracy across 3 tasks: 98.82%\n","Average Accuracy across 4 tasks: 95.63%\n","Average Accuracy across 5 tasks: 92.63%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.59%\n","Average Accuracy across 3 tasks: 98.25%\n","Average Accuracy across 4 tasks: 95.73%\n","Average Accuracy across 5 tasks: 94.85%\n"]}],"source":["\n","coreset_size = 0\n","trends_1 = []\n","for i in range(10):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model,  split_train_loaders,split_test_loaders, optimizer, epoch_per_task, coreset_size, beta=1e-2, binary_labels = tasks)\n","    trends_1.append(trend)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 99.86%\n","Average Accuracy across 2 tasks: 99.59%\n","Average Accuracy across 3 tasks: 98.99%\n","Average Accuracy across 4 tasks: 97.95%\n","Average Accuracy across 5 tasks: 92.80%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.64%\n","Average Accuracy across 3 tasks: 99.40%\n","Average Accuracy across 4 tasks: 98.87%\n","Average Accuracy across 5 tasks: 96.44%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.64%\n","Average Accuracy across 3 tasks: 98.37%\n","Average Accuracy across 4 tasks: 93.14%\n","Average Accuracy across 5 tasks: 97.01%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.54%\n","Average Accuracy across 3 tasks: 96.81%\n","Average Accuracy across 4 tasks: 94.45%\n","Average Accuracy across 5 tasks: 94.69%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.76%\n","Average Accuracy across 3 tasks: 98.92%\n","Average Accuracy across 4 tasks: 97.14%\n","Average Accuracy across 5 tasks: 92.71%\n"]}],"source":["trends_2 = []\n","for i in range(5):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model,  split_train_loaders,split_test_loaders, optimizer, epoch_per_task, coreset_size, beta=1, binary_labels = tasks)\n","    trends_2.append(trend)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 99.76%\n","Average Accuracy across 2 tasks: 99.02%\n","Average Accuracy across 3 tasks: 98.38%\n","Average Accuracy across 4 tasks: 98.63%\n","Average Accuracy across 5 tasks: 97.39%\n","Average Accuracy across 1 tasks: 99.86%\n","Average Accuracy across 2 tasks: 98.90%\n","Average Accuracy across 3 tasks: 98.65%\n","Average Accuracy across 4 tasks: 98.56%\n","Average Accuracy across 5 tasks: 97.83%\n","Average Accuracy across 1 tasks: 99.95%\n","Average Accuracy across 2 tasks: 99.05%\n","Average Accuracy across 3 tasks: 98.33%\n","Average Accuracy across 4 tasks: 98.41%\n","Average Accuracy across 5 tasks: 98.01%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 98.51%\n","Average Accuracy across 3 tasks: 98.68%\n","Average Accuracy across 4 tasks: 98.80%\n","Average Accuracy across 5 tasks: 98.00%\n","Average Accuracy across 1 tasks: 99.86%\n","Average Accuracy across 2 tasks: 98.78%\n","Average Accuracy across 3 tasks: 98.01%\n","Average Accuracy across 4 tasks: 98.57%\n","Average Accuracy across 5 tasks: 97.72%\n"]}],"source":["\n","trends_3 = []\n","for i in range(5):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, split_train_loaders,split_test_loaders, optimizer, epoch_per_task, coreset_size, beta=1e2, binary_labels = tasks)\n","    trends_3.append(trend)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/plain":["200"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["coreset_size\n"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9952718676122931\n","Average Accuracy across 1 tasks: 99.91%\n","0.9492654260528894\n","0\n","0.009456264775413725 0.10146914789422112 0 all\n","0.42849767274278683 beta\n","Average Accuracy across 2 tasks: 99.73%\n","0.9790821771611526\n","1\n","0.10146914789422112 0.04183564567769471 0.4677617709992642 all\n","128.70075447851292 beta\n","Average Accuracy across 3 tasks: 99.31%\n","0.9854984894259818\n","2\n","0.10146914789422112 0.029003021148036323 0 all\n","1.949236373939389 beta\n","Average Accuracy across 4 tasks: 98.99%\n","0.9598587997982854\n","3\n","0.10146914789422112 0.08028240040342927 0.2372270358654626 all\n","10.805755420837402 beta\n","Average Accuracy across 5 tasks: 98.44%\n","0.9955555555555555\n","Average Accuracy across 1 tasks: 99.91%\n","0.9564152791381\n","0\n","0.008888888888888946 0.08716944172380003 0.056914691989304614 all\n","0.8213656881538066 beta\n","Average Accuracy across 2 tasks: 99.56%\n","0.9702241195304161\n","1\n","0.08716944172380003 0.05955176093916781 0.505907912791584 all\n","136.17656475885408 beta\n","Average Accuracy across 3 tasks: 98.70%\n","0.9834843907351459\n","2\n","0.08716944172380003 0.03303121852970814 0 all\n","1.6464664774651294 beta\n","Average Accuracy across 4 tasks: 98.92%\n","0.9580433686333837\n","3\n","0.08716944172380003 0.08391326273323263 0.42726484837719797 all\n","52.73319795040565 beta\n","Average Accuracy across 5 tasks: 98.21%\n","0.9948936170212767\n","Average Accuracy across 1 tasks: 99.91%\n","0.9552399608227228\n","0\n","0.01021276595744669 0.08952007835455444 0 all\n","0.48169346057283596 beta\n","Average Accuracy across 2 tasks: 99.64%\n","0.9723585912486659\n","1\n","0.08952007835455444 0.05528281750266828 0.5064864458930459 all\n","145.5106654980942 beta\n","Average Accuracy across 3 tasks: 99.31%\n","0.9869083585095669\n","2\n","0.08952007835455444 0.02618328298086614 0 all\n","1.7920378634051783 beta\n","Average Accuracy across 4 tasks: 93.92%\n","0.9515885022692888\n","3\n","0.08952007835455444 0.09682299546142237 0.3729037242089678 all\n","29.00034926920236 beta\n","Average Accuracy across 5 tasks: 98.66%\n","0.9947044917257684\n","Average Accuracy across 1 tasks: 99.91%\n","0.9550440744368267\n","0\n","0.010591016548463283 0.08991185112634659 0.005887726757514339 all\n","0.5084726159254432 beta\n","Average Accuracy across 2 tasks: 99.68%\n","0.9737459978655284\n","1\n","0.08991185112634659 0.0525080042689432 0.3819161638682545 all\n","47.564183168778285 beta\n","Average Accuracy across 3 tasks: 99.31%\n","0.985901309164149\n","2\n","0.08991185112634659 0.02819738167170205 0.16705457515916142 all\n","8.223868900222616 beta\n","Average Accuracy across 4 tasks: 98.85%\n","0.957337367624811\n","3\n","0.08991185112634659 0.08532526475037794 0.5124137149577074 all\n","116.95026368362866 beta\n","Average Accuracy across 5 tasks: 98.31%\n","0.9960283687943262\n","Average Accuracy across 1 tasks: 99.91%\n","0.9545543584720863\n","0\n","0.007943262411347574 0.0908912830558275 0.09125976474147136 all\n","1.079560476628306 beta\n","Average Accuracy across 2 tasks: 99.78%\n","0.9662753468516542\n","1\n","0.0908912830558275 0.06744930629669166 0.5163188053701034 all\n","144.22585709010124 beta\n","Average Accuracy across 3 tasks: 99.15%\n","0.9843907351460223\n","2\n","0.0908912830558275 0.031218529707955467 0 all\n","1.732570890473255 beta\n","Average Accuracy across 4 tasks: 97.39%\n","0.9509833585476551\n","3\n","0.0908912830558275 0.09803328290468971 0.2810109387835021 all\n","12.458786848059278 beta\n","Average Accuracy across 5 tasks: 98.54%\n"]}],"source":["trends_4 = []\n","for i in range(5):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_auto_vcl(model, \n","        split_train_loaders,\n","        split_test_loaders,\n","        optimizer, \n","        epoch_per_task, \n","        coreset_size,\n","        binary_labels = tasks,\n","        dor = True)\n","    trends_4.append(trend)"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'trends_1' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[66], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m trends:\n\u001b[1;32m      4\u001b[0m         plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(t[\u001b[38;5;241m0\u001b[39m])),np\u001b[38;5;241m.\u001b[39mmean(t, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m plot_trends([\u001b[43mtrends_1\u001b[49m,trends_2,trends_3,trends_4,])\n","\u001b[0;31mNameError\u001b[0m: name 'trends_1' is not defined"]}],"source":["import matplotlib.pyplot as plt\n","# def plot_trends(trends):\n","#     for t in trends:\n","#         plt.plot(range(len(t[0])),np.mean(t, axis = 0))\n","plot_trends([trends_1,trends_2,trends_3,trends_4,])"]},{"cell_type":"markdown","metadata":{},"source":["## Intentially alike\n"]},{"cell_type":"code","execution_count":226,"metadata":{},"outputs":[],"source":["tasks = [(0, 1), (2, 3), (4, 5), (6, 7), (8, 9)]\n","split_alike_train_loaders, split_alike_test_loaders = create_split_dataloaders(mnist_trainset, mnist_testset, tasks, batch_size=batch_size)"]},{"cell_type":"code","execution_count":190,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.66%\n","Average Accuracy across 3 tasks: 99.46%\n","Average Accuracy across 4 tasks: 98.49%\n","Average Accuracy across 5 tasks: 98.56%\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[190], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m MFVI_NN(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, [\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m], \u001b[38;5;241m2\u001b[39m, num_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tasks))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m trend \u001b[38;5;241m=\u001b[39m \u001b[43mrun_vcl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43msplit_alike_train_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43msplit_alike_test_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoreset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m\u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m trends_alike_1\u001b[38;5;241m.\u001b[39mappend(trend)\n","Cell \u001b[0;32mIn[138], line 23\u001b[0m, in \u001b[0;36mrun_vcl\u001b[0;34m(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta, binary_labels)\u001b[0m\n\u001b[1;32m     21\u001b[0m         model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# for prediction\u001b[39;00m\n","Cell \u001b[0;32mIn[173], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label)\u001b[0m\n\u001b[1;32m     18\u001b[0m     kl_divergence \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mkl_divergence()\n\u001b[1;32m     19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m reconstruction_loss \u001b[38;5;241m+\u001b[39m kl_divergence \u001b[38;5;241m*\u001b[39m kl_weight\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["coreset_size = 0\n","trends_alike_1 = []\n","torch.manual_seed(SEED)\n","for i in range(10):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model,  split_alike_train_loaders,split_alike_test_loaders, optimizer, epoch_per_task, coreset_size, \n","    beta=1e-2, binary_labels = tasks)\n","    trends_alike_1.append(trend)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.51%\n","Average Accuracy across 3 tasks: 99.43%\n","Average Accuracy across 4 tasks: 98.89%\n","Average Accuracy across 5 tasks: 96.65%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.56%\n","Average Accuracy across 3 tasks: 98.74%\n","Average Accuracy across 4 tasks: 94.36%\n","Average Accuracy across 5 tasks: 96.41%\n","Average Accuracy across 1 tasks: 99.95%\n","Average Accuracy across 2 tasks: 99.67%\n","Average Accuracy across 3 tasks: 99.43%\n","Average Accuracy across 4 tasks: 94.82%\n","Average Accuracy across 5 tasks: 94.30%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.65%\n","Average Accuracy across 3 tasks: 99.45%\n","Average Accuracy across 4 tasks: 88.87%\n","Average Accuracy across 5 tasks: 96.86%\n","Average Accuracy across 1 tasks: 99.95%\n","Average Accuracy across 2 tasks: 99.46%\n","Average Accuracy across 3 tasks: 99.54%\n","Average Accuracy across 4 tasks: 97.31%\n","Average Accuracy across 5 tasks: 92.54%\n","Average Accuracy across 1 tasks: 99.95%\n","Average Accuracy across 2 tasks: 99.72%\n","Average Accuracy across 3 tasks: 98.49%\n","Average Accuracy across 4 tasks: 95.16%\n","Average Accuracy across 5 tasks: 90.46%\n","Average Accuracy across 1 tasks: 99.95%\n","Average Accuracy across 2 tasks: 99.63%\n","Average Accuracy across 3 tasks: 99.40%\n","Average Accuracy across 4 tasks: 93.04%\n","Average Accuracy across 5 tasks: 94.71%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.60%\n","Average Accuracy across 3 tasks: 99.17%\n","Average Accuracy across 4 tasks: 91.93%\n","Average Accuracy across 5 tasks: 92.31%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.67%\n","Average Accuracy across 3 tasks: 99.47%\n","Average Accuracy across 4 tasks: 96.35%\n","Average Accuracy across 5 tasks: 92.15%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.72%\n","Average Accuracy across 3 tasks: 99.38%\n","Average Accuracy across 4 tasks: 96.31%\n","Average Accuracy across 5 tasks: 97.02%\n"]}],"source":["coreset_size = 0\n","trends_alike_2 = []\n","torch.manual_seed(SEED)\n","for i in range(10):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model,  split_alike_train_loaders,split_alike_test_loaders, optimizer, epoch_per_task, coreset_size, \n","        beta=1, binary_labels = tasks)\n","    trends_alike_2.append(trend)"]},{"cell_type":"code","execution_count":191,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 99.23%\n","Average Accuracy across 3 tasks: 98.92%\n","Average Accuracy across 4 tasks: 99.34%\n","Average Accuracy across 5 tasks: 99.05%\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[191], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m MFVI_NN(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, [\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m], \u001b[38;5;241m2\u001b[39m, num_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tasks))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m trend \u001b[38;5;241m=\u001b[39m \u001b[43mrun_vcl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43msplit_alike_train_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43msplit_alike_test_loaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoreset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m trends_alike_3\u001b[38;5;241m.\u001b[39mappend(trend)\n","Cell \u001b[0;32mIn[138], line 23\u001b[0m, in \u001b[0;36mrun_vcl\u001b[0;34m(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta, binary_labels)\u001b[0m\n\u001b[1;32m     21\u001b[0m         model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# for prediction\u001b[39;00m\n","Cell \u001b[0;32mIn[173], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, trainloader, optimizer, epoch, device, kl_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, task_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, binary_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m      6\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the images\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/functional.py:166\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    165\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[0;32m--> 166\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    169\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/PIL/Image.py:701\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 701\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRecursionError\u001b[39;00m)):\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/PIL/Image.py:758\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args \u001b[38;5;241m==\u001b[39m ():\n\u001b[1;32m    756\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m--> 758\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/PIL/Image.py:850\u001b[0m, in \u001b[0;36mImage.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    836\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;124;03m    Allocates storage for the image and loads the pixel data.  In\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;124;03m    normal cases, you don't need to call this method, since the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;124;03m    :rtype: :ref:`PixelAccess` or :py:class:`PIL.PyAccess`\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpalette \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mdirty:\n\u001b[1;32m    851\u001b[0m         \u001b[38;5;66;03m# realize palette\u001b[39;00m\n\u001b[1;32m    852\u001b[0m         mode, arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mgetdata()\n\u001b[1;32m    853\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim\u001b[38;5;241m.\u001b[39mputpalette(mode, arr)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["coreset_size = 0\n","trends_alike_3 = []\n","torch.manual_seed(SEED)\n","for i in range(10):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model,  split_alike_train_loaders,split_alike_test_loaders,\n","     optimizer, epoch_per_task, coreset_size, \n","        beta=1e2, binary_labels = tasks)\n","    trends_alike_3.append(trend)"]},{"cell_type":"code","execution_count":227,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9667612293144208\n","Average Accuracy across 1 tasks: 99.91%\n","0.8170421155729677\n","0\n","0.5416258570029383 raw_pred\n","0.06647754137115847 0.3659157688540646 0.015254888028760561 all\n","0.0729905510109667 beta\n","Average Accuracy across 2 tasks: 99.66%\n","0.7935965848452508\n","1\n","0.7764140875133404 raw_pred\n","0.3659157688540646 0.4128068303094985 0.6290822684137637 all\n","213.18901736295032 beta\n","Average Accuracy across 3 tasks: 99.07%\n","0.9110271903323263\n","2\n","0.47532729103726085 raw_pred\n","0.4128068303094985 0.17794561933534747 0.010916041445929923 all\n","9.618536772691854 beta\n","Average Accuracy across 4 tasks: 97.50%\n","0.6989914271306101\n","3\n","0.7231467473524962 raw_pred\n","0.4128068303094985 0.6020171457387797 0.3688705894889076 all\n","5.231679085537842 beta\n","Average Accuracy across 5 tasks: 98.57%\n","0.9621749408983451\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[227], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m MFVI_NN(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, [\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m], \u001b[38;5;241m2\u001b[39m, num_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tasks))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m trend, alike_beta \u001b[38;5;241m=\u001b[39m \u001b[43mrun_auto_vcl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_alike_train_loaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_alike_test_loaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoreset_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbinary_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_betas\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m trends_alike_4\u001b[38;5;241m.\u001b[39mappend(trend)\n\u001b[1;32m     16\u001b[0m alike_betas\u001b[38;5;241m.\u001b[39mappend(alike_beta)\n","Cell \u001b[0;32mIn[225], line 118\u001b[0m, in \u001b[0;36mrun_auto_vcl\u001b[0;34m(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta_star, raw_training_epoch, raw_train_size, binary_labels, dor, return_betas)\u001b[0m\n\u001b[1;32m    116\u001b[0m         model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m--> 118\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# for prediction\u001b[39;00m\n","Cell \u001b[0;32mIn[173], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, trainloader, optimizer, epoch, device, kl_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, task_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, binary_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m      6\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the images\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/functional.py:363\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/_functional_tensor.py:925\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, leading to division by zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 925\u001b[0m     mean \u001b[38;5;241m=\u001b[39m \u001b[43mmean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m std\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    927\u001b[0m     std \u001b[38;5;241m=\u001b[39m std\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["trends_alike_4 = []\n","alike_betas = []\n","torch.manual_seed(SEED)\n","for i in range(10):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend, alike_beta = run_auto_vcl(model, \n","        split_alike_train_loaders,\n","        split_alike_test_loaders,\n","        optimizer, \n","        epoch_per_task, \n","        coreset_size,\n","        binary_labels = tasks,\n","        return_betas = True)\n","    trends_alike_4.append(trend)\n","    alike_betas.append(alike_beta)"]},{"cell_type":"code","execution_count":185,"metadata":{},"outputs":[],"source":["model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(tasks)).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","train(model, split_alike_train_loaders[0], optimizer, 1, device, 1, 0, binary_label=[0,1])"]},{"cell_type":"code","execution_count":188,"metadata":{},"outputs":[{"data":{"text/plain":["(0.014337299053824108, 0.7378864790032302)"]},"execution_count":188,"metadata":{},"output_type":"execute_result"}],"source":["test(model, split_alike_test_loaders[1], device,task_id=0, binary_label=[2,1])"]},{"cell_type":"code","execution_count":170,"metadata":{},"outputs":[{"data":{"text/plain":["7"]},"execution_count":170,"metadata":{},"output_type":"execute_result"}],"source":["split_alike_train_loaders[1].dataset[2][1]"]},{"cell_type":"code","execution_count":144,"metadata":{},"outputs":[{"data":{"text/html":["\n","<div id=\"altair-viz-183e309997ce4f168f167133a6c04b6d\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-183e309997ce4f168f167133a6c04b6d\") {\n","      outputDiv = document.getElementById(\"altair-viz-183e309997ce4f168f167133a6c04b6d\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 15, \"titleFontSize\": 20}, \"legend\": {\"labelFontSize\": 15, \"titleFontSize\": 15}, \"title\": {\"fontSize\": 24}}, \"data\": {\"name\": \"data-4ae3d9d60a6be8a7117606b967558499\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Series\", \"legend\": {\"title\": \"Model\"}, \"scale\": {\"scheme\": \"category10\"}, \"sort\": [\"beta = 0.01\", \"beta = 1\", \"beta = 100\", \"AutoVCL\"], \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"# of tasks\", \"type\": \"quantitative\"}, {\"field\": \"Values\", \"type\": \"quantitative\"}, {\"field\": \"Series\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"values\": [0, 1, 2, 3, 4]}, \"field\": \"# of tasks\", \"title\": \"# tasks\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Values\", \"scale\": {\"domain\": [0.9, 1]}, \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Accuracy Trends in the Permuated MNIST Experiment\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-4ae3d9d60a6be8a7117606b967558499\": [{\"# of tasks\": 0, \"Series\": \"beta = 0.01\", \"Values\": 0.9992434988179669}, {\"# of tasks\": 1, \"Series\": \"beta = 0.01\", \"Values\": 0.9965268954803463}, {\"# of tasks\": 2, \"Series\": \"beta = 0.01\", \"Values\": 0.9906304884149615}, {\"# of tasks\": 3, \"Series\": \"beta = 0.01\", \"Values\": 0.9285116175920891}, {\"# of tasks\": 4, \"Series\": \"beta = 0.01\", \"Values\": 0.906473961392624}, {\"# of tasks\": 0, \"Series\": \"beta = 1\", \"Values\": 0.9992434988179669}, {\"# of tasks\": 1, \"Series\": \"beta = 1\", \"Values\": 0.996199329944875}, {\"# of tasks\": 2, \"Series\": \"beta = 1\", \"Values\": 0.9924928444305763}, {\"# of tasks\": 3, \"Series\": \"beta = 1\", \"Values\": 0.9470460555078464}, {\"# of tasks\": 4, \"Series\": \"beta = 1\", \"Values\": 0.9434070645807797}, {\"# of tasks\": 0, \"Series\": \"beta = 100\", \"Values\": 0.9992434988179669}, {\"# of tasks\": 1, \"Series\": \"beta = 100\", \"Values\": 0.9876453486152158}, {\"# of tasks\": 2, \"Series\": \"beta = 100\", \"Values\": 0.9832658011566163}, {\"# of tasks\": 3, \"Series\": \"beta = 100\", \"Values\": 0.9855933136005477}, {\"# of tasks\": 4, \"Series\": \"beta = 100\", \"Values\": 0.9824450556294622}, {\"# of tasks\": 0, \"Series\": \"AutoVCL\", \"Values\": 0.9991594431310743}, {\"# of tasks\": 1, \"Series\": \"AutoVCL\", \"Values\": 0.9953123446031249}, {\"# of tasks\": 2, \"Series\": \"AutoVCL\", \"Values\": 0.9776139087346851}, {\"# of tasks\": 3, \"Series\": \"AutoVCL\", \"Values\": 0.9777427205714907}, {\"# of tasks\": 4, \"Series\": \"AutoVCL\", \"Values\": 0.9720439220164452}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.Chart(...)"]},"metadata":{},"output_type":"display_data"}],"source":["plot_trends([trends_alike_1, trends_alike_2, trends_alike_3, trends_alike_4], lower = 0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["f_mnist_train_dataset = datasets.FashionMNIST(\n","    root='data', \n","    train=True, \n","    download=True, \n","    transform=transform_mnist\n",")\n","\n","f_mnist_test_dataset = datasets.FashionMNIST(\n","    root='data', \n","    train=False, \n","    download=True, \n","    transform=transform_mnist\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## different difficulties"]},{"cell_type":"code","execution_count":126,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["transform_cifar = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=1), # Convert image to grayscale\n","    transforms.Resize((28, 28)),\n","    transforms.ToTensor(), \n","    transforms.Normalize((0.5,), (0.5,))])\n","\n","# Load the CIFAR-10 training dataset with the defined transform\n","cifar_train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_cifar)\n","\n","# Load the CIFAR-10 test dataset with the defined transform\n","cifar_test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar)\n"]},{"cell_type":"code","execution_count":127,"metadata":{},"outputs":[],"source":["tasks = [(0,1),(2,3),(4,5),(6,7),(8,9)]\n","mixed_tasks = [tasks[i//2] for i in range(len(tasks)*2)]"]},{"cell_type":"code","execution_count":129,"metadata":{},"outputs":[],"source":["torch.manual_seed(SEED)\n","mnist_train_loaders, mnist_test_loaders = \\\n","    create_split_dataloaders(mnist_trainset, mnist_testset, tasks, batch_size=batch_size)\n","cifar_train_loaders, cifar_test_loaders = \\\n","    create_split_dataloaders(cifar_train_dataset, cifar_test_dataset, tasks, batch_size=batch_size)"]},{"cell_type":"code","execution_count":130,"metadata":{},"outputs":[],"source":["mixed_train_loaders = [mnist_train_loaders, cifar_train_loaders]\n","mixed_test_loaders = [mnist_test_loaders, cifar_test_loaders]\n","\n","mixed_train_loaders = [mixed_train_loaders[i%2][i//2] for i in range(len(mixed_tasks))]\n","mixed_test_loaders = [mixed_test_loaders[i%2][i//2] for i in range(len(mixed_tasks))]"]},{"cell_type":"code","execution_count":131,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 93.26%\n","Average Accuracy across 3 tasks: 93.34%\n","Average Accuracy across 4 tasks: 83.85%\n","Average Accuracy across 5 tasks: 83.81%\n","Average Accuracy across 6 tasks: 82.11%\n","Average Accuracy across 7 tasks: 77.71%\n","Average Accuracy across 8 tasks: 79.99%\n","Average Accuracy across 9 tasks: 82.04%\n","Average Accuracy across 10 tasks: 79.90%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 93.48%\n","Average Accuracy across 3 tasks: 93.87%\n","Average Accuracy across 4 tasks: 86.28%\n","Average Accuracy across 5 tasks: 83.17%\n","Average Accuracy across 6 tasks: 82.75%\n","Average Accuracy across 7 tasks: 79.27%\n","Average Accuracy across 8 tasks: 79.36%\n","Average Accuracy across 9 tasks: 80.23%\n","Average Accuracy across 10 tasks: 77.54%\n","Average Accuracy across 1 tasks: 99.76%\n","Average Accuracy across 2 tasks: 93.29%\n","Average Accuracy across 3 tasks: 92.39%\n","Average Accuracy across 4 tasks: 86.93%\n","Average Accuracy across 5 tasks: 85.35%\n","Average Accuracy across 6 tasks: 79.10%\n","Average Accuracy across 7 tasks: 66.20%\n","Average Accuracy across 8 tasks: 78.11%\n","Average Accuracy across 9 tasks: 68.55%\n","Average Accuracy across 10 tasks: 73.23%\n","Average Accuracy across 1 tasks: 99.86%\n","Average Accuracy across 2 tasks: 92.51%\n","Average Accuracy across 3 tasks: 92.31%\n","Average Accuracy across 4 tasks: 84.66%\n","Average Accuracy across 5 tasks: 82.51%\n","Average Accuracy across 6 tasks: 83.63%\n","Average Accuracy across 7 tasks: 67.33%\n","Average Accuracy across 8 tasks: 77.09%\n","Average Accuracy across 9 tasks: 77.37%\n","Average Accuracy across 10 tasks: 78.71%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 93.43%\n","Average Accuracy across 3 tasks: 89.06%\n","Average Accuracy across 4 tasks: 83.84%\n","Average Accuracy across 5 tasks: 86.62%\n","Average Accuracy across 6 tasks: 82.61%\n","Average Accuracy across 7 tasks: 76.94%\n","Average Accuracy across 8 tasks: 82.51%\n","Average Accuracy across 9 tasks: 79.51%\n","Average Accuracy across 10 tasks: 80.31%\n"]}],"source":["coreset_size= 0\n","torch.manual_seed(SEED)\n","mixed_trends_1 = []\n","for i in range(5):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(mixed_tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, mixed_train_loaders,mixed_test_loaders, optimizer, epoch_per_task, coreset_size, beta=1e-2, binary_labels = mixed_tasks)\n","    mixed_trends_1.append(trend)"]},{"cell_type":"code","execution_count":132,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 93.28%\n","Average Accuracy across 3 tasks: 94.46%\n","Average Accuracy across 4 tasks: 85.02%\n","Average Accuracy across 5 tasks: 87.14%\n","Average Accuracy across 6 tasks: 82.45%\n","Average Accuracy across 7 tasks: 83.87%\n","Average Accuracy across 8 tasks: 80.21%\n","Average Accuracy across 9 tasks: 82.58%\n","Average Accuracy across 10 tasks: 81.63%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 93.23%\n","Average Accuracy across 3 tasks: 94.03%\n","Average Accuracy across 4 tasks: 85.22%\n","Average Accuracy across 5 tasks: 87.65%\n","Average Accuracy across 6 tasks: 84.47%\n","Average Accuracy across 7 tasks: 81.84%\n","Average Accuracy across 8 tasks: 83.43%\n","Average Accuracy across 9 tasks: 83.55%\n","Average Accuracy across 10 tasks: 82.06%\n","Average Accuracy across 1 tasks: 99.76%\n","Average Accuracy across 2 tasks: 93.03%\n","Average Accuracy across 3 tasks: 92.69%\n","Average Accuracy across 4 tasks: 87.62%\n","Average Accuracy across 5 tasks: 85.79%\n","Average Accuracy across 6 tasks: 84.54%\n","Average Accuracy across 7 tasks: 83.63%\n","Average Accuracy across 8 tasks: 81.56%\n","Average Accuracy across 9 tasks: 82.31%\n","Average Accuracy across 10 tasks: 82.57%\n","Average Accuracy across 1 tasks: 99.86%\n","Average Accuracy across 2 tasks: 92.58%\n","Average Accuracy across 3 tasks: 92.98%\n","Average Accuracy across 4 tasks: 84.87%\n","Average Accuracy across 5 tasks: 86.42%\n","Average Accuracy across 6 tasks: 81.09%\n","Average Accuracy across 7 tasks: 81.17%\n","Average Accuracy across 8 tasks: 83.17%\n","Average Accuracy across 9 tasks: 82.02%\n","Average Accuracy across 10 tasks: 82.86%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 93.43%\n","Average Accuracy across 3 tasks: 90.14%\n","Average Accuracy across 4 tasks: 83.43%\n","Average Accuracy across 5 tasks: 86.13%\n","Average Accuracy across 6 tasks: 82.91%\n","Average Accuracy across 7 tasks: 81.57%\n","Average Accuracy across 8 tasks: 82.74%\n","Average Accuracy across 9 tasks: 82.75%\n","Average Accuracy across 10 tasks: 80.04%\n"]}],"source":["torch.manual_seed(SEED)\n","mixed_trends_2 = []\n","for i in range(5):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(mixed_tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, mixed_train_loaders,mixed_test_loaders, optimizer, epoch_per_task, coreset_size, beta=1, binary_labels = mixed_tasks)\n","    mixed_trends_2.append(trend)"]},{"cell_type":"code","execution_count":133,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 89.58%\n","Average Accuracy across 3 tasks: 91.79%\n","Average Accuracy across 4 tasks: 84.56%\n","Average Accuracy across 5 tasks: 87.47%\n","Average Accuracy across 6 tasks: 84.63%\n","Average Accuracy across 7 tasks: 86.83%\n","Average Accuracy across 8 tasks: 84.39%\n","Average Accuracy across 9 tasks: 85.76%\n","Average Accuracy across 10 tasks: 85.10%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 89.53%\n","Average Accuracy across 3 tasks: 92.17%\n","Average Accuracy across 4 tasks: 85.96%\n","Average Accuracy across 5 tasks: 88.29%\n","Average Accuracy across 6 tasks: 85.02%\n","Average Accuracy across 7 tasks: 86.78%\n","Average Accuracy across 8 tasks: 85.79%\n","Average Accuracy across 9 tasks: 86.67%\n","Average Accuracy across 10 tasks: 86.10%\n","Average Accuracy across 1 tasks: 99.76%\n","Average Accuracy across 2 tasks: 88.05%\n","Average Accuracy across 3 tasks: 90.87%\n","Average Accuracy across 4 tasks: 85.06%\n","Average Accuracy across 5 tasks: 87.75%\n","Average Accuracy across 6 tasks: 84.68%\n","Average Accuracy across 7 tasks: 86.25%\n","Average Accuracy across 8 tasks: 84.76%\n","Average Accuracy across 9 tasks: 85.76%\n","Average Accuracy across 10 tasks: 85.39%\n","Average Accuracy across 1 tasks: 99.86%\n","Average Accuracy across 2 tasks: 89.20%\n","Average Accuracy across 3 tasks: 91.81%\n","Average Accuracy across 4 tasks: 84.77%\n","Average Accuracy across 5 tasks: 87.92%\n","Average Accuracy across 6 tasks: 84.95%\n","Average Accuracy across 7 tasks: 86.84%\n","Average Accuracy across 8 tasks: 85.01%\n","Average Accuracy across 9 tasks: 86.43%\n","Average Accuracy across 10 tasks: 85.45%\n","Average Accuracy across 1 tasks: 99.91%\n","Average Accuracy across 2 tasks: 90.05%\n","Average Accuracy across 3 tasks: 92.25%\n","Average Accuracy across 4 tasks: 85.80%\n","Average Accuracy across 5 tasks: 88.01%\n","Average Accuracy across 6 tasks: 84.42%\n","Average Accuracy across 7 tasks: 86.40%\n","Average Accuracy across 8 tasks: 84.00%\n","Average Accuracy across 9 tasks: 83.62%\n","Average Accuracy across 10 tasks: 82.95%\n"]}],"source":["torch.manual_seed(SEED)\n","mixed_trends_3 = []\n","for i in range(5):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(mixed_tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, mixed_train_loaders,mixed_test_loaders, optimizer, epoch_per_task, coreset_size, beta=1e2, binary_labels = mixed_tasks)\n","    mixed_trends_3.append(trend)"]},{"cell_type":"code","execution_count":228,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9836406619385342\n","Average Accuracy across 1 tasks: 99.91%\n","0.7062000000000002\n","0\n","0.578 raw_pred\n","0.03271867612293167 0.5875999999999997 0.031068484159667384 all\n","0.00803061195761599 beta\n","Average Accuracy across 2 tasks: 93.50%\n","0.7895200783545544\n","1\n","0.4681684622918707 raw_pred\n","0.5875999999999997 0.4209598432908912 0.012575255575269687 all\n","5.210287033464248 beta\n","Average Accuracy across 3 tasks: 94.32%\n","0.5709500000000001\n","2\n","0.4655 raw_pred\n","0.5875999999999997 0.8580999999999999 0.013255481427098773 all\n","0.0935452900052146 beta\n","Average Accuracy across 4 tasks: 86.19%\n","0.7798292422625399\n","3\n","0.4018143009605123 raw_pred\n","0.8580999999999999 0.4403415154749202 0.0458132516264789 all\n","71.49685600561959 beta\n","Average Accuracy across 5 tasks: 86.88%\n","0.61615\n","4\n","0.4495 raw_pred\n","0.8580999999999999 0.7677 0.018163691028432512 all\n","2.718033243194161 beta\n","Average Accuracy across 6 tasks: 84.86%\n","0.8834340382678751\n","5\n","0.49244712990936557 raw_pred\n","0.8580999999999999 0.2331319234642497 0.007775723965440524 all\n","339.60588071277493 beta\n","Average Accuracy across 7 tasks: 87.79%\n","0.65915\n","6\n","0.5625 raw_pred\n","0.8580999999999999 0.6817 0.022977369910025615 all\n","6.273493894150464 beta\n","Average Accuracy across 8 tasks: 86.01%\n","0.7074634392334846\n","7\n","0.47402924861321233 raw_pred\n","0.8580999999999999 0.5850731215330307 0.011199926200902287 all\n","13.705889265104476 beta\n","Average Accuracy across 9 tasks: 86.68%\n","0.6880000000000001\n","8\n","0.5505 raw_pred\n","0.8580999999999999 0.6239999999999999 0.018163691028432512 all\n","10.210682313055129 beta\n","Average Accuracy across 10 tasks: 86.82%\n","0.9815130023640662\n","Average Accuracy across 1 tasks: 99.91%\n","0.7128500000000001\n","0\n","0.5885 raw_pred\n","0.03697399527186751 0.5742999999999998 0.03805224707099212 all\n","0.0100671136008673 beta\n","Average Accuracy across 2 tasks: 92.98%\n","0.7707639569049951\n","1\n","0.48237022526934376 raw_pred\n","0.5742999999999998 0.4584720861900098 0.009495423833349509 all\n","3.1717091170678735 beta\n","Average Accuracy across 3 tasks: 93.74%\n","0.5689500000000001\n","2\n","0.4725 raw_pred\n","0.5742999999999998 0.8620999999999999 0.011543752483922297 all\n","0.07851904520777965 beta\n","Average Accuracy across 4 tasks: 86.36%\n","0.8014407684098186\n","3\n","0.4759871931696905 raw_pred\n","0.8620999999999999 0.3971184631803628 0.010774459701981069 all\n","79.9878431076963 beta\n","Average Accuracy across 5 tasks: 89.08%\n","0.6252500000000001\n","4\n","0.434 raw_pred\n","0.8620999999999999 0.7494999999999998 0.024602428402739445 all\n","3.538422709095724 beta\n","Average Accuracy across 6 tasks: 85.47%\n","0.9205941591137965\n","5\n","0.33484390735146025 raw_pred\n","0.8620999999999999 0.158811681772407 0.154873436989763 all\n","2707.9897793020564 beta\n","Average Accuracy across 7 tasks: 83.37%\n","0.6660999999999999\n","6\n","0.5435 raw_pred\n","0.8620999999999999 0.6678000000000002 0.01582831396708983 all\n","6.926490706794431 beta\n","Average Accuracy across 8 tasks: 86.99%\n","0.7926878466969238\n","7\n","0.48613212304589004 raw_pred\n","0.8620999999999999 0.41462430660615235 0.008813286958314787 all\n","66.85839110255245 beta\n","Average Accuracy across 9 tasks: 87.69%\n","0.6829500000000001\n","8\n","0.5085 raw_pred\n","0.8620999999999999 0.6340999999999999 0.007923242124234979 all\n","8.784012972723035 beta\n","Average Accuracy across 10 tasks: 87.56%\n","0.9476595744680851\n","Average Accuracy across 1 tasks: 99.81%\n","0.7095999999999999\n","0\n","0.593 raw_pred\n","0.10468085106382974 0.5808000000000002 0.04148711930169583 all\n","0.01825878528146973 beta\n","Average Accuracy across 2 tasks: 93.43%\n","0.8136141038197845\n","1\n","0.3584720861900098 raw_pred\n","0.5808000000000002 0.372771792360431 0.10252839256839558 all\n","17.467324998092312 beta\n","Average Accuracy across 3 tasks: 93.94%\n","0.5834999999999999\n","2\n","0.5365 raw_pred\n","0.5808000000000002 0.8330000000000002 0.01378898850614155 all\n","0.1112643292163238 beta\n","Average Accuracy across 4 tasks: 86.31%\n","0.807470651013874\n","3\n","0.5240128068303095 raw_pred\n","0.8330000000000002 0.3850586979722519 0.010774459701981069 all\n","68.36960123966246 beta\n","Average Accuracy across 5 tasks: 87.72%\n","0.6193500000000001\n","4\n","0.4435 raw_pred\n","0.8330000000000002 0.7612999999999999 0.020432187314053014 all\n","2.33630075462344 beta\n","Average Accuracy across 6 tasks: 85.31%\n","0.9304632426988922\n","5\n","0.29154078549848944 raw_pred\n","0.8330000000000002 0.1390735146022155 0.3034726202230797 all\n","9763.295239996607 beta\n","Average Accuracy across 7 tasks: 86.31%\n","0.66015\n","6\n","0.498 raw_pred\n","0.8330000000000002 0.6797 0.006964089177762089 all\n","4.375788843893875 beta\n","Average Accuracy across 8 tasks: 86.29%\n","0.7415027735753907\n","7\n","0.4881492687846697 raw_pred\n","0.8330000000000002 0.5169944528492185 0.008467760648591487 all\n","19.856067073501983 beta\n","Average Accuracy across 9 tasks: 87.90%\n","0.6937\n","8\n","0.557 raw_pred\n","0.8330000000000002 0.6126 0.02063329722690622 all\n","9.20731897406517 beta\n","Average Accuracy across 10 tasks: 85.81%\n","0.9527659574468086\n","Average Accuracy across 1 tasks: 99.95%\n","0.7089\n","0\n","0.594 raw_pred\n","0.09446808510638283 0.5822 0.04228977184203377 all\n","0.016528423338362512 beta\n","Average Accuracy across 2 tasks: 93.66%\n","0.8733104799216456\n","1\n","0.5479921645445641 raw_pred\n","0.5822 0.25337904015670887 0.017290493640564484 all\n","24.23515568440418 beta\n","Average Accuracy across 3 tasks: 94.01%\n","0.58855\n","2\n","0.49 raw_pred\n","0.5822 0.8229 0.008162571153159897 all\n","0.11744925994678389 beta\n","Average Accuracy across 4 tasks: 85.30%\n","0.8241728922091781\n","3\n","0.28121664887940234 raw_pred\n","0.8229 0.3516542155816438 0.34879662587913807 all\n","1906.2051616003716 beta\n","Average Accuracy across 5 tasks: 87.93%\n","0.6076499999999999\n","4\n","0.473 raw_pred\n","0.8229 0.7847000000000002 0.011430203126470731 all\n","1.5795042998235893 beta\n","Average Accuracy across 6 tasks: 83.50%\n","0.916968781470292\n","5\n","0.28851963746223563 raw_pred\n","0.8229 0.16606243705941592 0.31639415283937344 all\n","7814.961865082925 beta\n","Average Accuracy across 7 tasks: 87.37%\n","0.6514\n","6\n","0.5625 raw_pred\n","0.8229 0.6972 0.022977369910025615 all\n","3.9328689901443994 beta\n","Average Accuracy across 8 tasks: 86.04%\n","0.7300050428643469\n","7\n","0.46343923348461924 raw_pred\n","0.8229 0.5399899142713063 0.013805525373207795 all\n","15.37667532412928 beta\n","Average Accuracy across 9 tasks: 87.57%\n","0.69575\n","8\n","0.62 raw_pred\n","0.8229 0.6085 0.06913842034334682 all\n","13.619265345754634 beta\n","Average Accuracy across 10 tasks: 87.12%\n","0.9790543735224585\n","Average Accuracy across 1 tasks: 99.91%\n","0.7038\n","0\n","0.589 raw_pred\n","0.041891252955083 0.5924 0.03841998550156536 all\n","0.008946330824665356 beta\n","Average Accuracy across 2 tasks: 93.05%\n","0.8093046033300686\n","1\n","0.5479921645445641 raw_pred\n","0.5924 0.3813907933398628 0.017290493640564484 all\n","8.18839531627983 beta\n","Average Accuracy across 3 tasks: 94.74%\n","0.58495\n","2\n","0.5115 raw_pred\n","0.5924 0.8301000000000001 0.008409068065962963 all\n","0.12101418276503709 beta\n","Average Accuracy across 4 tasks: 87.19%\n","0.7556029882604055\n","3\n","0.38687299893276417 raw_pred\n","0.8301000000000001 0.488794023479189 0.060798782650358874 all\n","40.589998632408474 beta\n","Average Accuracy across 5 tasks: 88.99%\n","0.61635\n","4\n","0.4565 raw_pred\n","0.8301000000000001 0.7673000000000001 0.01582831396708983 all\n","2.0630666368475863 beta\n","Average Accuracy across 6 tasks: 86.15%\n","0.9108257804632427\n","5\n","0.5055387713997986 raw_pred\n","0.8301000000000001 0.1783484390735146 0.007471020764623208 all\n","433.40141685874204 beta\n","Average Accuracy across 7 tasks: 88.06%\n","0.6563000000000001\n","6\n","0.472 raw_pred\n","0.8301000000000001 0.6873999999999998 0.011658416554833108 all\n","4.144132820611023 beta\n","Average Accuracy across 8 tasks: 86.93%\n","0.7445789208270297\n","7\n","0.524457892082703 raw_pred\n","0.8301000000000001 0.5108421583459406 0.010869751736406997 all\n","20.91752870133841 beta\n","Average Accuracy across 9 tasks: 87.25%\n","0.6865499999999999\n","8\n","0.5295 raw_pred\n","0.8301000000000001 0.6269000000000002 0.012009204309927387 all\n","7.258331800418036 beta\n","Average Accuracy across 10 tasks: 86.76%\n"]}],"source":["mixed_trends_4 = []\n","mixed_betas = []\n","torch.manual_seed(SEED)\n","for i in range(5):\n","    model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(mixed_tasks)).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend, m_beta = run_auto_vcl(model, \n","        mixed_train_loaders,\n","        mixed_test_loaders,\n","        optimizer, \n","        epoch_per_task, \n","        coreset_size,\n","        binary_labels = mixed_tasks,\n","        return_betas = True)\n","    mixed_trends_4.append(trend)\n","    mixed_betas.append(m_beta)"]},{"cell_type":"code","execution_count":224,"metadata":{},"outputs":[{"data":{"text/plain":["0.26894142136999516"]},"execution_count":224,"metadata":{},"output_type":"execute_result"}],"source":["scale_similarity(0.2, 0,1-0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# mixed_trends_5 = []\n","# for i in range(5):\n","#     model = MFVI_NN(28*28, [256, 256], 2, num_tasks = len(mixed_tasks)).to(device)\n","#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","#     trend = run_auto_vcl(model, \n","#         mixed_train_loaders,\n","#         mixed_test_loaders,\n","#         optimizer, \n","#         epoch_per_task, \n","#         coreset_size,\n","#         binary_labels = mixed_tasks,\n","#         dor = True)\n","#     mixed_trends_5.append(trend)"]},{"cell_type":"code","execution_count":229,"metadata":{},"outputs":[{"data":{"text/html":["\n","<div id=\"altair-viz-1d2d131ea7784a1fa26a3363a66c5f66\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-1d2d131ea7784a1fa26a3363a66c5f66\") {\n","      outputDiv = document.getElementById(\"altair-viz-1d2d131ea7784a1fa26a3363a66c5f66\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 15, \"titleFontSize\": 20}, \"legend\": {\"labelFontSize\": 15, \"titleFontSize\": 15}, \"title\": {\"fontSize\": 24}}, \"data\": {\"name\": \"data-f493c756c8cdf3962f4aca94aba48680\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Series\", \"legend\": {\"title\": \"Model\"}, \"scale\": {\"scheme\": \"category10\"}, \"sort\": [\"beta = 0.01\", \"beta = 1\", \"beta = 100\", \"AutoVCL\"], \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"# of tasks\", \"type\": \"quantitative\"}, {\"field\": \"Values\", \"type\": \"quantitative\"}, {\"field\": \"Series\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"values\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}, \"field\": \"# of tasks\", \"title\": \"# tasks\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Values\", \"scale\": {\"domain\": [0.7, 1]}, \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Accuracy Trends in the Permuated MNIST Experiment\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-f493c756c8cdf3962f4aca94aba48680\": [{\"# of tasks\": 0, \"Series\": \"beta = 0.01\", \"Values\": 0.9986761229314421}, {\"# of tasks\": 1, \"Series\": \"beta = 0.01\", \"Values\": 0.9319179669030733}, {\"# of tasks\": 2, \"Series\": \"beta = 0.01\", \"Values\": 0.9219464315566949}, {\"# of tasks\": 3, \"Series\": \"beta = 0.01\", \"Values\": 0.8511225210300012}, {\"# of tasks\": 4, \"Series\": \"beta = 0.01\", \"Values\": 0.8429180670114145}, {\"# of tasks\": 5, \"Series\": \"beta = 0.01\", \"Values\": 0.8204008173097689}, {\"# of tasks\": 6, \"Series\": \"beta = 0.01\", \"Values\": 0.7348719397256817}, {\"# of tasks\": 7, \"Series\": \"beta = 0.01\", \"Values\": 0.7941155893594078}, {\"# of tasks\": 8, \"Series\": \"beta = 0.01\", \"Values\": 0.7754111923717356}, {\"# of tasks\": 9, \"Series\": \"beta = 0.01\", \"Values\": 0.7793528814298464}, {\"# of tasks\": 0, \"Series\": \"beta = 1\", \"Values\": 0.9986761229314421}, {\"# of tasks\": 1, \"Series\": \"beta = 1\", \"Values\": 0.931090780141844}, {\"# of tasks\": 2, \"Series\": \"beta = 1\", \"Values\": 0.9285954551734305}, {\"# of tasks\": 3, \"Series\": \"beta = 1\", \"Values\": 0.8522970140061081}, {\"# of tasks\": 4, \"Series\": \"beta = 1\", \"Values\": 0.8662689407366002}, {\"# of tasks\": 5, \"Series\": \"beta = 1\", \"Values\": 0.8309205398116666}, {\"# of tasks\": 6, \"Series\": \"beta = 1\", \"Values\": 0.8241463752835175}, {\"# of tasks\": 7, \"Series\": \"beta = 1\", \"Values\": 0.8222078244957451}, {\"# of tasks\": 8, \"Series\": \"beta = 1\", \"Values\": 0.826404486023425}, {\"# of tasks\": 9, \"Series\": \"beta = 1\", \"Values\": 0.8183212374289976}, {\"# of tasks\": 0, \"Series\": \"beta = 100\", \"Values\": 0.9986761229314421}, {\"# of tasks\": 1, \"Series\": \"beta = 100\", \"Values\": 0.892835342789598}, {\"# of tasks\": 2, \"Series\": \"beta = 100\", \"Values\": 0.9177893450309458}, {\"# of tasks\": 3, \"Series\": \"beta = 100\", \"Values\": 0.8523094916331507}, {\"# of tasks\": 4, \"Series\": \"beta = 100\", \"Values\": 0.8788792721972006}, {\"# of tasks\": 5, \"Series\": \"beta = 100\", \"Values\": 0.8473913378981525}, {\"# of tasks\": 6, \"Series\": \"beta = 100\", \"Values\": 0.8661871112672337}, {\"# of tasks\": 7, \"Series\": \"beta = 100\", \"Values\": 0.8479065491663119}, {\"# of tasks\": 8, \"Series\": \"beta = 100\", \"Values\": 0.8564882538126204}, {\"# of tasks\": 9, \"Series\": \"beta = 100\", \"Values\": 0.8499741815164803}, {\"# of tasks\": 0, \"Series\": \"AutoVCL\", \"Values\": 0.9989598108747044}, {\"# of tasks\": 1, \"Series\": \"AutoVCL\", \"Values\": 0.9332462174940899}, {\"# of tasks\": 2, \"Series\": \"AutoVCL\", \"Values\": 0.9415147944389259}, {\"# of tasks\": 3, \"Series\": \"AutoVCL\", \"Values\": 0.8627120221217319}, {\"# of tasks\": 4, \"Series\": \"AutoVCL\", \"Values\": 0.8812103782671723}, {\"# of tasks\": 5, \"Series\": \"AutoVCL\", \"Values\": 0.8505740930023382}, {\"# of tasks\": 6, \"Series\": \"AutoVCL\", \"Values\": 0.8657976173546276}, {\"# of tasks\": 7, \"Series\": \"AutoVCL\", \"Values\": 0.8645177931129083}, {\"# of tasks\": 8, \"Series\": \"AutoVCL\", \"Values\": 0.874188178258269}, {\"# of tasks\": 9, \"Series\": \"AutoVCL\", \"Values\": 0.868147689835916}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.Chart(...)"]},"metadata":{},"output_type":"display_data"}],"source":["plot_trends([mixed_trends_1, mixed_trends_2, mixed_trends_3, mixed_trends_4])"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["P-MNIST"]},{"cell_type":"code","execution_count":240,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 97.26%\n","Average Accuracy across 2 tasks: 82.98%\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[240], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m MFVI_NN(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m], \u001b[38;5;241m10\u001b[39m, num_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, single_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m trend \u001b[38;5;241m=\u001b[39m \u001b[43mrun_vcl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmnist_train_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpmnist_test_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoreset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m p_trends_1\u001b[38;5;241m.\u001b[39mappend(trend)\n","Cell \u001b[0;32mIn[225], line 23\u001b[0m, in \u001b[0;36mrun_vcl\u001b[0;34m(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta, binary_labels)\u001b[0m\n\u001b[1;32m     21\u001b[0m         model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# for prediction\u001b[39;00m\n","Cell \u001b[0;32mIn[239], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, trainloader, optimizer, epoch, device, kl_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, task_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, binary_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m      6\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the images\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[234], line 12\u001b[0m, in \u001b[0;36mPermutedMNIST.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 12\u001b[0m     image, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmnist_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermutation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# Apply permutation\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermutation]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/datasets/mnist.py:142\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    138\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/PIL/Image.py:3103\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3101\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mtostring()\n\u001b[0;32m-> 3103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/PIL/Image.py:3018\u001b[0m, in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   3016\u001b[0m     args \u001b[38;5;241m=\u001b[39m mode, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m _MAPMODES:\n\u001b[0;32m-> 3018\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3019\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39m_new(core\u001b[38;5;241m.\u001b[39mmap_buffer(data, size, decoder_name, \u001b[38;5;241m0\u001b[39m, args))\n\u001b[1;32m   3020\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/PIL/Image.py:2925\u001b[0m, in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2921\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageColor\n\u001b[1;32m   2923\u001b[0m     color \u001b[38;5;241m=\u001b[39m ImageColor\u001b[38;5;241m.\u001b[39mgetcolor(color, mode)\n\u001b[0;32m-> 2925\u001b[0m im \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(color, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(color) \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]:\n\u001b[1;32m   2927\u001b[0m     \u001b[38;5;66;03m# RGB or RGBA value for a P image\u001b[39;00m\n\u001b[1;32m   2928\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImagePalette\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["p_trends_1 = []\n","torch.manual_seed(SEED)\n","coreset_size = 0\n","for i in range(5):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10, single_head=True).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, pmnist_train_loaders,pmnist_test_loaders, optimizer, epoch_per_task, coreset_size, beta=1e-2)\n","    p_trends_1.append(trend)"]},{"cell_type":"code","execution_count":246,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":246,"metadata":{},"output_type":"execute_result"}],"source":["coreset_size"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 97.41%\n","Average Accuracy across 2 tasks: 93.11%\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m MFVI_NN(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m], \u001b[38;5;241m10\u001b[39m, num_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, single_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m trend \u001b[38;5;241m=\u001b[39m \u001b[43mrun_vcl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmnist_train_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpmnist_test_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoreset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m p_trends_2\u001b[38;5;241m.\u001b[39mappend(trend)\n","Cell \u001b[0;32mIn[8], line 23\u001b[0m, in \u001b[0;36mrun_vcl\u001b[0;34m(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta, binary_labels)\u001b[0m\n\u001b[1;32m     21\u001b[0m         model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# for prediction\u001b[39;00m\n","Cell \u001b[0;32mIn[17], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, trainloader, optimizer, epoch, device, kl_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, task_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, binary_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m      6\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the images\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[4], line 12\u001b[0m, in \u001b[0;36mPermutedMNIST.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 12\u001b[0m     image, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmnist_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermutation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# Apply permutation\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermutation]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/datasets/mnist.py:142\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    138\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["p_trends_2 = []\n","torch.manual_seed(SEED)\n","for i in range(5):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10, single_head=False).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, pmnist_train_loaders,pmnist_test_loaders, optimizer, epoch_per_task, coreset_size, beta=1)\n","    p_trends_2.append(trend)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 97.80%\n","Average Accuracy across 2 tasks: 90.43%\n","Average Accuracy across 3 tasks: 88.51%\n","Average Accuracy across 4 tasks: 87.55%\n","Average Accuracy across 5 tasks: 86.75%\n","Average Accuracy across 6 tasks: 86.48%\n","Average Accuracy across 7 tasks: 86.20%\n","Average Accuracy across 8 tasks: 86.03%\n","Average Accuracy across 9 tasks: 85.61%\n","Average Accuracy across 10 tasks: 85.40%\n","Average Accuracy across 1 tasks: 97.71%\n","Average Accuracy across 2 tasks: 90.53%\n","Average Accuracy across 3 tasks: 88.20%\n","Average Accuracy across 4 tasks: 86.75%\n","Average Accuracy across 5 tasks: 86.31%\n","Average Accuracy across 6 tasks: 86.01%\n","Average Accuracy across 7 tasks: 85.85%\n","Average Accuracy across 8 tasks: 85.56%\n","Average Accuracy across 9 tasks: 85.32%\n","Average Accuracy across 10 tasks: 85.15%\n","Average Accuracy across 1 tasks: 97.74%\n","Average Accuracy across 2 tasks: 90.80%\n","Average Accuracy across 3 tasks: 88.24%\n","Average Accuracy across 4 tasks: 87.25%\n","Average Accuracy across 5 tasks: 86.77%\n","Average Accuracy across 6 tasks: 86.25%\n","Average Accuracy across 7 tasks: 86.22%\n","Average Accuracy across 8 tasks: 85.94%\n","Average Accuracy across 9 tasks: 85.69%\n","Average Accuracy across 10 tasks: 85.65%\n","Average Accuracy across 1 tasks: 97.80%\n","Average Accuracy across 2 tasks: 90.75%\n","Average Accuracy across 3 tasks: 88.51%\n","Average Accuracy across 4 tasks: 87.66%\n","Average Accuracy across 5 tasks: 87.10%\n","Average Accuracy across 6 tasks: 86.69%\n","Average Accuracy across 7 tasks: 86.25%\n","Average Accuracy across 8 tasks: 86.06%\n","Average Accuracy across 9 tasks: 85.79%\n","Average Accuracy across 10 tasks: 85.76%\n","Average Accuracy across 1 tasks: 97.79%\n","Average Accuracy across 2 tasks: 90.64%\n","Average Accuracy across 3 tasks: 88.06%\n","Average Accuracy across 4 tasks: 86.89%\n","Average Accuracy across 5 tasks: 86.07%\n","Average Accuracy across 6 tasks: 85.59%\n","Average Accuracy across 7 tasks: 85.44%\n","Average Accuracy across 8 tasks: 85.24%\n","Average Accuracy across 9 tasks: 85.09%\n","Average Accuracy across 10 tasks: 84.90%\n"]}],"source":["p_trends_3 = []\n","torch.manual_seed(SEED)\n","for i in range(5):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10, single_head=True).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, pmnist_train_loaders,pmnist_test_loaders, optimizer, epoch_per_task, coreset_size, beta=1e2)\n","    p_trends_3.append(trend)"]},{"cell_type":"code","execution_count":230,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.24968999999999997\n","Average Accuracy across 1 tasks: 97.30%\n","0.24671000000000004\n","0\n","0.1387 raw_pred\n","0.8336777777777779 0.8369888888888889 0.00026753301764113245 all\n","0.9723568714678044 beta\n","Average Accuracy across 2 tasks: 94.41%\n","0.22808\n","1\n","0.112 raw_pred\n","0.8369888888888889 0.857688888888889 0.0001568599996668718 all\n","0.8276132594156334 beta\n","Average Accuracy across 3 tasks: 90.74%\n","0.24731999999999998\n","2\n","0.0719 raw_pred\n","0.857688888888889 0.8363111111111111 0.00021643582836173894 all\n","1.2200478232689953 beta\n","Average Accuracy across 4 tasks: 84.60%\n","0.2266\n","3\n","0.1234 raw_pred\n","0.857688888888889 0.8593333333333333 0.00019702162945985427 all\n","0.9867572108509809 beta\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[230], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m MFVI_NN(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m], \u001b[38;5;241m10\u001b[39m, num_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, single_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m trend, p_beta\u001b[38;5;241m=\u001b[39m \u001b[43mrun_auto_vcl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmnist_train_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpmnist_test_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoreset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_betas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m p_trends_4\u001b[38;5;241m.\u001b[39mappend(trend)\n\u001b[1;32m     10\u001b[0m p_betas\u001b[38;5;241m.\u001b[39mappend(p_beta)\n","Cell \u001b[0;32mIn[225], line 118\u001b[0m, in \u001b[0;36mrun_auto_vcl\u001b[0;34m(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta_star, raw_training_epoch, raw_train_size, binary_labels, dor, return_betas)\u001b[0m\n\u001b[1;32m    116\u001b[0m         model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m--> 118\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# for prediction\u001b[39;00m\n","Cell \u001b[0;32mIn[173], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, trainloader, optimizer, epoch, device, kl_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, task_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, binary_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m      6\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the images\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[76], line 12\u001b[0m, in \u001b[0;36mPermutedMNIST.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 12\u001b[0m     image, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmnist_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermutation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# Apply permutation\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermutation]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/functional.py:363\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/_functional_tensor.py:920\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    917\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    919\u001b[0m dtype \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m--> 920\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(std, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (std \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["p_trends_4 = []\n","p_betas = []\n","torch.manual_seed(SEED)\n","for i in range(5):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10, single_head=True).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend, p_beta= run_auto_vcl(model, pmnist_train_loaders,pmnist_test_loaders, optimizer, \n","        epoch_per_task, coreset_size, return_betas=True)\n","    p_trends_4.append(trend)\n","    p_betas.append(p_beta)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["\n","<div id=\"altair-viz-29193f0ae8734336bd48febeeeabdc28\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-29193f0ae8734336bd48febeeeabdc28\") {\n","      outputDiv = document.getElementById(\"altair-viz-29193f0ae8734336bd48febeeeabdc28\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 15, \"titleFontSize\": 20}, \"legend\": {\"labelFontSize\": 15, \"titleFontSize\": 15}, \"title\": {\"fontSize\": 24}}, \"data\": {\"name\": \"data-a687ae4d97cee9f20172d3187863d4cd\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Series\", \"legend\": {\"title\": \"Model\"}, \"scale\": {\"scheme\": \"category10\"}, \"sort\": [\"beta = 0.01\", \"beta = 1\", \"beta = 100\", \"AutoVCL\"], \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"# of tasks\", \"type\": \"quantitative\"}, {\"field\": \"Values\", \"type\": \"quantitative\"}, {\"field\": \"Series\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"values\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}, \"field\": \"# of tasks\", \"title\": \"# tasks\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Values\", \"scale\": {\"domain\": [0.7, 1]}, \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Accuracy Trends in the Permuated MNIST Experiment\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-a687ae4d97cee9f20172d3187863d4cd\": [{\"# of tasks\": 0, \"Series\": \"beta = 0.01\", \"Values\": 0.97744}, {\"# of tasks\": 1, \"Series\": \"beta = 0.01\", \"Values\": 0.96143}, {\"# of tasks\": 2, \"Series\": \"beta = 0.01\", \"Values\": 0.9407466666666668}, {\"# of tasks\": 3, \"Series\": \"beta = 0.01\", \"Values\": 0.9128900000000002}, {\"# of tasks\": 4, \"Series\": \"beta = 0.01\", \"Values\": 0.88806}, {\"# of tasks\": 5, \"Series\": \"beta = 0.01\", \"Values\": 0.8564733333333333}, {\"# of tasks\": 6, \"Series\": \"beta = 0.01\", \"Values\": 0.8341799999999999}, {\"# of tasks\": 7, \"Series\": \"beta = 0.01\", \"Values\": 0.7968824999999999}, {\"# of tasks\": 8, \"Series\": \"beta = 0.01\", \"Values\": 0.7716711111111111}, {\"# of tasks\": 9, \"Series\": \"beta = 0.01\", \"Values\": 0.747904}, {\"# of tasks\": 0, \"Series\": \"beta = 1\", \"Values\": 0.97728}, {\"# of tasks\": 1, \"Series\": \"beta = 1\", \"Values\": 0.96854}, {\"# of tasks\": 2, \"Series\": \"beta = 1\", \"Values\": 0.9638933333333334}, {\"# of tasks\": 3, \"Series\": \"beta = 1\", \"Values\": 0.9590250000000001}, {\"# of tasks\": 4, \"Series\": \"beta = 1\", \"Values\": 0.955376}, {\"# of tasks\": 5, \"Series\": \"beta = 1\", \"Values\": 0.9522633333333335}, {\"# of tasks\": 6, \"Series\": \"beta = 1\", \"Values\": 0.9486828571428572}, {\"# of tasks\": 7, \"Series\": \"beta = 1\", \"Values\": 0.9459199999999999}, {\"# of tasks\": 8, \"Series\": \"beta = 1\", \"Values\": 0.9431555555555555}, {\"# of tasks\": 9, \"Series\": \"beta = 1\", \"Values\": 0.94054}, {\"# of tasks\": 0, \"Series\": \"beta = 100\", \"Values\": 0.97768}, {\"# of tasks\": 1, \"Series\": \"beta = 100\", \"Values\": 0.9062899999999999}, {\"# of tasks\": 2, \"Series\": \"beta = 100\", \"Values\": 0.8830333333333333}, {\"# of tasks\": 3, \"Series\": \"beta = 100\", \"Values\": 0.8722049999999999}, {\"# of tasks\": 4, \"Series\": \"beta = 100\", \"Values\": 0.8659840000000001}, {\"# of tasks\": 5, \"Series\": \"beta = 100\", \"Values\": 0.8620166666666667}, {\"# of tasks\": 6, \"Series\": \"beta = 100\", \"Values\": 0.8599257142857143}, {\"# of tasks\": 7, \"Series\": \"beta = 100\", \"Values\": 0.8576475}, {\"# of tasks\": 8, \"Series\": \"beta = 100\", \"Values\": 0.8549911111111111}, {\"# of tasks\": 9, \"Series\": \"beta = 100\", \"Values\": 0.8537279999999999}, {\"# of tasks\": 0, \"Series\": \"AutoVCL\", \"Values\": 0.97714}, {\"# of tasks\": 1, \"Series\": \"AutoVCL\", \"Values\": 0.97051}, {\"# of tasks\": 2, \"Series\": \"AutoVCL\", \"Values\": 0.9648933333333332}, {\"# of tasks\": 3, \"Series\": \"AutoVCL\", \"Values\": 0.959845}, {\"# of tasks\": 4, \"Series\": \"AutoVCL\", \"Values\": 0.9560000000000001}, {\"# of tasks\": 5, \"Series\": \"AutoVCL\", \"Values\": 0.9525366666666667}, {\"# of tasks\": 6, \"Series\": \"AutoVCL\", \"Values\": 0.9482857142857144}, {\"# of tasks\": 7, \"Series\": \"AutoVCL\", \"Values\": 0.9451075000000001}, {\"# of tasks\": 8, \"Series\": \"AutoVCL\", \"Values\": 0.9417088888888889}, {\"# of tasks\": 9, \"Series\": \"AutoVCL\", \"Values\": 0.939086}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.Chart(...)"]},"metadata":{},"output_type":"display_data"}],"source":["plot_trends([p_trends_1, p_trends_2,p_trends_3, p_trends_4])"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 99.91%\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[53], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m MFVI_NN(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m], \u001b[38;5;241m10\u001b[39m, num_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     trend \u001b[38;5;241m=\u001b[39m \u001b[43mrun_vcl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoreset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     pc_trends_1\u001b[38;5;241m.\u001b[39mappend(trend)\n\u001b[1;32m      8\u001b[0m pc_trends_2 \u001b[38;5;241m=\u001b[39m []\n","Cell \u001b[0;32mIn[51], line 23\u001b[0m, in \u001b[0;36mrun_vcl\u001b[0;34m(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta, binary_labels)\u001b[0m\n\u001b[1;32m     21\u001b[0m         model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# for prediction\u001b[39;00m\n","Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, trainloader, optimizer, epoch, device, kl_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, task_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, binary_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m      6\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the images\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/datasets/mnist.py:142\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    138\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/PIL/Image.py:3103\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3101\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mtostring()\n\u001b[0;32m-> 3103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/PIL/Image.py:3019\u001b[0m, in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m _MAPMODES:\n\u001b[1;32m   3018\u001b[0m     im \u001b[38;5;241m=\u001b[39m new(mode, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m-> 3019\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3020\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3021\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImagePalette\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/PIL/Image.py:544\u001b[0m, in \u001b[0;36mImage._new\u001b[0;34m(self, im)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_new\u001b[39m(\u001b[38;5;28mself\u001b[39m, im):\n\u001b[0;32m--> 544\u001b[0m     new \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m     new\u001b[38;5;241m.\u001b[39mim \u001b[38;5;241m=\u001b[39m im\n\u001b[1;32m    546\u001b[0m     new\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mmode\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["pc_trends_1 = []\n","coreset_size = 1000\n","for i in range(1):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, train_loaders,test_loaders, optimizer, epoch_per_task, coreset_size, beta=1e-2)\n","    pc_trends_1.append(trend)\n","pc_trends_2 = []\n","for i in range(1):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, train_loaders,test_loaders, optimizer, epoch_per_task, coreset_size, beta=1)\n","    pc_trends_2.append(trend)\n","pc_trends_3 = []\n","for i in range(1):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl(model, train_loaders,test_loaders, optimizer, epoch_per_task, coreset_size, beta=1e2)\n","    pc_trends_3.append(trend)\n","pc_trends_4 = []\n","for i in range(1):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend  = run_auto_vcl(model, train_loaders,test_loaders, optimizer, epoch_per_task, coreset_size, \n","            raw_training_epoch = raw_training_epoch,\n","            raw_train_size= raw_train_size)\n","    pc_trends_4.append(trend)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["\n","<div id=\"altair-viz-c73b0b2d3c2d4680ad59e695bc6e946b\"></div>\n","<script type=\"text/javascript\">\n","  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n","  (function(spec, embedOpt){\n","    let outputDiv = document.currentScript.previousElementSibling;\n","    if (outputDiv.id !== \"altair-viz-c73b0b2d3c2d4680ad59e695bc6e946b\") {\n","      outputDiv = document.getElementById(\"altair-viz-c73b0b2d3c2d4680ad59e695bc6e946b\");\n","    }\n","    const paths = {\n","      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n","      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n","      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n","      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n","    };\n","\n","    function maybeLoadScript(lib, version) {\n","      var key = `${lib.replace(\"-\", \"\")}_version`;\n","      return (VEGA_DEBUG[key] == version) ?\n","        Promise.resolve(paths[lib]) :\n","        new Promise(function(resolve, reject) {\n","          var s = document.createElement('script');\n","          document.getElementsByTagName(\"head\")[0].appendChild(s);\n","          s.async = true;\n","          s.onload = () => {\n","            VEGA_DEBUG[key] = version;\n","            return resolve(paths[lib]);\n","          };\n","          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n","          s.src = paths[lib];\n","        });\n","    }\n","\n","    function showError(err) {\n","      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n","      throw err;\n","    }\n","\n","    function displayChart(vegaEmbed) {\n","      vegaEmbed(outputDiv, spec, embedOpt)\n","        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n","    }\n","\n","    if(typeof define === \"function\" && define.amd) {\n","      requirejs.config({paths});\n","      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n","    } else {\n","      maybeLoadScript(\"vega\", \"5\")\n","        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n","        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n","        .catch(showError)\n","        .then(() => displayChart(vegaEmbed));\n","    }\n","  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 15, \"titleFontSize\": 20}, \"legend\": {\"labelFontSize\": 15, \"titleFontSize\": 15}, \"title\": {\"fontSize\": 24}}, \"data\": {\"name\": \"data-1a08c5aab4d92bc279dd866125d5b863\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"field\": \"Series\", \"legend\": {\"title\": \"Model\"}, \"scale\": {\"scheme\": \"category10\"}, \"sort\": [\"beta = 0.01\", \"beta = 1\", \"beta = 100\", \"AutoVCL\"], \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"# of tasks\", \"type\": \"quantitative\"}, {\"field\": \"Values\", \"type\": \"quantitative\"}, {\"field\": \"Series\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"values\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}, \"field\": \"# of tasks\", \"title\": \"# tasks\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Values\", \"scale\": {\"domain\": [0.7, 1]}, \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"height\": 400, \"title\": \"Accuracy Trends in the Permuated MNIST Experiment\", \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-1a08c5aab4d92bc279dd866125d5b863\": [{\"# of tasks\": 0, \"Series\": \"beta = 0.01\", \"Values\": 0.9775}, {\"# of tasks\": 1, \"Series\": \"beta = 0.01\", \"Values\": 0.96975}, {\"# of tasks\": 2, \"Series\": \"beta = 0.01\", \"Values\": 0.9576333333333333}, {\"# of tasks\": 3, \"Series\": \"beta = 0.01\", \"Values\": 0.9513750000000001}, {\"# of tasks\": 4, \"Series\": \"beta = 0.01\", \"Values\": 0.94978}, {\"# of tasks\": 5, \"Series\": \"beta = 0.01\", \"Values\": 0.9429666666666666}, {\"# of tasks\": 6, \"Series\": \"beta = 0.01\", \"Values\": 0.9362285714285715}, {\"# of tasks\": 7, \"Series\": \"beta = 0.01\", \"Values\": 0.928275}, {\"# of tasks\": 8, \"Series\": \"beta = 0.01\", \"Values\": 0.9333555555555555}, {\"# of tasks\": 9, \"Series\": \"beta = 0.01\", \"Values\": 0.92408}, {\"# of tasks\": 0, \"Series\": \"beta = 1\", \"Values\": 0.9793}, {\"# of tasks\": 1, \"Series\": \"beta = 1\", \"Values\": 0.9674499999999999}, {\"# of tasks\": 2, \"Series\": \"beta = 1\", \"Values\": 0.9642}, {\"# of tasks\": 3, \"Series\": \"beta = 1\", \"Values\": 0.9582999999999999}, {\"# of tasks\": 4, \"Series\": \"beta = 1\", \"Values\": 0.9564999999999999}, {\"# of tasks\": 5, \"Series\": \"beta = 1\", \"Values\": 0.95355}, {\"# of tasks\": 6, \"Series\": \"beta = 1\", \"Values\": 0.9523714285714285}, {\"# of tasks\": 7, \"Series\": \"beta = 1\", \"Values\": 0.9499875000000001}, {\"# of tasks\": 8, \"Series\": \"beta = 1\", \"Values\": 0.9471555555555555}, {\"# of tasks\": 9, \"Series\": \"beta = 1\", \"Values\": 0.9460200000000001}, {\"# of tasks\": 0, \"Series\": \"beta = 100\", \"Values\": 0.9781}, {\"# of tasks\": 1, \"Series\": \"beta = 100\", \"Values\": 0.9076}, {\"# of tasks\": 2, \"Series\": \"beta = 100\", \"Values\": 0.8961666666666667}, {\"# of tasks\": 3, \"Series\": \"beta = 100\", \"Values\": 0.8945000000000001}, {\"# of tasks\": 4, \"Series\": \"beta = 100\", \"Values\": 0.89268}, {\"# of tasks\": 5, \"Series\": \"beta = 100\", \"Values\": 0.8887}, {\"# of tasks\": 6, \"Series\": \"beta = 100\", \"Values\": 0.8901428571428571}, {\"# of tasks\": 7, \"Series\": \"beta = 100\", \"Values\": 0.8902374999999999}, {\"# of tasks\": 8, \"Series\": \"beta = 100\", \"Values\": 0.887688888888889}, {\"# of tasks\": 9, \"Series\": \"beta = 100\", \"Values\": 0.8904}, {\"# of tasks\": 0, \"Series\": \"AutoVCL\", \"Values\": 0.9785}, {\"# of tasks\": 1, \"Series\": \"AutoVCL\", \"Values\": 0.96895}, {\"# of tasks\": 2, \"Series\": \"AutoVCL\", \"Values\": 0.9633333333333333}, {\"# of tasks\": 3, \"Series\": \"AutoVCL\", \"Values\": 0.9565250000000001}, {\"# of tasks\": 4, \"Series\": \"AutoVCL\", \"Values\": 0.9528800000000001}, {\"# of tasks\": 5, \"Series\": \"AutoVCL\", \"Values\": 0.9487166666666665}, {\"# of tasks\": 6, \"Series\": \"AutoVCL\", \"Values\": 0.9437571428571427}, {\"# of tasks\": 7, \"Series\": \"AutoVCL\", \"Values\": 0.9435250000000001}, {\"# of tasks\": 8, \"Series\": \"AutoVCL\", \"Values\": 0.9409777777777778}, {\"# of tasks\": 9, \"Series\": \"AutoVCL\", \"Values\": 0.9401200000000001}]}}, {\"mode\": \"vega-lite\"});\n","</script>"],"text/plain":["alt.Chart(...)"]},"metadata":{},"output_type":"display_data"}],"source":["plot_trends([pc_trends_1, pc_trends_2, pc_trends_3, pc_trends_4])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}

{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T22:17:14.618901Z","iopub.status.busy":"2024-03-28T22:17:14.618543Z","iopub.status.idle":"2024-03-28T22:17:14.648435Z","shell.execute_reply":"2024-03-28T22:17:14.647304Z","shell.execute_reply.started":"2024-03-28T22:17:14.618873Z"},"id":"SPZBRp-PUgWP","trusted":true},"outputs":[],"source":["class MFVI_Layer(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super(MFVI_Layer, self).__init__()\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        \n","        # Mean and log variance parameters\n","        self.W_m = nn.Parameter(torch.Tensor(out_features, in_features))\n","        self.b_m = nn.Parameter(torch.Tensor(out_features))\n","        self.W_logv = nn.Parameter(torch.Tensor(out_features, in_features))\n","        self.b_logv = nn.Parameter(torch.Tensor(out_features))\n","\n","        # Prior distributions initialized to None\n","        self.prior_W_m = self.prior_b_m = self.prior_W_logv = self.prior_b_logv = None\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        # Initialize mean parameters to a normal distribution and log variance parameters to a small value\n","        self.W_m.data.normal_(0, 0.1)\n","        self.b_m.data.normal_(0, 0.1)\n","        self.W_logv.data.fill_(-6.0)\n","        self.b_logv.data.fill_(-6.0)\n","        self.set_priors()\n","\n","    def set_priors(self):\n","        # Set priors to the current parameters\n","        self.prior_W_m = self.W_m.detach().clone()\n","        self.prior_b_m = self.b_m.detach().clone()\n","        self.prior_W_logv = self.W_logv.detach().clone()\n","        self.prior_b_logv = self.b_logv.detach().clone()\n","\n","    def forward(self, x, sample=True):\n","        W_std = torch.exp(0.5 * self.W_logv)\n","        b_std = torch.exp(0.5 * self.b_logv)\n","        \n","        act_mu = F.linear(x, self.W_m, self.b_m)\n","        act_var = 1e-16 + F.linear(x.pow(2), W_std.pow(2)) + b_std.pow(2)\n","        act_std = torch.sqrt(act_var)\n","\n","        if self.training or sample:\n","            eps = torch.randn_like(act_mu)\n","            return act_mu + act_std * eps\n","        else:\n","            return act_mu\n","\n","    def kl_divergence(self, device):\n","        self.update_prior_device(device)\n","        num_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n","        # Convert log variance to standard deviation for posterior and prior\n","        W_std_post = torch.exp(0.5 * self.W_logv)\n","        b_std_post = torch.exp(0.5 * self.b_logv)\n","        W_std_prior = torch.exp(0.5 * self.prior_W_logv)\n","        b_std_prior = torch.exp(0.5 * self.prior_b_logv)\n","\n","        # Calculate KL divergence for weights\n","        kl_div_W = torch.log(W_std_prior / W_std_post) + \\\n","                ((W_std_post**2 + (self.W_m - self.prior_W_m)**2) / (2 * W_std_prior**2)) - 0.5\n","        # Sum over all elements\n","        kl_div_W = kl_div_W.sum()\n","\n","        # Calculate KL divergence for biases\n","        kl_div_b = torch.log(b_std_prior / b_std_post) + \\\n","                ((b_std_post**2 + (self.b_m - self.prior_b_m)**2) / (2 * b_std_prior**2)) - 0.5\n","        # Sum over all elements\n","        kl_div_b = kl_div_b.sum()\n","\n","        # Total KL divergence\n","        total_kl = kl_div_W + kl_div_b\n","\n","        return total_kl/num_params\n","\n","    def update_prior_device(self, device):\n","        # Ensure priors are moved to the correct device\n","        self.prior_W_m = self.prior_W_m.to(device)\n","        self.prior_b_m = self.prior_b_m.to(device)\n","        self.prior_W_logv = self.prior_W_logv.to(device)\n","        self.prior_b_logv = self.prior_b_logv.to(device)\n","\n","class MFVI_NN(nn.Module):\n","    def __init__(self, input_size, hidden_sizes, output_size, num_tasks=1, single_head=False):\n","        super(MFVI_NN, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_sizes = hidden_sizes\n","        self.output_size = output_size\n","        self.num_tasks = num_tasks\n","        self.single_head = single_head\n","        self.layers = nn.ModuleList()\n","        self.task_specific_layers = nn.ModuleDict()  # Using ModuleDict for task-specific layers\n","\n","        # Construct shared layers\n","        sizes = [input_size] + hidden_sizes\n","        for i in range(len(sizes) - 1):\n","            self.layers.append(MFVI_Layer(sizes[i], sizes[i + 1]))\n","\n","        # Construct task-specific output layers\n","        if single_head:\n","            self.task_specific_layers[str(0)] = MFVI_Layer(sizes[-1], output_size)\n","        else:\n","            for task_id in range(num_tasks):\n","                self.task_specific_layers[str(task_id)] = MFVI_Layer(sizes[-1], output_size)\n","\n","    def forward(self, x, task_id=0, sample=True):\n","        for layer in self.layers:\n","            x = F.relu(layer(x, sample=sample))\n","        if self.single_head:\n","            x = self.task_specific_layers[\"0\"](x, sample=sample)\n","        else:\n","            x = self.task_specific_layers[str(task_id)](x, sample=sample)\n","        return x\n","\n","    def kl_divergence(self):\n","        kl_div = 0\n","        # Accumulate KL divergence from shared and task-specific layers\n","        for layer in self.layers:\n","            kl_div += layer.kl_divergence(next(self.parameters()).device)\n","        # for task_layer in self.task_specific_layers.values():\n","        #     kl_div += task_layer.kl_divergence(next(self.parameters()).device)\n","        return kl_div\n","\n","    def update_priors(self):\n","        # Update priors in each layer\n","        for layer in self.layers + list(self.task_specific_layers.values()):\n","            layer.set_priors()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T22:17:14.971505Z","iopub.status.busy":"2024-03-28T22:17:14.971198Z","iopub.status.idle":"2024-03-28T22:17:14.982774Z","shell.execute_reply":"2024-03-28T22:17:14.981720Z","shell.execute_reply.started":"2024-03-28T22:17:14.971481Z"},"id":"su4PfiXIdwAN","trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","\n","def train(model, trainloader, optimizer, epoch, device, kl_weight=1, task_id = 0, binary_label = None):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(trainloader):\n","        data, target = data.to(device), target.to(device)\n","        data = data.view(data.size(0), -1)  # Flatten the images\n","        optimizer.zero_grad()\n","        output = model(data, sample=True, task_id = task_id)\n","        if binary_label != None:\n","            target = (target == binary_label[0]).long()\n","        reconstruction_loss = F.cross_entropy(output, target, reduction='mean')\n","        \n","#         print(kl_divergence,reconstruction_loss)\n","        if task_id == 0:\n","            loss = reconstruction_loss\n","        else:\n","            kl_divergence = model.kl_divergence()\n","            loss = reconstruction_loss + kl_divergence * kl_weight\n","        loss.backward()\n","        optimizer.step()\n","#     print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(trainloader.dataset)} ({100. * batch_idx / len(trainloader):.0f}%)]\\tLoss: {loss.item()}\")\n","\n","def test(model, testloader, device, task_id = 0, binary_label = None):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in testloader:\n","            data, target = data.to(device), target.to(device)\n","            data = data.view(data.size(0), -1)  # Flatten the images\n","            output = model(data, sample=False, task_id = task_id)\n","            if binary_label != None:\n","                target = (target == binary_label[0]).long()\n","\n","            # Use cross_entropy for test loss calculation, sum up batch loss\n","            test_loss += F.cross_entropy(output, target, reduction='mean').item()\n","            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(testloader.dataset)\n","    # print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(testloader.dataset)} ({100. * correct / len(testloader.dataset):.0f}%)\\n')\n","    return test_loss, correct / len(testloader.dataset)\n"]},{"cell_type":"markdown","metadata":{"id":"lCTWinB8DD_M"},"source":["## Permuted MNIST"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T22:17:15.847234Z","iopub.status.busy":"2024-03-28T22:17:15.846642Z","iopub.status.idle":"2024-03-28T22:17:20.400313Z","shell.execute_reply":"2024-03-28T22:17:20.399340Z","shell.execute_reply.started":"2024-03-28T22:17:15.847202Z"},"id":"-iGpZltOvLRw","trusted":true},"outputs":[],"source":["from torchvision import datasets, transforms\n","\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.1307,), (0.3081,))])\n","\n","train_dataset = datasets.MNIST(root='~/.pytorch/MNIST_data/', train=True, download=True, transform=transform)\n","test_dataset = datasets.MNIST(root='~/.pytorch/MNIST_data/', train=False, download=True, transform=transform)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T22:17:20.402467Z","iopub.status.busy":"2024-03-28T22:17:20.402053Z","iopub.status.idle":"2024-03-28T22:17:20.418338Z","shell.execute_reply":"2024-03-28T22:17:20.417371Z","shell.execute_reply.started":"2024-03-28T22:17:20.402441Z"},"id":"G3VNEXUADM7j","trusted":true},"outputs":[],"source":["import torch\n","\n","def generate_permutations(task_count, image_size):\n","    permutations = [torch.randperm(image_size) for _ in range(task_count - 1)]\n","    return permutations\n","\n","# Generate permutations for 9 tasks (+1 original MNIST)\n","task_count = 10\n","image_size = 28 * 28  # MNIST images are 28x28\n","permutations = generate_permutations(task_count, image_size)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T22:17:20.419800Z","iopub.status.busy":"2024-03-28T22:17:20.419497Z","iopub.status.idle":"2024-03-28T22:17:20.427183Z","shell.execute_reply":"2024-03-28T22:17:20.426283Z","shell.execute_reply.started":"2024-03-28T22:17:20.419777Z"},"id":"bkE72alHDOKy","trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","class PermutedMNIST(Dataset):\n","    def __init__(self, mnist_dataset, permutation=None):\n","        self.mnist_dataset = mnist_dataset\n","        self.permutation = permutation\n","\n","    def __len__(self):\n","        return len(self.mnist_dataset)\n","\n","    def __getitem__(self, idx):\n","        image, label = self.mnist_dataset[idx]\n","        if self.permutation is not None:\n","            # Apply permutation\n","            image = image.view(-1)[self.permutation].view(1, 28, 28)\n","        return image, label\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T22:17:20.429290Z","iopub.status.busy":"2024-03-28T22:17:20.429021Z","iopub.status.idle":"2024-03-28T22:17:20.438100Z","shell.execute_reply":"2024-03-28T22:17:20.437241Z","shell.execute_reply.started":"2024-03-28T22:17:20.429267Z"},"id":"1Riy4xPFDRAp","trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","batch_size = 256\n","\n","# Create a DataLoader for the original MNIST\n","pmnist_train_loaders = [DataLoader(train_dataset, batch_size=batch_size, shuffle=True)]\n","pmnist_test_loaders = [DataLoader(test_dataset, batch_size=batch_size, shuffle=False)]\n","train_datasets = [train_dataset]\n","# Create DataLoaders for permuted tasks\n","for perm in permutations:\n","    permuted_train = PermutedMNIST(train_dataset, permutation=perm)\n","    permuted_test = PermutedMNIST(test_dataset, permutation=perm)\n","\n","    train_loader = DataLoader(permuted_train, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(permuted_test, batch_size=batch_size, shuffle=False)\n","\n","    pmnist_train_loaders.append(train_loader)\n","    pmnist_test_loaders.append(test_loader)\n","    train_datasets.append(permuted_train)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2024-03-28T22:17:20.439666Z","iopub.status.busy":"2024-03-28T22:17:20.439291Z"},"id":"fprvcPUPDbhv","outputId":"fb650c07-66b7-43d2-e4e8-37ba765532a2","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/10 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [00:33<00:00,  3.36s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 97.78%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [00:46<00:00,  4.66s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 2 tasks: 96.72%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [00:51<00:00,  5.18s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 3 tasks: 96.49%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [00:56<00:00,  5.66s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 4 tasks: 95.99%\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|█████████ | 9/10 [01:04<00:07,  7.21s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m         ave_acc_trend\u001b[38;5;241m.\u001b[39mappend(average_accuracy)\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Accuracy across \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(task_accuracies)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tasks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maverage_accuracy\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[43mrun_vcl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[17], line 21\u001b[0m, in \u001b[0;36mrun_vcl\u001b[0;34m(model, optimizer, epoch_per_task, beta)\u001b[0m\n\u001b[1;32m     19\u001b[0m prev_test_loaders\u001b[38;5;241m.\u001b[39mappend(test_loader)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m task_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ptl \u001b[38;5;129;01min\u001b[39;00m prev_test_loaders: \n","Cell \u001b[0;32mIn[16], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label)\u001b[0m\n\u001b[1;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the images\u001b[39;00m\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 9\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m binary_label \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     target \u001b[38;5;241m=\u001b[39m (target \u001b[38;5;241m==\u001b[39m binary_label[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mlong()\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[9], line 109\u001b[0m, in \u001b[0;36mMFVI_NN.forward\u001b[0;34m(self, x, task_id, sample)\u001b[0m\n\u001b[1;32m    107\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_specific_layers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m](x, sample\u001b[38;5;241m=\u001b[39msample)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_specific_layers\u001b[49m[\u001b[38;5;28mstr\u001b[39m(task_id)](x, sample\u001b[38;5;241m=\u001b[39msample)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1682\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1682\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1683\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1684\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from tqdm import tqdm\n","# Assuming model, optimizer, train_loaders, test_loaders are defined\n","if torch.cuda.is_available():\n","    device = 'cuda'\n","else:\n","    device = 'cpu'\n","    \n","model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","epoch_per_task = 10\n","beta = 1\n","def run_vcl(model, optimizer, epoch_per_task, beta):\n","    device = next(model.parameters()).device\n","    task_accuracies = []\n","    ave_acc_trend = []\n","    prev_test_loaders= []\n","    for task_id, (train_loader, test_loader) in enumerate(zip(train_loaders, test_loaders), start=0):\n","        task_accuracies = []\n","        prev_test_loaders.append(test_loader)\n","        for epoch in tqdm(range(1, epoch_per_task + 1)):\n","            train(model, train_loader, optimizer, epoch, device, beta, task_id=task_id)\n","        task_num = 0  \n","        for ptl in prev_test_loaders: \n","            test_loss, task_accuracy = test(model, ptl, device,task_id=task_num)\n","            task_accuracies.append(task_accuracy)\n","            task_num += 1\n","        \n","        model.update_priors()\n","\n","        average_accuracy = sum(task_accuracies) / len(task_accuracies)\n","        ave_acc_trend.append(average_accuracy)\n","        print(f'Average Accuracy across {len(task_accuracies)} tasks: {average_accuracy*100:.2f}%')\n","run_vcl(model, optimizer, epoch_per_task, beta)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([7, 2, 1,  ..., 4, 5, 6])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["pmnist_test_loaders[0].dataset.targets"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T14:25:51.264730Z","iopub.status.busy":"2024-03-22T14:25:51.263934Z","iopub.status.idle":"2024-03-22T14:25:51.295704Z","shell.execute_reply":"2024-03-22T14:25:51.294416Z","shell.execute_reply.started":"2024-03-22T14:25:51.264697Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'ave_acc_trend' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mave_acc_trend\u001b[49m)),ave_acc_trend)\n","\u001b[0;31mNameError\u001b[0m: name 'ave_acc_trend' is not defined"]}],"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(range(len(ave_acc_trend)),ave_acc_trend)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T14:25:51.508581Z","iopub.status.busy":"2024-03-22T14:25:51.508228Z","iopub.status.idle":"2024-03-22T14:25:51.515278Z","shell.execute_reply":"2024-03-22T14:25:51.514323Z","shell.execute_reply.started":"2024-03-22T14:25:51.508552Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader, ConcatDataset, Subset\n","def random_coreset(dataset, coreset_size):\n","    \"\"\"\n","    Randomly selects a subset of data points to form a coreset.\n","\n","    Args:\n","    - dataset (torch.utils.data.Dataset): The dataset to sample from.\n","    - coreset_size (int): The number of samples to include in the coreset.\n","\n","    Returns:\n","    - coreset_indices (torch.Tensor): Indices of the selected samples.\n","    \"\"\"\n","    # Ensure coreset size does not exceed dataset size\n","    coreset_size = min(coreset_size, len(dataset))\n","    \n","    # Randomly select indices without replacement\n","    coreset_indices = np.random.choice(len(dataset), size=coreset_size, replace=False)\n","    \n","    # Convert numpy array to torch tensor\n","    coreset_indices = torch.from_numpy(coreset_indices)\n","    \n","    coreset = Subset(dataset, coreset_indices)\n","    return coreset\n","\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":207},"execution":{"iopub.execute_input":"2024-03-22T14:25:52.412402Z","iopub.status.busy":"2024-03-22T14:25:52.411660Z","iopub.status.idle":"2024-03-22T14:58:25.913735Z","shell.execute_reply":"2024-03-22T14:58:25.912877Z","shell.execute_reply.started":"2024-03-22T14:25:52.412371Z"},"id":"DBD-Tcr1EAn2","outputId":"3116097e-5d13-4583-8b9a-795fc0a6efa2","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n","  0%|          | 0/10 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 1/10 [00:04<00:42,  4.75s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Accuracy across \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(task_accuracies_rc)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tasks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maverage_accuracy\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ave_acc_trend_rc\n\u001b[0;32m---> 44\u001b[0m ave_acc_trend_1 \u001b[38;5;241m=\u001b[39m \u001b[43mrun_vcl_with_coreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_per_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoreset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-1\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[20], line 20\u001b[0m, in \u001b[0;36mrun_vcl_with_coreset\u001b[0;34m(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta)\u001b[0m\n\u001b[1;32m     18\u001b[0m     model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     22\u001b[0m coresets\u001b[38;5;241m.\u001b[39mappend(random_coreset(train_datasets[task_id], coreset_size))\n","Cell \u001b[0;32mIn[16], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label)\u001b[0m\n\u001b[1;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Flatten the images\u001b[39;00m\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 9\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m binary_label \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     target \u001b[38;5;241m=\u001b[39m (target \u001b[38;5;241m==\u001b[39m binary_label[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mlong()\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[9], line 105\u001b[0m, in \u001b[0;36mMFVI_NN.forward\u001b[0;34m(self, x, task_id, sample)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, task_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 105\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingle_head:\n\u001b[1;32m    107\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_specific_layers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m](x, sample\u001b[38;5;241m=\u001b[39msample)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[9], line 37\u001b[0m, in \u001b[0;36mMFVI_Layer.forward\u001b[0;34m(self, x, sample)\u001b[0m\n\u001b[1;32m     34\u001b[0m W_std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_logv)\n\u001b[1;32m     35\u001b[0m b_std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_logv)\n\u001b[0;32m---> 37\u001b[0m act_mu \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb_m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m act_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-16\u001b[39m \u001b[38;5;241m+\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(x\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m), W_std\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m+\u001b[39m b_std\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     39\u001b[0m act_std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(act_var)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from tqdm import tqdm\n","epoch_per_task = 10\n","model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","coreset_size = 200\n","beta = 1\n","\n","def run_vcl_with_coreset(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta):\n","    ave_acc_trend_rc = []\n","    prev_test_loaders= []\n","    coresets = []\n","    for task_id, (train_loader, test_loader) in enumerate(zip(train_loaders, test_loaders), start=0):\n","        task_accuracies_rc = []\n","        for i in tqdm(range(len(coresets))):\n","            for epoch in (range(1, epoch_per_task + 1)):\n","                coreset_loader = DataLoader(coresets[i], batch_size=batch_size, shuffle=True)\n","                train(model, coreset_loader, optimizer, epoch, device, beta, task_id=i)\n","            model.update_priors()\n","        for epoch in tqdm(range(1, epoch_per_task + 1)):\n","            train(model, train_loader, optimizer, epoch, device, beta, task_id=task_id)\n","        model.update_priors()\n","        coresets.append(random_coreset(train_datasets[task_id], coreset_size))\n","\n","        # for prediction\n","        prediction_model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10).to(device)\n","        prediction_model.load_state_dict(model.state_dict())\n","        # replay\n","        for i in tqdm(range(len(coresets))):\n","            for epoch in (range(1, epoch_per_task + 1)):\n","                coreset_loader = DataLoader(coresets[i], batch_size=batch_size, shuffle=True)\n","                train(prediction_model, coreset_loader, optimizer, epoch, device, beta, task_id=i)\n","        task_num = 0  \n","        prev_test_loaders.append(test_loader)\n","        for ptl in prev_test_loaders: \n","            test_loss, task_accuracy = test(prediction_model, ptl, device,task_id=task_num)\n","            task_accuracies_rc.append(task_accuracy)\n","            task_num += 1\n","\n","        average_accuracy = sum(task_accuracies_rc) / len(task_accuracies_rc)\n","        ave_acc_trend_rc.append(average_accuracy)\n","        print(f'Average Accuracy across {len(task_accuracies_rc)} tasks: {average_accuracy*100:.2f}%')\n","    return ave_acc_trend_rc\n","\n","ave_acc_trend_1 = run_vcl_with_coreset(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta=1e-1)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["def run_vcl_with_coreset(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta):\n","    ave_acc_trend_rc = []\n","    prev_test_loaders= []\n","    coresets = []\n","    for task_id, (train_loader, test_loader) in enumerate(zip(train_loaders, test_loaders), start=0):\n","        task_accuracies_rc = []\n","        # for i in tqdm(range(len(coresets))):\n","        #     for epoch in (range(1, epoch_per_task + 1)):\n","        #         coreset_loader = DataLoader(coresets[i], batch_size=batch_size, shuffle=True)\n","        #         train(model, coreset_loader, optimizer, epoch, device, beta, task_id=i)\n","        #     model.update_priors()\n","        for epoch in tqdm(range(1, epoch_per_task + 1)):\n","            train(model, train_loader, optimizer, epoch, device, beta, task_id=task_id)\n","        model.update_priors()\n","        # coresets.append(random_coreset(train_datasets[task_id], coreset_size))\n","\n","        # for prediction\n","        prediction_model =type(model)(model.input_size, model.hidden_sizes, model.output_size, model.num_tasks, model.single_head).to(device)\n","        prediction_model.load_state_dict(model.state_dict())\n","        # replay\n","        # for i in tqdm(range(len(coresets))):\n","        #     for epoch in (range(1, epoch_per_task + 1)):\n","        #         coreset_loader = DataLoader(coresets[i], batch_size=batch_size, shuffle=True)\n","        #         train(prediction_model, coreset_loader, optimizer, epoch, device, beta, task_id=i)\n","        task_num = 0  \n","        prev_test_loaders.append(test_loader)\n","        for ptl in prev_test_loaders: \n","            test_loss, task_accuracy = test(prediction_model, ptl, device,task_id=task_num)\n","            task_accuracies_rc.append(task_accuracy)\n","            task_num += 1\n","\n","        average_accuracy = sum(task_accuracies_rc) / len(task_accuracies_rc)\n","        ave_acc_trend_rc.append(average_accuracy)\n","        print(f'Average Accuracy across {len(task_accuracies_rc)} tasks: {average_accuracy*100:.2f}%')\n","    return ave_acc_trend_rc"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10/10 [00:49<00:00,  4.90s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 99.03%\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|███████   | 7/10 [01:10<00:30, 10.06s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m MFVI_NN(\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m], \u001b[38;5;241m10\u001b[39m, num_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, single_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m trend \u001b[38;5;241m=\u001b[39m \u001b[43mrun_vcl_with_coreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmnist_train_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmnist_train_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoreset_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m p_trends_2\u001b[38;5;241m.\u001b[39mappend(trend)\n","Cell \u001b[0;32mIn[24], line 13\u001b[0m, in \u001b[0;36mrun_vcl_with_coreset\u001b[0;34m(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# for i in tqdm(range(len(coresets))):\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     for epoch in (range(1, epoch_per_task + 1)):\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#         coreset_loader = DataLoader(coresets[i], batch_size=batch_size, shuffle=True)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#         train(model, coreset_loader, optimizer, epoch, device, beta, task_id=i)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     model.update_priors()\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_per_task \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mupdate_priors()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# coresets.append(random_coreset(train_datasets[task_id], coreset_size))\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# for prediction\u001b[39;00m\n","Cell \u001b[0;32mIn[16], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, epoch, device, kl_weight, task_id, binary_label)\u001b[0m\n\u001b[1;32m     18\u001b[0m     kl_divergence \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mkl_divergence()\n\u001b[1;32m     19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m reconstruction_loss \u001b[38;5;241m+\u001b[39m kl_divergence \u001b[38;5;241m*\u001b[39m kl_weight\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["p_trends_2 = []\n","coreset_size = 0\n","for i in range(5):\n","    model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10, single_head=True).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    trend = run_vcl_with_coreset(model, pmnist_train_loaders, pmnist_train_loaders, \n","        optimizer,10, coreset_size, beta=1)\n","    p_trends_2.append(trend)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T14:58:25.916361Z","iopub.status.busy":"2024-03-22T14:58:25.915730Z","iopub.status.idle":"2024-03-22T15:30:48.763943Z","shell.execute_reply":"2024-03-22T15:30:48.763026Z","shell.execute_reply.started":"2024-03-22T14:58:25.916325Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 10/10 [02:07<00:00, 12.79s/it]\n","100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 97.82%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n","100%|██████████| 10/10 [03:00<00:00, 18.10s/it]\n","100%|██████████| 2/2 [00:01<00:00,  1.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 2 tasks: 95.91%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2/2 [00:01<00:00,  1.81it/s]\n","100%|██████████| 10/10 [03:01<00:00, 18.15s/it]\n","100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 3 tasks: 95.53%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n","100%|██████████| 10/10 [03:01<00:00, 18.14s/it]\n","100%|██████████| 4/4 [00:02<00:00,  1.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 4 tasks: 94.73%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:02<00:00,  1.70it/s]\n","100%|██████████| 10/10 [03:01<00:00, 18.11s/it]\n","100%|██████████| 5/5 [00:03<00:00,  1.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 5 tasks: 93.29%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5/5 [00:03<00:00,  1.61it/s]\n","100%|██████████| 10/10 [03:00<00:00, 18.06s/it]\n","100%|██████████| 6/6 [00:03<00:00,  1.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 6 tasks: 93.78%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n","100%|██████████| 10/10 [03:01<00:00, 18.12s/it]\n","100%|██████████| 7/7 [00:04<00:00,  1.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 7 tasks: 93.35%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 7/7 [00:04<00:00,  1.59it/s]\n","100%|██████████| 10/10 [03:01<00:00, 18.15s/it]\n","100%|██████████| 8/8 [00:05<00:00,  1.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 8 tasks: 92.62%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [00:05<00:00,  1.58it/s]\n","100%|██████████| 10/10 [03:01<00:00, 18.16s/it]\n","100%|██████████| 9/9 [00:05<00:00,  1.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 9 tasks: 92.50%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9/9 [00:05<00:00,  1.57it/s]\n","100%|██████████| 10/10 [02:59<00:00, 17.95s/it]\n","100%|██████████| 10/10 [00:06<00:00,  1.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 10 tasks: 91.71%\n"]}],"source":["epoch_per_task = 10\n","model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","coreset_size = 200\n","ave_acc_trend_2 = run_vcl_with_coreset(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta=1)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T15:30:48.765429Z","iopub.status.busy":"2024-03-22T15:30:48.765138Z","iopub.status.idle":"2024-03-22T16:03:43.167572Z","shell.execute_reply":"2024-03-22T16:03:43.166692Z","shell.execute_reply.started":"2024-03-22T15:30:48.765405Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]\n","100%|██████████| 10/10 [02:05<00:00, 12.59s/it]\n","100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 1 tasks: 97.85%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n","100%|██████████| 10/10 [02:59<00:00, 17.95s/it]\n","100%|██████████| 2/2 [00:01<00:00,  1.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 2 tasks: 93.47%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2/2 [00:01<00:00,  1.78it/s]\n","100%|██████████| 10/10 [03:03<00:00, 18.34s/it]\n","100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 3 tasks: 91.85%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n","100%|██████████| 10/10 [03:07<00:00, 18.71s/it]\n","100%|██████████| 4/4 [00:02<00:00,  1.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 4 tasks: 90.50%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:02<00:00,  1.61it/s]\n","100%|██████████| 10/10 [03:04<00:00, 18.48s/it]\n","100%|██████████| 5/5 [00:03<00:00,  1.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 5 tasks: 89.79%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5/5 [00:03<00:00,  1.54it/s]\n","100%|██████████| 10/10 [03:06<00:00, 18.64s/it]\n","100%|██████████| 6/6 [00:03<00:00,  1.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 6 tasks: 89.01%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6/6 [00:03<00:00,  1.55it/s]\n","100%|██████████| 10/10 [03:04<00:00, 18.40s/it]\n","100%|██████████| 7/7 [00:04<00:00,  1.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 7 tasks: 88.30%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 7/7 [00:04<00:00,  1.55it/s]\n","100%|██████████| 10/10 [03:05<00:00, 18.54s/it]\n","100%|██████████| 8/8 [00:05<00:00,  1.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 8 tasks: 88.08%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8/8 [00:05<00:00,  1.57it/s]\n","100%|██████████| 10/10 [03:03<00:00, 18.36s/it]\n","100%|██████████| 9/9 [00:05<00:00,  1.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 9 tasks: 87.32%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9/9 [00:05<00:00,  1.55it/s]\n","100%|██████████| 10/10 [03:04<00:00, 18.42s/it]\n","100%|██████████| 10/10 [00:06<00:00,  1.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Average Accuracy across 10 tasks: 87.22%\n"]}],"source":["model = MFVI_NN(28*28, [100, 100], 10, num_tasks = 10).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","ave_acc_trend_3 = run_vcl_with_coreset(model, train_loaders, test_loaders, optimizer, epoch_per_task, coreset_size, beta=10)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-22T16:03:43.170394Z","iopub.status.busy":"2024-03-22T16:03:43.169943Z","iopub.status.idle":"2024-03-22T16:03:43.202647Z","shell.execute_reply":"2024-03-22T16:03:43.201461Z","shell.execute_reply.started":"2024-03-22T16:03:43.170358Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'ave_acc_trend_rc' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ave_acc_trend_1)),\u001b[43mave_acc_trend_rc\u001b[49m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ave_acc_trend_2)),ave_acc_trend_rc)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ave_acc_trend_3)),ave_acc_trend_rc)\n","\u001b[0;31mNameError\u001b[0m: name 'ave_acc_trend_rc' is not defined"]}],"source":["plt.plot(range(len(ave_acc_trend_1)),ave_acc_trend_rc)\n","plt.plot(range(len(ave_acc_trend_2)),ave_acc_trend_rc)\n","plt.plot(range(len(ave_acc_trend_3)),ave_acc_trend_rc)"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:49:50.651029Z","iopub.status.busy":"2024-03-21T21:49:50.650367Z","iopub.status.idle":"2024-03-21T21:49:50.658468Z","shell.execute_reply":"2024-03-21T21:49:50.657509Z","shell.execute_reply.started":"2024-03-21T21:49:50.650997Z"},"id":"KBjaQtbREyCc","trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'np'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgreedy_k_center\u001b[39m(X, k):\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    Selects k points from X using the greedy k-center algorithm.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    - indices (list): Indices of the selected centers.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'np'"]}],"source":["import np \n","def greedy_k_center(X, k):\n","    \"\"\"\n","    Selects k points from X using the greedy k-center algorithm.\n","    \n","    Args:\n","    - X (np.array): The dataset, shape (n_samples, n_features).\n","    - k (int): Number of centers to select.\n","    \n","    Returns:\n","    - centers (np.array): The selected centers, shape (k, n_features).\n","    - indices (list): Indices of the selected centers.\n","    \"\"\"\n","    # Randomly choose the first center\n","    n_samples = X.shape[0]\n","    first_center_idx = np.random.choice(n_samples)\n","    centers = [X[first_center_idx]]\n","    indices = [first_center_idx]\n","    \n","    # Initialize the minimum distance to the closest center for each point\n","    min_distances = np.full(n_samples, np.inf)\n","    \n","    # Iteratively select k-1 remaining centers\n","    for _ in range(k - 1):\n","        # Update the minimum distances for all points\n","        distances = np.linalg.norm(X - centers[-1], axis=1)\n","        min_distances = np.minimum(min_distances, distances)\n","        \n","        # Select the next center to be the point with the maximum distance to its closest center\n","        next_center_idx = np.argmax(min_distances)\n","        centers.append(X[next_center_idx])\n","        indices.append(next_center_idx)\n","    \n","    return np.array(centers), indices\n"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["def create_split_task(dataset, classes):\n","    \"\"\"\n","    Create a binary classification task from the MNIST dataset.\n","    \n","    Parameters:\n","    - dataset: The original MNIST dataset (training or test).\n","    - classes: A tuple of two integers representing the classes to include in the split.\n","    \n","    Returns:\n","    - A Subset of the original dataset containing only the specified classes.\n","    \"\"\"\n","    # Find indices of classes we're interested in\n","    indices = [i for i, (_, target) in enumerate(dataset) if target in classes]\n","    \n","    # Create a subset of the dataset with only the specified classes\n","    subset = Subset(dataset, indices)\n","    \n","    return subset\n","\n","def create_split_dataloaders(train_dataset, test_dataset, tasks, batch_size=256):\n","    \"\"\"\n","    Create DataLoaders for each binary task in Split MNIST.\n","    \n","    Parameters:\n","    - train_dataset: The MNIST training dataset.\n","    - test_dataset: The MNIST test dataset.\n","    - batch_size: The batch size for the DataLoader.\n","    \n","    Returns:\n","    - A list of tuples containing (train_loader, test_loader) for each binary task.\n","    \"\"\"\n","    dataloaders = []\n","\n","    for task in tasks:\n","        # Create training subset and DataLoader\n","        train_subset = create_split_task(train_dataset, task)\n","        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n","\n","        # Create test subset and DataLoader\n","        test_subset = create_split_task(test_dataset, task)\n","        test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n","\n","        dataloaders.append((train_loader, test_loader))\n","    \n","    return dataloaders"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":["import torch\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5,), (0.5, 0.5, 0.5))]\n",")"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","\n","Files already downloaded and verified\n"]}],"source":["cifar10_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","cifar10_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"output with shape [1, 28, 28] doesn't match the broadcast shape [3, 28, 28]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[65], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m1\u001b[39m), (\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m7\u001b[39m), (\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m4\u001b[39m), (\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)]\n\u001b[0;32m----> 2\u001b[0m dataloaders \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_split_dataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmnist_trainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmnist_testset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[51], line 36\u001b[0m, in \u001b[0;36mcreate_split_dataloaders\u001b[0;34m(train_dataset, test_dataset, tasks, batch_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m dataloaders \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Create training subset and DataLoader\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     train_subset \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_split_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_subset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Create test subset and DataLoader\u001b[39;00m\n","Cell \u001b[0;32mIn[51], line 13\u001b[0m, in \u001b[0;36mcreate_split_task\u001b[0;34m(dataset, classes)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mCreate a binary classification task from the MNIST dataset.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m- A Subset of the original dataset containing only the specified classes.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Find indices of classes we're interested in\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m indices \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, (_, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset) \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m classes]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Create a subset of the dataset with only the specified classes\u001b[39;00m\n\u001b[1;32m     16\u001b[0m subset \u001b[38;5;241m=\u001b[39m Subset(dataset, indices)\n","Cell \u001b[0;32mIn[51], line 13\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mCreate a binary classification task from the MNIST dataset.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m- A Subset of the original dataset containing only the specified classes.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Find indices of classes we're interested in\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m indices \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, (_, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset) \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m classes]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Create a subset of the dataset with only the specified classes\u001b[39;00m\n\u001b[1;32m     16\u001b[0m subset \u001b[38;5;241m=\u001b[39m Subset(dataset, indices)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/functional.py:363\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/MDS/lib/python3.10/site-packages/torchvision/transforms/_functional_tensor.py:928\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m std\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    927\u001b[0m     std \u001b[38;5;241m=\u001b[39m std\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 928\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv_(std)\n","\u001b[0;31mRuntimeError\u001b[0m: output with shape [1, 28, 28] doesn't match the broadcast shape [3, 28, 28]"]}],"source":["tasks = [(6, 1), (9, 7), (8, 4), (5, 0), (2, 3)]\n","dataloaders = create_split_dataloaders(mnist_trainset, mnist_testset, tasks, batch_size=256)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ave_acc_trend_split_mnist_1 = run_vcl_with_coreset(model, *dataloaders optimizer, epoch_per_task, coreset_size, beta=10)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
